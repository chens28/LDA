{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf98b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import math\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e342cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_processed_text(file_name):\n",
    "    '''\n",
    "    load processed documents back\n",
    "    '''\n",
    "    text_list = []\n",
    "\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            text_list.append(line.strip()) # no need to split for mallet\n",
    "\n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db6e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_seeds(num_seeds=10):\n",
    "    '''\n",
    "    generate n random seeds\n",
    "    '''\n",
    "    seeds = np.random.randint(low=0, high=10000, size=num_seeds).tolist()\n",
    "        \n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b65e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_topic_words(topic_keys_file):\n",
    "    '''\n",
    "    load top topic words generated by mallet\n",
    "    '''\n",
    "    topic_words = []\n",
    "    with open(topic_keys_file, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            words = parts[2:]  # Skip the topic ID and weight\n",
    "            topic_words.append(words)\n",
    "    return topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41928d5e",
   "metadata": {},
   "source": [
    "The 2 functions belowa are inspired by the little-mallet-wrapper - https://github.com/maria-antoniak/little-mallet-wrapper/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ff40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path_to_mallet,\n",
    "                path_to_training_data,\n",
    "                path_to_formatted_training_data,\n",
    "                training_data,\n",
    "                training_ids=None,\n",
    "                use_pipe_from=None):\n",
    "    '''\n",
    "    import data to mallet\n",
    "    '''\n",
    "\n",
    "    training_data_file = open(path_to_training_data, 'w')\n",
    "    for i, d in enumerate(training_data):\n",
    "        if training_ids:\n",
    "            training_data_file.write(str(training_ids[i]) + ' no_label ' + d + '\\n')\n",
    "        else:\n",
    "            training_data_file.write(str(i) + ' no_label ' + d + '\\n')\n",
    "    training_data_file.close()\n",
    "\n",
    "    if use_pipe_from:\n",
    "        print('Importing data using pipe...')\n",
    "        os.system(path_to_mallet + ' import-file --input \"' + path_to_training_data + '\"' \n",
    "                                             + ' --output \"' + path_to_formatted_training_data + '\"' \\\n",
    "                                             + ' --keep-sequence' \\\n",
    "                                             + ' --use-pipe-from \"' + use_pipe_from + '\"'\n",
    "                                             + ' --preserve-case')\n",
    "        \n",
    "    else:\n",
    "        print('Importing data...')\n",
    "        os.system(path_to_mallet + ' import-file --input \"' + path_to_training_data + '\"' \n",
    "                                             + ' --output \"' + path_to_formatted_training_data + '\"' \\\n",
    "                                             + ' --keep-sequence'\n",
    "                                             + ' --preserve-case')\n",
    "\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_topic_model(path_to_mallet,\n",
    "                      path_to_formatted_training_data,\n",
    "                      path_to_topic_keys,\n",
    "                      path_to_topic_distributions,\n",
    "                      num_topics,\n",
    "                      interval,\n",
    "                      burnin,\n",
    "                      random_state):\n",
    "    '''\n",
    "    train LDA model using mallet\n",
    "    '''\n",
    "\n",
    "#     print('Training topic model...')\n",
    "    os.system(path_to_mallet + ' train-topics --input \"' + path_to_formatted_training_data + '\"' \\\n",
    "                                          + ' --num-topics ' + str(num_topics) \\\n",
    "                                          + ' --num-top-words ' + str(50) \\\n",
    "                                          + ' --random-seed ' + str(random_state) \\\n",
    "                                          + ' --output-topic-keys \"' + path_to_topic_keys + '\"' \\\n",
    "                                          + ' --output-doc-topics \"' + path_to_topic_distributions + '\"' \\\n",
    "                                          + ' --optimize-interval ' + str(interval) \\\n",
    "                                          + ' --optimize-burn-in ' + str(burnin))\n",
    "\n",
    "#     print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b135a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mallet_tests(seed, topic_words):\n",
    "    '''\n",
    "    generate intrusion tests for a lda model\n",
    "    '''\n",
    "    num_topics = len(topic_words)  # Determine the number of topics dynamically\n",
    "    intrusion_tests = {}\n",
    "        \n",
    "    # Create Intrusion Tests\n",
    "    for i, words in enumerate(topic_words):\n",
    "        \n",
    "        # Randomly sample 5 words from the top 10 words of the topic\n",
    "        np.random.seed(seed)\n",
    "        sample_words = np.random.choice(words[:10], 5, replace=False).tolist()\n",
    "        \n",
    "        # Prepare list of other topics to explore for intruder word\n",
    "        other_topics = list(range(num_topics))\n",
    "        other_topics.remove(i)  # Remove the current topic\n",
    "\n",
    "        # Ensure the intruder word is not in the top 50 words of the current topic\n",
    "        intruder_word = None\n",
    "        while other_topics and intruder_word is None:\n",
    "            np.random.seed(seed)\n",
    "            intruder_topic = np.random.choice(other_topics)\n",
    "            other_topics.remove(intruder_topic)  # Remove the explored topic\n",
    "            \n",
    "            # Attempt to find a suitable intruder word\n",
    "            for word in topic_words[intruder_topic]:\n",
    "                if word not in words:\n",
    "                    intruder_word = word\n",
    "                    break\n",
    "\n",
    "        # Save the sample and the intruder into a dictionary\n",
    "        intrusion_tests[i] = {'top 5 sample': sample_words,\n",
    "                              'intruder': intruder_word}\n",
    "                              \n",
    "    return intrusion_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769714c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lda_mallet(path_to_mallet, path_to_formatted_training_data, texts, id2word, num_topics, seeds, grid):\n",
    "    '''\n",
    "    tune lda for each num_topics and seeds using grid search\n",
    "    '''\n",
    "    results = []\n",
    "\n",
    "    total_iter = len(num_topics)*len(seeds)*len(grid['interval'])*len(grid['burnin'])\n",
    "    progress_bar = tqdm(total=total_iter, desc=\"Total progress\")\n",
    "    \n",
    "    for k in num_topics:\n",
    "        \n",
    "        for seed in seeds:\n",
    "            \n",
    "            # tune lda\n",
    "            best_score = float('-inf')\n",
    "            best_interval = None\n",
    "            best_burnin = None\n",
    "            best_topic_words = None\n",
    "            \n",
    "            for interval in grid['interval']:\n",
    "                for burnin in grid['burnin']:\n",
    "                    path_to_topic_keys           = output_directory_path + '/mallet.topic_keys.' + str(k) + '_' + str(seed) + '_' + str(interval) + '_' + str(burnin) + '.txt'\n",
    "                    path_to_topic_distributions  = output_directory_path + '/mallet.topic_distributions.' + str(k) + '_' + str(seed) + '_' + str(interval) + '_' + str(burnin) + '.txt'\n",
    "\n",
    "                    train_topic_model(\n",
    "                        path_to_mallet,\n",
    "                        path_to_formatted_training_data,\n",
    "                        path_to_topic_keys,\n",
    "                        path_to_topic_distributions,\n",
    "                        num_topics = k,\n",
    "                        interval = interval,\n",
    "                        burnin = burnin,\n",
    "                        random_state = seed)\n",
    "\n",
    "                    topic_words = load_topic_words(path_to_topic_keys)\n",
    "                    coherence_model = models.CoherenceModel(topics=topic_words, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "                    score = coherence_model.get_coherence()\n",
    "\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_interval = interval\n",
    "                        best_burnin = burnin\n",
    "                        best_topic_words = topic_words\n",
    "\n",
    "                    progress_bar.update(1)\n",
    "                 \n",
    "            # make tests\n",
    "            tests = prepare_mallet_tests(seed, best_topic_words)\n",
    "            \n",
    "            results.append({\n",
    "                    'num_topics': k,\n",
    "                    'seed': seed,\n",
    "                    'score': best_score,\n",
    "                    'interval': best_interval,\n",
    "                    'burnin': best_burnin,\n",
    "                    'tests': tests})\n",
    "    \n",
    "    progress_bar.close()\n",
    "   \n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63210b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df, file_path):\n",
    "    '''saves df to local csv'''\n",
    "    df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
