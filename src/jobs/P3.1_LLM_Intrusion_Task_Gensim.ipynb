{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.29-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Using cached aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
      "  Using cached langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
      "  Using cached langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.51-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Using cached pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached orjson-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic<3,>=1->langchain)\n",
      "  Using cached pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic<3,>=1->langchain)\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "Using cached aiohttp-3.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
      "Using cached langchain_core-0.1.46-py3-none-any.whl (299 kB)\n",
      "Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Using cached langsmith-0.1.51-py3-none-any.whl (115 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Using cached pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "Using cached pydantic_core-2.18.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached SQLAlchemy-2.0.29-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "Using cached greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (620 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Using cached orjson-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, PyYAML, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, idna, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic-core, marshmallow, jsonpatch, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.7.1 which is incompatible.\n",
      "botocore 1.31.64 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 SQLAlchemy-2.0.29 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 attrs-23.2.0 certifi-2024.2.2 charset-normalizer-3.3.2 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 idna-3.7 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.46 langchain-text-splitters-0.0.1 langsmith-0.1.51 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.1 packaging-23.2 pydantic-2.7.1 pydantic-core-2.18.2 requests-2.31.0 tenacity-8.2.3 typing-extensions-4.11.0 typing-inspect-0.9.0 urllib3-2.2.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/urllib3-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/typing_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/typing_extensions-4.11.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/tenacity already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/tenacity-8.2.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/_yaml already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/packaging already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/packaging-23.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/orjson-3.10.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/orjson already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/numpy-1.26.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/mypy_extensions.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/mypy_extensions-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/multidict-6.0.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/multidict already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/jsonpointer.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/jsonpointer-2.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/greenlet already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/greenlet-3.0.3.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/frozenlist-1.4.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/frozenlist already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/certifi-2024.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/attr already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/attrs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/attrs-23.2.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/annotated_types already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/annotated_types-0.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/yarl already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/yarl-1.9.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/typing_inspect.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/typing_inspect-0.9.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/sqlalchemy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/SQLAlchemy-2.0.29.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/pydantic_core-2.18.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/pydantic_core already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/marshmallow already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/marshmallow-3.21.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/jsonpatch.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/jsonpatch-1.33.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/aiosignal already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/aiosignal-1.3.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/pydantic already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/pydantic-2.7.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/dataclasses_json already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/dataclasses_json-0.6.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/aiohttp-3.9.5.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/aiohttp already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langsmith already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langsmith-0.1.51.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langchain_core already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langchain_core-0.1.46.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langchain_text_splitters already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langchain_text_splitters-0.0.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langchain_community already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langchain_community-0.0.34.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langchain already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/langchain-0.1.16.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/include already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install langchain --target /home/aah9103/.local/lib/python3.11/site-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pillow (from pdf2image)\n",
      "  Using cached pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Using cached pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Installing collected packages: pillow, pdf2image\n",
      "Successfully installed pdf2image-1.17.0 pillow-10.3.0\n",
      "\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/pillow.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/PIL already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/pillow-10.3.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/pdf2image already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/pdf2image-1.17.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pdf2image --target /home/aah9103/.local/lib/python3.11/site-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPT4All\n",
      "  Using cached gpt4all-2.6.0-py3-none-manylinux1_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting requests (from GPT4All)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from GPT4All)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->GPT4All)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->GPT4All)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->GPT4All)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->GPT4All)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached gpt4all-2.6.0-py3-none-manylinux1_x86_64.whl (3.9 MB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: urllib3, tqdm, idna, charset-normalizer, certifi, requests, GPT4All\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.75 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.75 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.7.1 which is incompatible.\n",
      "botocore 1.31.64 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed GPT4All-2.6.0 certifi-2024.2.2 charset-normalizer-3.3.2 idna-3.7 requests-2.31.0 tqdm-4.66.2 urllib3-2.2.1\n",
      "\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/urllib3 already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/urllib3-2.2.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/tqdm-4.66.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/idna already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/idna-3.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/charset_normalizer already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/charset_normalizer-3.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/certifi-2024.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/requests already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/requests-2.31.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/gpt4all already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/gpt4all-2.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/aah9103/.local/lib/python3.11/site-packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install GPT4All --target /home/aah9103/.local/lib/python3.11/site-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/share/apps/anaconda3/2024.02/bin/python'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/aah9103',\n",
       " '/share/apps/anaconda3/2024.02/lib/python311.zip',\n",
       " '/share/apps/anaconda3/2024.02/lib/python3.11',\n",
       " '/share/apps/anaconda3/2024.02/lib/python3.11/lib-dynload',\n",
       " '',\n",
       " '/home/aah9103/.local/lib/python3.11/site-packages',\n",
       " '/share/apps/anaconda3/2024.02/lib/python3.11/site-packages']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from pdf2image import convert_from_path\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load dictionary:\n",
    "# data = {0: {'top 5 sample': ['water', 'area', 'river', 'park', 'miles'], 'intruder': 'game'}, \n",
    "#         1: {'top 5 sample': ['horses', 'horse', 'breed', 'coins', 'silver'], 'intruder': 'hindu'},\n",
    "#         2: {'top 5 sample': ['issue', 'situation', 'lead', 'stick', 'nice'], 'intruder': 'tampon'}}\n",
    "\n",
    "# #gensim VI is worse than mallet GS \n",
    "# #10-20-50 topics. regenerate 20 times(mutlitple runs) and then over multiple datasetsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Gensim File\n",
    "dataG = pd.read_csv('gensim_test.csv')\n",
    "dataG['package'] = 'gensim'\n",
    "#dataG.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Mallet file\n",
    "dataM = pd.read_csv('mallet_test.csv')\n",
    "dataM['package'] = 'mallet'\n",
    "#dataM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shorten for test\n",
    "dataM = dataM.head(1)\n",
    "dataG = dataG.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>seed</th>\n",
       "      <th>score</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>tests</th>\n",
       "      <th>package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.615142</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{0: {'top 5 sample': ['start', 'time', 'feel',...</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_topics  seed     score       alpha   eta   \n",
       "0          10  1928  0.615142  asymmetric  0.01  \\\n",
       "\n",
       "                                               tests package  \n",
       "0  {0: {'top 5 sample': ['start', 'time', 'feel',...  gensim  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.concat([dataG, dataM], ignore_index=True)#.reset_index()\n",
    "data = dataG\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load json output of topic model\n",
    "# with open('llm_tests.json', 'r') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fix JSON strings and convert them to JSON objects\n",
    "def convertJSON(s):\n",
    "    s = s.replace(\"'\", '\"')\n",
    "    s = re.sub(r'(\\s*)(\\d+)(\\s*):', r'\\1\"\\2\"\\3:', s)\n",
    "    return json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load json string\n",
    "data['tests'] = data['tests'].apply(lambda x: convertJSON(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load json output of topic model\n",
    "# with open('gensim_tests.json', 'r') as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GPT4All(model=\"./models/gptj/mistral-7b-openorca.gguf2.Q4_0.gguf\", backend = 'gptj', verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a helpful assistant evaluating the top words of a topic model output for a given topic. \n",
    "Select which word or phrase is the least related to all other words or phrases in terms of the meaning of the word or phrase. \n",
    "If multiple words do not fit, choose the word that is most out of place in terms of the meaning of the word.\n",
    "{datasetDescription}\n",
    "Here is the list of words for your task: [{listOfWords}]\n",
    "Your answer MUST CONTAIN ONLY a single word.\n",
    "Also, mark the selected word by preceding it with 000 and succeeding it with 000.\n",
    "For example if a list of words is \"apple, banana, cat\", your response should ONLY BE: '000cat000'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template = template, input_variables = ['datasetDescription', 'listOfWords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llmChain = LLMChain(prompt = prompt, llm = llm, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans = llmChain({'datasetDescription': 'data of words', 'listOfWords': 'apple, banana, cat, sheep, house'})\n",
    "\n",
    "# regSearch = re.search(r'000(.*?)000', ans['text'])\n",
    "# if regSearch:\n",
    "#     print(regSearch.group(1))\n",
    "# else:\n",
    "#     print('no match')\n",
    "\n",
    "# You are a helpful assistant evaluating the top words of a topic model output for a given topic. \n",
    "# Select which word or phrase is the least related to all other words or phrases in terms of the meaning of the word or phrase. \n",
    "# If multiple words do not fit, choose the word that is most out of place in terms of the meaning of the word.\n",
    "# Pay attention to the similarity of each word to all othe words in the set when you make your decision.\n",
    "# Here is the list of words for your task: [hour, gain, week, baby, labor, section]\n",
    "# Your answer MUST CONTAIN ONLY a single word.\n",
    "# Also, mark the selected word by preceding it with 000 and succeeding it with 000.\n",
    "# For example if a list of words is \"apple, banana, cat\", your response should ONLY BE: '000cat000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDesc = \"\"\"\n",
    "Pay attention to the similarity of each word to all othe words in the set when you make your decision.\n",
    "\"\"\"\n",
    "\n",
    "# dataDesc = \"\"\"\n",
    "# The topic modelling is based on a corpus of reddit posts relating to maternal health. \n",
    "# The data from which topic words are extracted includes topics like abortion and sexuality.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in data.items():\n",
    "#     wordList = v['top 5 sample'] + [v['intruder']]\n",
    "#     random.shuffle(wordList)\n",
    "#     wordListStr = \", \".join(wordList)\n",
    "#     trueIntruder = v['intruder']\n",
    "#     detectedIntruder = 'NOTDETECTED'\n",
    "#     ans = llmChain({'datasetDescription': dataDesc, 'listOfWords': wordListStr})\n",
    "#     regSearch = re.search(r'000(.*?)000', ans['text'])\n",
    "#     data[k]['wordlist'] = wordList\n",
    "#     data[k]['wordliststr'] = wordListStr\n",
    "#     if regSearch:\n",
    "#         detectedIntruder = regSearch.group(1)\n",
    "#     data[k]['detectedIntruder'] = detectedIntruder\n",
    "#     if trueIntruder.lower() == detectedIntruder.lower():\n",
    "#         data[k]['success'] = 1\n",
    "#     else:\n",
    "#         data[k]['success'] = 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame.from_dict(data, orient='index')\n",
    "# rate = df['success'].sum() / len(df)\n",
    "# rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llmEval(data, llmChain, maxIter = 10, dataDesc = \"\"\"\"\"\"):\n",
    "    tot = len(data)\n",
    "    i = 1\n",
    "    for k, v in data.items():\n",
    "        print(\"Evaluating \",i,\" / \",tot)\n",
    "        i += 1\n",
    "        itr = maxIter\n",
    "        wordList = v['top 5 sample'] + [v['intruder']]\n",
    "        random.shuffle(wordList)\n",
    "        wordListStr = \", \".join(wordList)\n",
    "        trueIntruder = v['intruder']\n",
    "        data[k]['wordlist'] = wordList\n",
    "        data[k]['wordliststr'] = wordListStr\n",
    "        detectedIntruder = 'NOTDETECTED'\n",
    "        while itr > 0:\n",
    "            itr -= 1\n",
    "            if detectedIntruder != 'NOTDETECTED':\n",
    "                itr = 0\n",
    "                break\n",
    "            ans = llmChain({'datasetDescription': dataDesc, 'listOfWords': wordListStr})\n",
    "            regSearch = re.search(r'000(.*?)000', ans['text'])\n",
    "            if regSearch:\n",
    "                detectedIntruder = regSearch.group(1)\n",
    "\n",
    "        data[k]['detectedIntruder'] = detectedIntruder\n",
    "        data[k]['rawLLMOP'] = ans['text']\n",
    "        if trueIntruder.lower() == detectedIntruder.lower():\n",
    "            data[k]['success'] = 1\n",
    "        else:\n",
    "            data[k]['success'] = 0\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    rate = df['success'].sum() / len(df)\n",
    "    return pd.Series({'score': rate, 'data': data})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating  1  /  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating  2  /  10\n",
      "Evaluating  3  /  10\n",
      "Evaluating  4  /  10\n",
      "Evaluating  5  /  10\n",
      "Evaluating  6  /  10\n",
      "Evaluating  7  /  10\n",
      "Evaluating  8  /  10\n",
      "Evaluating  9  /  10\n",
      "Evaluating  10  /  10\n"
     ]
    }
   ],
   "source": [
    "#Run eval\n",
    "data[['score', 'data']] = data['tests'].apply(lambda x: llmEval(x, llmChain, 10, dataDesc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>seed</th>\n",
       "      <th>score</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>tests</th>\n",
       "      <th>package</th>\n",
       "      <th>data</th>\n",
       "      <th>NewScore</th>\n",
       "      <th>fixedData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.5</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'0': {'top 5 sample': ['start', 'time', 'feel...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['start', 'time', 'feel...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'0': {'top 5 sample': ['start', 'time', 'feel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_topics  seed  score       alpha   eta   \n",
       "0          10  1928    0.5  asymmetric  0.01  \\\n",
       "\n",
       "                                               tests package   \n",
       "0  {'0': {'top 5 sample': ['start', 'time', 'feel...  gensim  \\\n",
       "\n",
       "                                                data  NewScore   \n",
       "0  {'0': {'top 5 sample': ['start', 'time', 'feel...       0.5  \\\n",
       "\n",
       "                                           fixedData  \n",
       "0  {'0': {'top 5 sample': ['start', 'time', 'feel...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixEval(data):\n",
    "    newData = pd.DataFrame.from_dict(data, orient= 'index')[['top 5 sample', 'wordliststr', 'rawLLMOP', 'intruder', 'detectedIntruder', 'success']]\n",
    "    newData = newData.to_dict(orient='index')\n",
    "    tot = len(data)\n",
    "    i = 1\n",
    "    for k, v in newData.items():\n",
    "        i += 1\n",
    "        trueIntruder = newData[k]['intruder']\n",
    "        detectedIntruder = newData[k]['detectedIntruder']\n",
    "        llmOP = newData[k]['rawLLMOP']\n",
    "        # llmOP = 'is: int'\n",
    "        # trueIntruder = 'test'\n",
    "        # detectedIntruder = 'NOTDETECTED'\n",
    "#        print(trueIntruder)\n",
    "#        detectedIntruder = 'NOTDETECTED'\n",
    "        if detectedIntruder == 'NOTDETECTED':\n",
    "            print(\"fixing \",i,\" / \",tot)\n",
    "            regSearch = re.search(r\"is:\\W*([a-zA-Z]+)\\W*\", llmOP)\n",
    "            if regSearch:\n",
    "                detectedIntruder = regSearch.group(1)\n",
    "#        print(detectedIntruder)\n",
    "\n",
    "        newData[k]['detectedIntruder'] = detectedIntruder\n",
    "        if trueIntruder.lower() == detectedIntruder.lower():\n",
    "            newData[k]['success'] = 1\n",
    "        else:\n",
    "            newData[k]['success'] = 0\n",
    "\n",
    "    df = pd.DataFrame.from_dict(newData, orient= 'index')[['top 5 sample', 'wordliststr', 'rawLLMOP', 'intruder', 'detectedIntruder', 'success']]\n",
    "    rate = df['success'].sum() / len(df)\n",
    "    return pd.Series({'NewScore': rate, 'fixedData': newData})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#databkp = data\n",
    "#data = databkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run repair\n",
    "data[['NewScore', 'fixedData']] = data['data'].apply(lambda x: fixEval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>seed</th>\n",
       "      <th>score</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.50</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.15</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.10</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.20</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>gensim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_topics  seed  score       alpha    eta package\n",
       "0           10  1928   0.50  asymmetric   0.01  gensim\n",
       "1           10  3328   0.10          10   0.01  gensim\n",
       "2           10  1062   0.40          10    NaN  gensim\n",
       "3           10  3953   0.10          10   0.01  gensim\n",
       "4           10  1172   0.20          10    NaN  gensim\n",
       "5           20  1928   0.15  asymmetric   0.10  gensim\n",
       "6           20  3328   0.35        0.01    NaN  gensim\n",
       "7           20  1062   0.15          10    NaN  gensim\n",
       "8           20  3953   0.20  asymmetric   0.01  gensim\n",
       "9           20  1172   0.50          10   0.10  gensim\n",
       "10          50  1928   0.10         0.1  10.00  gensim\n",
       "11          50  3328   0.16         0.1  10.00  gensim\n",
       "12          50  1062   0.20         0.1  10.00  gensim\n",
       "13          50  3953   0.16         0.1  10.00  gensim\n",
       "14          50  1172   0.20         0.1  10.00  gensim\n",
       "15         100  1928   0.05         0.1  10.00  gensim\n",
       "16         100  3328   0.34         0.1  10.00  gensim\n",
       "17         100  1062   0.12         0.1  10.00  gensim\n",
       "18         100  3953   0.04         0.1  10.00  gensim\n",
       "19         100  1172   0.17         0.1  10.00  gensim"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dcols = list(data.columns)\n",
    "#dcols.remove(['tests', 'data'])\n",
    "#data[['num_topics', 'seed', 'score', 'alpha', 'eta', 'package']]\n",
    "#dcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('evalOutputGensim2.xlsx')#, mode='a', header=False)\n",
    "#data[['num_topics', 'seed', 'score', 'alpha', 'eta', 'package']].to_csv('evalOutputGensim1.csv')\n",
    "# pd.DataFrame.from_dict(dict(data.head(1)['data'])[0], orient= 'index')[['top 5 sample', 'wordliststr', 'rawLLMOP', 'intruder', 'detectedIntruder', 'success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('evalOutput1.csv')\n",
    "# pd.DataFrame.from_dict(dict(data.head(1)['data'])[0], orient= 'index')[['top 5 sample', 'wordliststr', 'rawLLMOP', 'intruder', 'detectedIntruder', 'success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>seed</th>\n",
       "      <th>score</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>tests</th>\n",
       "      <th>package</th>\n",
       "      <th>data</th>\n",
       "      <th>NewScore</th>\n",
       "      <th>fixedData</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.50</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'0': {'top 5 sample': ['start', 'time', 'feel', 'back', 'make'], 'intruder': 'baby', 'wordlist': ['back', 'make', 'feel', 'time', 'start', 'baby'], 'wordliststr': 'back, make, feel, time, start, baby', 'detectedIntruder': 'baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'success': 1}, '1': {'top 5 sample': ['blood', 'sex', 'doctor', 'problem', 'year'], 'intruder': 'week', 'wordlist': ['year', 'problem', 'doctor', 'sex', 'blood', 'week'], 'wordliststr': 'year, problem, doctor, sex, blood, week', 'detectedIntruder': 'sex', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'success': 0}, '2': {'top 5 sample': ['human', 'life', 'abortion', 'make', 'child'], 'intruder': 'week', 'wordlist': ['make', 'abortion', 'human', 'week', 'life', 'child'], 'wordliststr': 'make, abortion, human, week, life, child', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in this set is: 000week000', 'success': 1}, '3': {'top 5 sample': ['hour', 'labor', ...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['start', 'time', 'feel', 'back', 'make'], 'intruder': 'baby', 'wordlist': ['back', 'make', 'feel', 'time', 'start', 'baby'], 'wordliststr': 'back, make, feel, time, start, baby', 'detectedIntruder': 'baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'success': 1}, '1': {'top 5 sample': ['blood', 'sex', 'doctor', 'problem', 'year'], 'intruder': 'week', 'wordlist': ['year', 'problem', 'doctor', 'sex', 'blood', 'week'], 'wordliststr': 'year, problem, doctor, sex, blood, week', 'detectedIntruder': 'sex', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'success': 0}, '2': {'top 5 sample': ['human', 'life', 'abortion', 'make', 'child'], 'intruder': 'week', 'wordlist': ['make', 'abortion', 'human', 'week', 'life', 'child'], 'wordliststr': 'make, abortion, human, week, life, child', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in this set is: 000week000', 'success': 1}, '3': {'top 5 sample': ['hour', 'labor', ...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>{'0': {'top 5 sample': ['start', 'time', 'feel', 'back', 'make'], 'wordliststr': 'back, make, feel, time, start, baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'intruder': 'baby', 'detectedIntruder': 'baby', 'success': 1}, '1': {'top 5 sample': ['blood', 'sex', 'doctor', 'problem', 'year'], 'wordliststr': 'year, problem, doctor, sex, blood, week', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'intruder': 'week', 'detectedIntruder': 'sex', 'success': 0}, '2': {'top 5 sample': ['human', 'life', 'abortion', 'make', 'child'], 'wordliststr': 'make, abortion, human, week, life, child', 'rawLLMOP': 'The least related word in this set is: 000week000', 'intruder': 'week', 'detectedIntruder': 'week', 'success': 1}, '3': {'top 5 sample': ['hour', 'labor', 'birth', 'push', 'hospital'], 'wordliststr': 'week, hour, hospital, birth, labor, push', 'rawLLMOP': 'The least related word in this set is: 000hospital000', 'intruder': 'week', 'detectedIntruder': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'0': {'top 5 sample': ['iud', 'month', 'bad', 'heavy', 'period'], 'intruder': 'make', 'wordlist': ['iud', 'bad', 'heavy', 'month', 'make', 'period'], 'wordliststr': 'iud, bad, heavy, month, make, period', 'detectedIntruder': 'iud', 'rawLLMOP': 'The least related word in this set is: 000iud000', 'success': 0}, '1': {'top 5 sample': ['give', 'time', 'thing', 'hard', 'baby'], 'intruder': 'period', 'wordlist': ['time', 'give', 'thing', 'baby', 'hard', 'period'], 'wordliststr': 'time, give, thing, baby, hard, period', 'detectedIntruder': 'baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'success': 0}, '2': {'top 5 sample': ['time', 'pain', 'cervix', 'check', 'doctor'], 'intruder': 'day', 'wordlist': ['check', 'cervix', 'day', 'pain', 'time', 'doctor'], 'wordliststr': 'check, cervix, day, pain, time, doctor', 'detectedIntruder': 'cervix', 'rawLLMOP': 'The least related word in this set is: 000cervix000', 'success': 0}, '3': {'top 5 sample': ['move', 'thing', 'good...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['iud', 'month', 'bad', 'heavy', 'period'], 'intruder': 'make', 'wordlist': ['iud', 'bad', 'heavy', 'month', 'make', 'period'], 'wordliststr': 'iud, bad, heavy, month, make, period', 'detectedIntruder': 'iud', 'rawLLMOP': 'The least related word in this set is: 000iud000', 'success': 0}, '1': {'top 5 sample': ['give', 'time', 'thing', 'hard', 'baby'], 'intruder': 'period', 'wordlist': ['time', 'give', 'thing', 'baby', 'hard', 'period'], 'wordliststr': 'time, give, thing, baby, hard, period', 'detectedIntruder': 'baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'success': 0}, '2': {'top 5 sample': ['time', 'pain', 'cervix', 'check', 'doctor'], 'intruder': 'day', 'wordlist': ['check', 'cervix', 'day', 'pain', 'time', 'doctor'], 'wordliststr': 'check, cervix, day, pain, time, doctor', 'detectedIntruder': 'cervix', 'rawLLMOP': 'The least related word in this set is: 000cervix000', 'success': 0}, '3': {'top 5 sample': ['move', 'thing', 'good...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{'0': {'top 5 sample': ['iud', 'month', 'bad', 'heavy', 'period'], 'wordliststr': 'iud, bad, heavy, month, make, period', 'rawLLMOP': 'The least related word in this set is: 000iud000', 'intruder': 'make', 'detectedIntruder': 'iud', 'success': 0}, '1': {'top 5 sample': ['give', 'time', 'thing', 'hard', 'baby'], 'wordliststr': 'time, give, thing, baby, hard, period', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'intruder': 'period', 'detectedIntruder': 'baby', 'success': 0}, '2': {'top 5 sample': ['time', 'pain', 'cervix', 'check', 'doctor'], 'wordliststr': 'check, cervix, day, pain, time, doctor', 'rawLLMOP': 'The least related word in this set is: 000cervix000', 'intruder': 'day', 'detectedIntruder': 'cervix', 'success': 0}, '3': {'top 5 sample': ['move', 'thing', 'good', 'make', 'feel'], 'wordliststr': 'good, feel, thing, day, make, move', 'rawLLMOP': 'The least related word in this set is: 000move000', 'intruder': 'day', 'detectedIntruder': 'move', 'success':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.40</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'top 5 sample': ['cup', 'flow', 'partner', 'wear', 'change'], 'intruder': 'abortion', 'wordlist': ['wear', 'change', 'abortion', 'cup', 'partner', 'flow'], 'wordliststr': 'wear, change, abortion, cup, partner, flow', 'detectedIntruder': 'abortion', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'success': 1}, '1': {'top 5 sample': ['make', 'good', 'feel', 'lot', 'start'], 'intruder': 'abortion', 'wordlist': ['make', 'lot', 'feel', 'abortion', 'good', 'start'], 'wordliststr': 'make, lot, feel, abortion, good, start', 'detectedIntruder': 'abortion', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'success': 1}, '2': {'top 5 sample': ['hospital', 'epidural', 'plan', 'contraction', 'section'], 'intruder': 'abortion', 'wordlist': ['contraction', 'epidural', 'abortion', 'plan', 'hospital', 'section'], 'wordliststr': 'contraction, epidural, abortion, plan, hospital, section', 'detectedIntruder': 'contraction', 'rawLLMOP': 'The least relate...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['cup', 'flow', 'partner', 'wear', 'change'], 'intruder': 'abortion', 'wordlist': ['wear', 'change', 'abortion', 'cup', 'partner', 'flow'], 'wordliststr': 'wear, change, abortion, cup, partner, flow', 'detectedIntruder': 'abortion', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'success': 1}, '1': {'top 5 sample': ['make', 'good', 'feel', 'lot', 'start'], 'intruder': 'abortion', 'wordlist': ['make', 'lot', 'feel', 'abortion', 'good', 'start'], 'wordliststr': 'make, lot, feel, abortion, good, start', 'detectedIntruder': 'abortion', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'success': 1}, '2': {'top 5 sample': ['hospital', 'epidural', 'plan', 'contraction', 'section'], 'intruder': 'abortion', 'wordlist': ['contraction', 'epidural', 'abortion', 'plan', 'hospital', 'section'], 'wordliststr': 'contraction, epidural, abortion, plan, hospital, section', 'detectedIntruder': 'contraction', 'rawLLMOP': 'The least relate...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>{'0': {'top 5 sample': ['cup', 'flow', 'partner', 'wear', 'change'], 'wordliststr': 'wear, change, abortion, cup, partner, flow', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'intruder': 'abortion', 'detectedIntruder': 'abortion', 'success': 1}, '1': {'top 5 sample': ['make', 'good', 'feel', 'lot', 'start'], 'wordliststr': 'make, lot, feel, abortion, good, start', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'intruder': 'abortion', 'detectedIntruder': 'abortion', 'success': 1}, '2': {'top 5 sample': ['hospital', 'epidural', 'plan', 'contraction', 'section'], 'wordliststr': 'contraction, epidural, abortion, plan, hospital, section', 'rawLLMOP': 'The least related word in this set is: 000contraction000', 'intruder': 'abortion', 'detectedIntruder': 'contraction', 'success': 0}, '3': {'top 5 sample': ['make', 'risk', 'result', 'blood', 'year'], 'wordliststr': 'risk, abortion, result, year, blood, make', 'rawLLMOP': 'The least related word...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'0': {'top 5 sample': ['pregnancy', 'early', 'thing', 'pregnant', 'time'], 'intruder': 'tampon', 'wordlist': ['time', 'thing', 'pregnant', 'early', 'tampon', 'pregnancy'], 'wordliststr': 'time, thing, pregnant, early, tampon, pregnancy', 'detectedIntruder': 'thing', 'rawLLMOP': 'The least related word in this set is: 000thing000', 'success': 0}, '1': {'top 5 sample': ['doctor', 'start', 'week', 'check', 'thing'], 'intruder': 'tampon', 'wordlist': ['tampon', 'start', 'check', 'doctor', 'week', 'thing'], 'wordliststr': 'tampon, start, check, doctor, week, thing', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: tampon', 'success': 0}, '2': {'top 5 sample': ['tampon', 'blood', 'bit', 'cup', 'pad'], 'intruder': 'doctor', 'wordlist': ['bit', 'blood', 'tampon', 'pad', 'cup', 'doctor'], 'wordliststr': 'bit, blood, tampon, pad, cup, doctor', 'detectedIntruder': 'doctor', 'rawLLMOP': 'The least related word in this set is: 000doctor000', 'success': 1},...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['pregnancy', 'early', 'thing', 'pregnant', 'time'], 'intruder': 'tampon', 'wordlist': ['time', 'thing', 'pregnant', 'early', 'tampon', 'pregnancy'], 'wordliststr': 'time, thing, pregnant, early, tampon, pregnancy', 'detectedIntruder': 'thing', 'rawLLMOP': 'The least related word in this set is: 000thing000', 'success': 0}, '1': {'top 5 sample': ['doctor', 'start', 'week', 'check', 'thing'], 'intruder': 'tampon', 'wordlist': ['tampon', 'start', 'check', 'doctor', 'week', 'thing'], 'wordliststr': 'tampon, start, check, doctor, week, thing', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: tampon', 'success': 0}, '2': {'top 5 sample': ['tampon', 'blood', 'bit', 'cup', 'pad'], 'intruder': 'doctor', 'wordlist': ['bit', 'blood', 'tampon', 'pad', 'cup', 'doctor'], 'wordliststr': 'bit, blood, tampon, pad, cup, doctor', 'detectedIntruder': 'doctor', 'rawLLMOP': 'The least related word in this set is: 000doctor000', 'success': 1},...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{'0': {'top 5 sample': ['pregnancy', 'early', 'thing', 'pregnant', 'time'], 'wordliststr': 'time, thing, pregnant, early, tampon, pregnancy', 'rawLLMOP': 'The least related word in this set is: 000thing000', 'intruder': 'tampon', 'detectedIntruder': 'thing', 'success': 0}, '1': {'top 5 sample': ['doctor', 'start', 'week', 'check', 'thing'], 'wordliststr': 'tampon, start, check, doctor, week, thing', 'rawLLMOP': 'The least related word in this set is: tampon', 'intruder': 'tampon', 'detectedIntruder': 'NOTDETECTED', 'success': 0}, '2': {'top 5 sample': ['tampon', 'blood', 'bit', 'cup', 'pad'], 'wordliststr': 'bit, blood, tampon, pad, cup, doctor', 'rawLLMOP': 'The least related word in this set is: 000doctor000', 'intruder': 'doctor', 'detectedIntruder': 'doctor', 'success': 1}, '3': {'top 5 sample': ['abortion', 'person', 'people', 'child', 'human'], 'wordliststr': 'doctor, child, person, human, abortion, people', 'rawLLMOP': 'The least related word in this set is: 000abortion000',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.20</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'top 5 sample': ['control', 'pill', 'take', 'day', 'side_effect'], 'intruder': 'bad', 'wordlist': ['pill', 'control', 'bad', 'day', 'side_effect', 'take'], 'wordliststr': 'pill, control, bad, day, side_effect, take', 'detectedIntruder': 'day', 'rawLLMOP': 'The least related word in this set is: 000day000', 'success': 0}, '1': {'top 5 sample': ['time', 'baby', 'give', 'hard', 'breastfeed'], 'intruder': 'period', 'wordlist': ['give', 'breastfeed', 'baby', 'hard', 'period', 'time'], 'wordliststr': 'give, breastfeed, baby, hard, period, time', 'detectedIntruder': 'period', 'rawLLMOP': 'The least related word in this set is: 000period000', 'success': 1}, '2': {'top 5 sample': ['pregnancy', 'week', 'doctor', 'gain', 'pregnant'], 'intruder': 'day', 'wordlist': ['pregnant', 'day', 'doctor', 'week', 'pregnancy', 'gain'], 'wordliststr': 'pregnant, day, doctor, week, pregnancy, gain', 'detectedIntruder': 'day', 'rawLLMOP': 'The least related word in this set is: 000day000', 'success': ...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['control', 'pill', 'take', 'day', 'side_effect'], 'intruder': 'bad', 'wordlist': ['pill', 'control', 'bad', 'day', 'side_effect', 'take'], 'wordliststr': 'pill, control, bad, day, side_effect, take', 'detectedIntruder': 'day', 'rawLLMOP': 'The least related word in this set is: 000day000', 'success': 0}, '1': {'top 5 sample': ['time', 'baby', 'give', 'hard', 'breastfeed'], 'intruder': 'period', 'wordlist': ['give', 'breastfeed', 'baby', 'hard', 'period', 'time'], 'wordliststr': 'give, breastfeed, baby, hard, period, time', 'detectedIntruder': 'period', 'rawLLMOP': 'The least related word in this set is: 000period000', 'success': 1}, '2': {'top 5 sample': ['pregnancy', 'week', 'doctor', 'gain', 'pregnant'], 'intruder': 'day', 'wordlist': ['pregnant', 'day', 'doctor', 'week', 'pregnancy', 'gain'], 'wordliststr': 'pregnant, day, doctor, week, pregnancy, gain', 'detectedIntruder': 'day', 'rawLLMOP': 'The least related word in this set is: 000day000', 'success': ...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>{'0': {'top 5 sample': ['control', 'pill', 'take', 'day', 'side_effect'], 'wordliststr': 'pill, control, bad, day, side_effect, take', 'rawLLMOP': 'The least related word in this set is: 000day000', 'intruder': 'bad', 'detectedIntruder': 'day', 'success': 0}, '1': {'top 5 sample': ['time', 'baby', 'give', 'hard', 'breastfeed'], 'wordliststr': 'give, breastfeed, baby, hard, period, time', 'rawLLMOP': 'The least related word in this set is: 000period000', 'intruder': 'period', 'detectedIntruder': 'period', 'success': 1}, '2': {'top 5 sample': ['pregnancy', 'week', 'doctor', 'gain', 'pregnant'], 'wordliststr': 'pregnant, day, doctor, week, pregnancy, gain', 'rawLLMOP': 'The least related word in this set is: 000day000', 'intruder': 'day', 'detectedIntruder': 'day', 'success': 1}, '3': {'top 5 sample': ['lot', 'good', 'doctor', 'test', 'common'], 'wordliststr': 'day, test, lot, common, doctor, good', 'rawLLMOP': 'The least related word in this set is: 000doctor000', 'intruder': 'day', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.15</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{'0': {'top 5 sample': ['good', 'time', 'feel', 'pain', 'thing'], 'intruder': 'week', 'wordlist': ['thing', 'good', 'week', 'time', 'pain', 'feel'], 'wordliststr': 'thing, good, week, time, pain, feel', 'detectedIntruder': 'pain', 'rawLLMOP': 'The least related word in this set is: 000pain000', 'success': 0}, '1': {'top 5 sample': ['water', 'infection', 'doctor', 'make', 'yeast_infection'], 'intruder': 'week', 'wordlist': ['doctor', 'make', 'yeast_infection', 'water', 'week', 'infection'], 'wordliststr': 'doctor, make, yeast_infection, water, week, infection', 'detectedIntruder': 'water', 'rawLLMOP': 'The least related word in this set is: 000water000', 'success': 0}, '2': {'top 5 sample': ['midwife', 'trimester', 'woman', 'class', 'medical'], 'intruder': 'week', 'wordlist': ['medical', 'trimester', 'class', 'midwife', 'woman', 'week'], 'wordliststr': 'medical, trimester, class, midwife, woman, week', 'detectedIntruder': 'class', 'rawLLMOP': 'The least related word in this set is: ...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['good', 'time', 'feel', 'pain', 'thing'], 'intruder': 'week', 'wordlist': ['thing', 'good', 'week', 'time', 'pain', 'feel'], 'wordliststr': 'thing, good, week, time, pain, feel', 'detectedIntruder': 'pain', 'rawLLMOP': 'The least related word in this set is: 000pain000', 'success': 0}, '1': {'top 5 sample': ['water', 'infection', 'doctor', 'make', 'yeast_infection'], 'intruder': 'week', 'wordlist': ['doctor', 'make', 'yeast_infection', 'water', 'week', 'infection'], 'wordliststr': 'doctor, make, yeast_infection, water, week, infection', 'detectedIntruder': 'water', 'rawLLMOP': 'The least related word in this set is: 000water000', 'success': 0}, '2': {'top 5 sample': ['midwife', 'trimester', 'woman', 'class', 'medical'], 'intruder': 'week', 'wordlist': ['medical', 'trimester', 'class', 'midwife', 'woman', 'week'], 'wordliststr': 'medical, trimester, class, midwife, woman, week', 'detectedIntruder': 'class', 'rawLLMOP': 'The least related word in this set is: ...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'0': {'top 5 sample': ['good', 'time', 'feel', 'pain', 'thing'], 'wordliststr': 'thing, good, week, time, pain, feel', 'rawLLMOP': 'The least related word in this set is: 000pain000', 'intruder': 'week', 'detectedIntruder': 'pain', 'success': 0}, '1': {'top 5 sample': ['water', 'infection', 'doctor', 'make', 'yeast_infection'], 'wordliststr': 'doctor, make, yeast_infection, water, week, infection', 'rawLLMOP': 'The least related word in this set is: 000water000', 'intruder': 'week', 'detectedIntruder': 'water', 'success': 0}, '2': {'top 5 sample': ['midwife', 'trimester', 'woman', 'class', 'medical'], 'wordliststr': 'medical, trimester, class, midwife, woman, week', 'rawLLMOP': 'The least related word in this set is: 000class000', 'intruder': 'week', 'detectedIntruder': 'class', 'success': 0}, '3': {'top 5 sample': ['woman', 'life', 'abortion', 'baby', 'human'], 'wordliststr': 'human, abortion, life, week, baby, woman', 'rawLLMOP': 'The least related word in this set is: 000week00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'top 5 sample': ['feel', 'time', 'ultrasound', 'weight', 'start'], 'intruder': 'period', 'wordlist': ['time', 'feel', 'start', 'weight', 'period', 'ultrasound'], 'wordliststr': 'time, feel, start, weight, period, ultrasound', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: 'ultrasound'.', 'success': 0}, '1': {'top 5 sample': ['bleed', 'cramp', 'mirena', 'spot', 'month'], 'intruder': 'week', 'wordlist': ['spot', 'cramp', 'week', 'mirena', 'month', 'bleed'], 'wordliststr': 'spot, cramp, week, mirena, month, bleed', 'detectedIntruder': 'cramp', 'rawLLMOP': 'The least related word in this set is: 000cramp000', 'success': 0}, '2': {'top 5 sample': ['painful', 'hurt', 'pressure', 'uncomfortable', 'doctor'], 'intruder': 'week', 'wordlist': ['doctor', 'pressure', 'hurt', 'uncomfortable', 'painful', 'week'], 'wordliststr': 'doctor, pressure, hurt, uncomfortable, painful, week', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in t...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['feel', 'time', 'ultrasound', 'weight', 'start'], 'intruder': 'period', 'wordlist': ['time', 'feel', 'start', 'weight', 'period', 'ultrasound'], 'wordliststr': 'time, feel, start, weight, period, ultrasound', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: 'ultrasound'.', 'success': 0}, '1': {'top 5 sample': ['bleed', 'cramp', 'mirena', 'spot', 'month'], 'intruder': 'week', 'wordlist': ['spot', 'cramp', 'week', 'mirena', 'month', 'bleed'], 'wordliststr': 'spot, cramp, week, mirena, month, bleed', 'detectedIntruder': 'cramp', 'rawLLMOP': 'The least related word in this set is: 000cramp000', 'success': 0}, '2': {'top 5 sample': ['painful', 'hurt', 'pressure', 'uncomfortable', 'doctor'], 'intruder': 'week', 'wordlist': ['doctor', 'pressure', 'hurt', 'uncomfortable', 'painful', 'week'], 'wordliststr': 'doctor, pressure, hurt, uncomfortable, painful, week', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in t...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>{'0': {'top 5 sample': ['feel', 'time', 'ultrasound', 'weight', 'start'], 'wordliststr': 'time, feel, start, weight, period, ultrasound', 'rawLLMOP': 'The least related word in this set is: 'ultrasound'.', 'intruder': 'period', 'detectedIntruder': 'ultrasound', 'success': 0}, '1': {'top 5 sample': ['bleed', 'cramp', 'mirena', 'spot', 'month'], 'wordliststr': 'spot, cramp, week, mirena, month, bleed', 'rawLLMOP': 'The least related word in this set is: 000cramp000', 'intruder': 'week', 'detectedIntruder': 'cramp', 'success': 0}, '2': {'top 5 sample': ['painful', 'hurt', 'pressure', 'uncomfortable', 'doctor'], 'wordliststr': 'doctor, pressure, hurt, uncomfortable, painful, week', 'rawLLMOP': 'The least related word in this set is: 000week000', 'intruder': 'week', 'detectedIntruder': 'week', 'success': 1}, '3': {'top 5 sample': ['remove', 'bathroom', 'mine', 'position', 'pull'], 'wordliststr': 'bathroom, mine, position, week, pull, remove', 'rawLLMOP': 'The least related word in this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'0': {'top 5 sample': ['pad', 'sex', 'clean', 'yeast_infection', 'buy'], 'intruder': 'labor', 'wordlist': ['pad', 'clean', 'sex', 'buy', 'yeast_infection', 'labor'], 'wordliststr': 'pad, clean, sex, buy, yeast_infection, labor', 'detectedIntruder': 'sex', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'success': 0}, '1': {'top 5 sample': ['feel', 'hour', 'make', 'week', 'nurse'], 'intruder': 'contraction', 'wordlist': ['week', 'make', 'contraction', 'hour', 'nurse', 'feel'], 'wordliststr': 'week, make, contraction, hour, nurse, feel', 'detectedIntruder': 'contraction', 'rawLLMOP': 'The least related word in this set is: 000contraction000', 'success': 1}, '2': {'top 5 sample': ['week', 'hospital', 'maternity', 'feel', 'baby'], 'intruder': 'contraction', 'wordlist': ['hospital', 'maternity', 'baby', 'week', 'contraction', 'feel'], 'wordliststr': 'hospital, maternity, baby, week, contraction, feel', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in t...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['pad', 'sex', 'clean', 'yeast_infection', 'buy'], 'intruder': 'labor', 'wordlist': ['pad', 'clean', 'sex', 'buy', 'yeast_infection', 'labor'], 'wordliststr': 'pad, clean, sex, buy, yeast_infection, labor', 'detectedIntruder': 'sex', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'success': 0}, '1': {'top 5 sample': ['feel', 'hour', 'make', 'week', 'nurse'], 'intruder': 'contraction', 'wordlist': ['week', 'make', 'contraction', 'hour', 'nurse', 'feel'], 'wordliststr': 'week, make, contraction, hour, nurse, feel', 'detectedIntruder': 'contraction', 'rawLLMOP': 'The least related word in this set is: 000contraction000', 'success': 1}, '2': {'top 5 sample': ['week', 'hospital', 'maternity', 'feel', 'baby'], 'intruder': 'contraction', 'wordlist': ['hospital', 'maternity', 'baby', 'week', 'contraction', 'feel'], 'wordliststr': 'hospital, maternity, baby, week, contraction, feel', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in t...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>{'0': {'top 5 sample': ['pad', 'sex', 'clean', 'yeast_infection', 'buy'], 'wordliststr': 'pad, clean, sex, buy, yeast_infection, labor', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'intruder': 'labor', 'detectedIntruder': 'sex', 'success': 0}, '1': {'top 5 sample': ['feel', 'hour', 'make', 'week', 'nurse'], 'wordliststr': 'week, make, contraction, hour, nurse, feel', 'rawLLMOP': 'The least related word in this set is: 000contraction000', 'intruder': 'contraction', 'detectedIntruder': 'contraction', 'success': 1}, '2': {'top 5 sample': ['week', 'hospital', 'maternity', 'feel', 'baby'], 'wordliststr': 'hospital, maternity, baby, week, contraction, feel', 'rawLLMOP': 'The least related word in this set is: 000week000', 'intruder': 'contraction', 'detectedIntruder': 'week', 'success': 0}, '3': {'top 5 sample': ['time', 'baby', 'doctor', 'birth', 'woman'], 'wordliststr': 'labor, time, birth, woman, baby, doctor', 'rawLLMOP': 'The least related word in this set is: 00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.20</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'0': {'top 5 sample': ['week', 'doctor', 'day', 'pregnant', 'early'], 'intruder': 'tampon', 'wordlist': ['doctor', 'pregnant', 'tampon', 'week', 'day', 'early'], 'wordliststr': 'doctor, pregnant, tampon, week, day, early', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 1}, '1': {'top 5 sample': ['find', 'midwife', 'size', 'good', 'check'], 'intruder': 'tampon', 'wordlist': ['midwife', 'size', 'find', 'check', 'good', 'tampon'], 'wordliststr': 'midwife, size, find, check, good, tampon', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 1}, '2': {'top 5 sample': ['tampon', 'flow', 'change', 'wear', 'day'], 'intruder': 'doctor', 'wordlist': ['doctor', 'day', 'tampon', 'change', 'wear', 'flow'], 'wordliststr': 'doctor, day, tampon, change, wear, flow', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 0}, '3': ...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['week', 'doctor', 'day', 'pregnant', 'early'], 'intruder': 'tampon', 'wordlist': ['doctor', 'pregnant', 'tampon', 'week', 'day', 'early'], 'wordliststr': 'doctor, pregnant, tampon, week, day, early', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 1}, '1': {'top 5 sample': ['find', 'midwife', 'size', 'good', 'check'], 'intruder': 'tampon', 'wordlist': ['midwife', 'size', 'find', 'check', 'good', 'tampon'], 'wordliststr': 'midwife, size, find, check, good, tampon', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 1}, '2': {'top 5 sample': ['tampon', 'flow', 'change', 'wear', 'day'], 'intruder': 'doctor', 'wordlist': ['doctor', 'day', 'tampon', 'change', 'wear', 'flow'], 'wordliststr': 'doctor, day, tampon, change, wear, flow', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 0}, '3': ...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>{'0': {'top 5 sample': ['week', 'doctor', 'day', 'pregnant', 'early'], 'wordliststr': 'doctor, pregnant, tampon, week, day, early', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'intruder': 'tampon', 'detectedIntruder': 'tampon', 'success': 1}, '1': {'top 5 sample': ['find', 'midwife', 'size', 'good', 'check'], 'wordliststr': 'midwife, size, find, check, good, tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'intruder': 'tampon', 'detectedIntruder': 'tampon', 'success': 1}, '2': {'top 5 sample': ['tampon', 'flow', 'change', 'wear', 'day'], 'wordliststr': 'doctor, day, tampon, change, wear, flow', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'intruder': 'doctor', 'detectedIntruder': 'tampon', 'success': 0}, '3': {'top 5 sample': ['leave', 'baby', 'work', 'kick', 'trimester'], 'wordliststr': 'work, trimester, baby, find, kick, leave', 'rawLLMOP': 'The least related word in this set is: 000kick000', 'intruder': 'fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{'0': {'top 5 sample': ['period', 'pill', 'pack', 'day', 'side_effect'], 'intruder': 'feel', 'wordlist': ['day', 'pill', 'side_effect', 'feel', 'period', 'pack'], 'wordliststr': 'day, pill, side_effect, feel, period, pack', 'detectedIntruder': 'side_effect', 'rawLLMOP': 'The least related word in this set is: 000side_effect000', 'success': 0}, '1': {'top 5 sample': ['breastfeed', 'baby', 'formula', 'eat', 'feed'], 'intruder': 'back', 'wordlist': ['eat', 'feed', 'baby', 'back', 'breastfeed', 'formula'], 'wordliststr': 'eat, feed, baby, back, breastfeed, formula', 'detectedIntruder': 'back', 'rawLLMOP': 'The least related word in this set is: 000back000', 'success': 1}, '2': {'top 5 sample': ['gain', 'week', 'weight', 'doctor', 'start'], 'intruder': 'bit', 'wordlist': ['doctor', 'gain', 'bit', 'start', 'weight', 'week'], 'wordliststr': 'doctor, gain, bit, start, weight, week', 'detectedIntruder': 'bit', 'rawLLMOP': 'The least related word in this set is: 000bit000', 'success': 1}, '3...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['period', 'pill', 'pack', 'day', 'side_effect'], 'intruder': 'feel', 'wordlist': ['day', 'pill', 'side_effect', 'feel', 'period', 'pack'], 'wordliststr': 'day, pill, side_effect, feel, period, pack', 'detectedIntruder': 'side_effect', 'rawLLMOP': 'The least related word in this set is: 000side_effect000', 'success': 0}, '1': {'top 5 sample': ['breastfeed', 'baby', 'formula', 'eat', 'feed'], 'intruder': 'back', 'wordlist': ['eat', 'feed', 'baby', 'back', 'breastfeed', 'formula'], 'wordliststr': 'eat, feed, baby, back, breastfeed, formula', 'detectedIntruder': 'back', 'rawLLMOP': 'The least related word in this set is: 000back000', 'success': 1}, '2': {'top 5 sample': ['gain', 'week', 'weight', 'doctor', 'start'], 'intruder': 'bit', 'wordlist': ['doctor', 'gain', 'bit', 'start', 'weight', 'week'], 'wordliststr': 'doctor, gain, bit, start, weight, week', 'detectedIntruder': 'bit', 'rawLLMOP': 'The least related word in this set is: 000bit000', 'success': 1}, '3...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>{'0': {'top 5 sample': ['period', 'pill', 'pack', 'day', 'side_effect'], 'wordliststr': 'day, pill, side_effect, feel, period, pack', 'rawLLMOP': 'The least related word in this set is: 000side_effect000', 'intruder': 'feel', 'detectedIntruder': 'side_effect', 'success': 0}, '1': {'top 5 sample': ['breastfeed', 'baby', 'formula', 'eat', 'feed'], 'wordliststr': 'eat, feed, baby, back, breastfeed, formula', 'rawLLMOP': 'The least related word in this set is: 000back000', 'intruder': 'back', 'detectedIntruder': 'back', 'success': 1}, '2': {'top 5 sample': ['gain', 'week', 'weight', 'doctor', 'start'], 'wordliststr': 'doctor, gain, bit, start, weight, week', 'rawLLMOP': 'The least related word in this set is: 000bit000', 'intruder': 'bit', 'detectedIntruder': 'bit', 'success': 1}, '3': {'top 5 sample': ['push', 'labor', 'section', 'epidural', 'natural'], 'wordliststr': 'push, natural, epidural, start, section, labor', 'rawLLMOP': 'The least related word in this set is: 000epidural000',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['delay_clamp', 'due_date_buddy', 'horrendous', 'cutip', 'shield'], 'intruder': 'lotion', 'wordlist': ['lotion', 'shield', 'delay_clamp', 'due_date_buddy', 'horrendous', 'cutip'], 'wordliststr': 'lotion, shield, delay_clamp, due_date_buddy, horrendous, cutip', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: horrendous', 'success': 0}, '1': {'top 5 sample': ['offense', 'assault', 'battery', 'unpermitted', 'harmful_offensive'], 'intruder': 'slippage', 'wordlist': ['battery', 'assault', 'harmful_offensive', 'slippage', 'offense', 'unpermitted'], 'wordliststr': 'battery, assault, harmful_offensive, slippage, offense, unpermitted', 'detectedIntruder': 'assault', 'rawLLMOP': 'The least related word in this set is: 000assault000', 'success': 0}, '2': {'top 5 sample': ['extender', 'due_date_buddy', 'horrendous', 'literally', 'strapon'], 'intruder': 'destine', 'wordlist': ['destine', 'strapon', 'literally', 'extender', 'horrendou...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['delay_clamp', 'due_date_buddy', 'horrendous', 'cutip', 'shield'], 'intruder': 'lotion', 'wordlist': ['lotion', 'shield', 'delay_clamp', 'due_date_buddy', 'horrendous', 'cutip'], 'wordliststr': 'lotion, shield, delay_clamp, due_date_buddy, horrendous, cutip', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: horrendous', 'success': 0}, '1': {'top 5 sample': ['offense', 'assault', 'battery', 'unpermitted', 'harmful_offensive'], 'intruder': 'slippage', 'wordlist': ['battery', 'assault', 'harmful_offensive', 'slippage', 'offense', 'unpermitted'], 'wordliststr': 'battery, assault, harmful_offensive, slippage, offense, unpermitted', 'detectedIntruder': 'assault', 'rawLLMOP': 'The least related word in this set is: 000assault000', 'success': 0}, '2': {'top 5 sample': ['extender', 'due_date_buddy', 'horrendous', 'literally', 'strapon'], 'intruder': 'destine', 'wordlist': ['destine', 'strapon', 'literally', 'extender', 'horrendou...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{'0': {'top 5 sample': ['delay_clamp', 'due_date_buddy', 'horrendous', 'cutip', 'shield'], 'wordliststr': 'lotion, shield, delay_clamp, due_date_buddy, horrendous, cutip', 'rawLLMOP': 'The least related word in this set is: horrendous', 'intruder': 'lotion', 'detectedIntruder': 'NOTDETECTED', 'success': 0}, '1': {'top 5 sample': ['offense', 'assault', 'battery', 'unpermitted', 'harmful_offensive'], 'wordliststr': 'battery, assault, harmful_offensive, slippage, offense, unpermitted', 'rawLLMOP': 'The least related word in this set is: 000assault000', 'intruder': 'slippage', 'detectedIntruder': 'assault', 'success': 0}, '2': {'top 5 sample': ['extender', 'due_date_buddy', 'horrendous', 'literally', 'strapon'], 'wordliststr': 'destine, strapon, literally, extender, horrendous, due_date_buddy', 'rawLLMOP': 'The least related word in this set is: 000strapon000', 'intruder': 'destine', 'detectedIntruder': 'strapon', 'success': 0}, '3': {'top 5 sample': ['colonoscopy', 'ulcerative', 'gast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['smp', 'lange', 'donate_cord', 'cutip', 'due_date_buddy'], 'intruder': 'stretch_mark', 'wordlist': ['stretch_mark', 'smp', 'donate_cord', 'due_date_buddy', 'lange', 'cutip'], 'wordliststr': 'stretch_mark, smp, donate_cord, due_date_buddy, lange, cutip', 'detectedIntruder': 'smoothing_iron', 'rawLLMOP': 'The least related word in this set is: 000smoothing_iron000', 'success': 0}, '1': {'top 5 sample': ['shield', 'stretch_mark', 'slippage', 'delay_clamp', 'due_date_buddy'], 'intruder': 'hydrogel', 'wordlist': ['stretch_mark', 'due_date_buddy', 'shield', 'delay_clamp', 'hydrogel', 'slippage'], 'wordliststr': 'stretch_mark, due_date_buddy, shield, delay_clamp, hydrogel, slippage', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '2': {'top 5 sample': ['minor', 'unconsente', 'cut', 'circumcise', 'ceremony'], 'intruder': 'kilogram', 'wordlist': ['circumcise', 'minor', 'kilogram', 'ceremony', 'unconsent...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['smp', 'lange', 'donate_cord', 'cutip', 'due_date_buddy'], 'intruder': 'stretch_mark', 'wordlist': ['stretch_mark', 'smp', 'donate_cord', 'due_date_buddy', 'lange', 'cutip'], 'wordliststr': 'stretch_mark, smp, donate_cord, due_date_buddy, lange, cutip', 'detectedIntruder': 'smoothing_iron', 'rawLLMOP': 'The least related word in this set is: 000smoothing_iron000', 'success': 0}, '1': {'top 5 sample': ['shield', 'stretch_mark', 'slippage', 'delay_clamp', 'due_date_buddy'], 'intruder': 'hydrogel', 'wordlist': ['stretch_mark', 'due_date_buddy', 'shield', 'delay_clamp', 'hydrogel', 'slippage'], 'wordliststr': 'stretch_mark, due_date_buddy, shield, delay_clamp, hydrogel, slippage', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '2': {'top 5 sample': ['minor', 'unconsente', 'cut', 'circumcise', 'ceremony'], 'intruder': 'kilogram', 'wordlist': ['circumcise', 'minor', 'kilogram', 'ceremony', 'unconsent...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>{'0': {'top 5 sample': ['smp', 'lange', 'donate_cord', 'cutip', 'due_date_buddy'], 'wordliststr': 'stretch_mark, smp, donate_cord, due_date_buddy, lange, cutip', 'rawLLMOP': 'The least related word in this set is: 000smoothing_iron000', 'intruder': 'stretch_mark', 'detectedIntruder': 'smoothing_iron', 'success': 0}, '1': {'top 5 sample': ['shield', 'stretch_mark', 'slippage', 'delay_clamp', 'due_date_buddy'], 'wordliststr': 'stretch_mark, due_date_buddy, shield, delay_clamp, hydrogel, slippage', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'intruder': 'hydrogel', 'detectedIntruder': 'shield', 'success': 0}, '2': {'top 5 sample': ['minor', 'unconsente', 'cut', 'circumcise', 'ceremony'], 'wordliststr': 'circumcise, minor, kilogram, ceremony, unconsente, cut', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'intruder': 'kilogram', 'detectedIntruder': 'kilogram', 'success': 1}, '3': {'top 5 sample': ['advanced', 'chub', 'ozzydog', 'swollen', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['criminal', 'due_date_buddy', 'threat', 'harmful_offensive', 'offense'], 'intruder': 'conduct', 'wordlist': ['criminal', 'due_date_buddy', 'harmful_offensive', 'conduct', 'threat', 'offense'], 'wordliststr': 'criminal, due_date_buddy, harmful_offensive, conduct, threat, offense', 'detectedIntruder': 'due_date_buddy', 'rawLLMOP': 'The least related word in this set is: 000due_date_buddy000', 'success': 0}, '1': {'top 5 sample': ['ovarian', 'hysterectomy', 'poly', 'cystic', 'smile'], 'intruder': 'conduct', 'wordlist': ['ovarian', 'conduct', 'smile', 'cystic', 'poly', 'hysterectomy'], 'wordliststr': 'ovarian, conduct, smile, cystic, poly, hysterectomy', 'detectedIntruder': 'smile', 'rawLLMOP': 'The least related word in this set is: 000smile000', 'success': 0}, '2': {'top 5 sample': ['ozzydog', 'lbs', 'jump', 'pitbull', 'yike'], 'intruder': 'conduct', 'wordlist': ['ozzydog', 'yike', 'jump', 'conduct', 'pitbull', 'lbs'], 'wordliststr': 'ozzydog, yike, jump, cond...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['criminal', 'due_date_buddy', 'threat', 'harmful_offensive', 'offense'], 'intruder': 'conduct', 'wordlist': ['criminal', 'due_date_buddy', 'harmful_offensive', 'conduct', 'threat', 'offense'], 'wordliststr': 'criminal, due_date_buddy, harmful_offensive, conduct, threat, offense', 'detectedIntruder': 'due_date_buddy', 'rawLLMOP': 'The least related word in this set is: 000due_date_buddy000', 'success': 0}, '1': {'top 5 sample': ['ovarian', 'hysterectomy', 'poly', 'cystic', 'smile'], 'intruder': 'conduct', 'wordlist': ['ovarian', 'conduct', 'smile', 'cystic', 'poly', 'hysterectomy'], 'wordliststr': 'ovarian, conduct, smile, cystic, poly, hysterectomy', 'detectedIntruder': 'smile', 'rawLLMOP': 'The least related word in this set is: 000smile000', 'success': 0}, '2': {'top 5 sample': ['ozzydog', 'lbs', 'jump', 'pitbull', 'yike'], 'intruder': 'conduct', 'wordlist': ['ozzydog', 'yike', 'jump', 'conduct', 'pitbull', 'lbs'], 'wordliststr': 'ozzydog, yike, jump, cond...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>{'0': {'top 5 sample': ['criminal', 'due_date_buddy', 'threat', 'harmful_offensive', 'offense'], 'wordliststr': 'criminal, due_date_buddy, harmful_offensive, conduct, threat, offense', 'rawLLMOP': 'The least related word in this set is: 000due_date_buddy000', 'intruder': 'conduct', 'detectedIntruder': 'due_date_buddy', 'success': 0}, '1': {'top 5 sample': ['ovarian', 'hysterectomy', 'poly', 'cystic', 'smile'], 'wordliststr': 'ovarian, conduct, smile, cystic, poly, hysterectomy', 'rawLLMOP': 'The least related word in this set is: 000smile000', 'intruder': 'conduct', 'detectedIntruder': 'smile', 'success': 0}, '2': {'top 5 sample': ['ozzydog', 'lbs', 'jump', 'pitbull', 'yike'], 'wordliststr': 'ozzydog, yike, jump, conduct, pitbull, lbs', 'rawLLMOP': 'The least related word in this set is: 000yike000', 'intruder': 'conduct', 'detectedIntruder': 'yike', 'success': 0}, '3': {'top 5 sample': ['due_date_buddy', 'slippage', 'smp', 'shield', 'delay_clamp'], 'wordliststr': 'smp, slippage, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'intruder': 'battery', 'wordlist': ['delay_clamp', 'horrendous', 'smp', 'shield', 'donate_cord', 'battery'], 'wordliststr': 'delay_clamp, horrendous, smp, shield, donate_cord, battery', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 0}, '1': {'top 5 sample': ['gastroscopy', 'rule', 'soother', 'colonoscopy', 'celiac_disease'], 'intruder': 'twosie', 'wordlist': ['soother', 'gastroscopy', 'colonoscopy', 'celiac_disease', 'rule', 'twosie'], 'wordliststr': 'soother, gastroscopy, colonoscopy, celiac_disease, rule, twosie', 'detectedIntruder': 'twosie', 'rawLLMOP': 'In this case, the least related word to all other words in terms of meaning is: 000twosie000', 'success': 1}, '2': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'intruder': 'battery', 'wordlist': ['donate_cord', 'horrendous', 'shield', 'smp'...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'intruder': 'battery', 'wordlist': ['delay_clamp', 'horrendous', 'smp', 'shield', 'donate_cord', 'battery'], 'wordliststr': 'delay_clamp, horrendous, smp, shield, donate_cord, battery', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 0}, '1': {'top 5 sample': ['gastroscopy', 'rule', 'soother', 'colonoscopy', 'celiac_disease'], 'intruder': 'twosie', 'wordlist': ['soother', 'gastroscopy', 'colonoscopy', 'celiac_disease', 'rule', 'twosie'], 'wordliststr': 'soother, gastroscopy, colonoscopy, celiac_disease, rule, twosie', 'detectedIntruder': 'twosie', 'rawLLMOP': 'In this case, the least related word to all other words in terms of meaning is: 000twosie000', 'success': 1}, '2': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'intruder': 'battery', 'wordlist': ['donate_cord', 'horrendous', 'shield', 'smp'...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>{'0': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'wordliststr': 'delay_clamp, horrendous, smp, shield, donate_cord, battery', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'battery', 'detectedIntruder': 'horrendous', 'success': 0}, '1': {'top 5 sample': ['gastroscopy', 'rule', 'soother', 'colonoscopy', 'celiac_disease'], 'wordliststr': 'soother, gastroscopy, colonoscopy, celiac_disease, rule, twosie', 'rawLLMOP': 'In this case, the least related word to all other words in terms of meaning is: 000twosie000', 'intruder': 'twosie', 'detectedIntruder': 'twosie', 'success': 1}, '2': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'wordliststr': 'donate_cord, horrendous, shield, smp, battery, delay_clamp', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'battery', 'detectedIntruder': 'horrendous', 'success': 0}, '3': {'top 5 sample': ['horrendous', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'intruder': 'germ', 'wordlist': ['due_date_buddy', 'delay_clamp', 'donate_cord', 'shield', 'germ', 'horrendous'], 'wordliststr': 'due_date_buddy, delay_clamp, donate_cord, shield, germ, horrendous', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 0}, '1': {'top 5 sample': ['baby', 'week', 'time', 'day', 'woman'], 'intruder': 'horrendous', 'wordlist': ['time', 'week', 'woman', 'day', 'baby', 'horrendous'], 'wordliststr': 'time, week, woman, day, baby, horrendous', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 1}, '2': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'intruder': 'germ', 'wordlist': ['delay_clamp', 'due_date_buddy', 'shield', 'germ', 'donate_cord', 'horrendous'], 'wordliststr': 'delay_clamp, due_...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'intruder': 'germ', 'wordlist': ['due_date_buddy', 'delay_clamp', 'donate_cord', 'shield', 'germ', 'horrendous'], 'wordliststr': 'due_date_buddy, delay_clamp, donate_cord, shield, germ, horrendous', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 0}, '1': {'top 5 sample': ['baby', 'week', 'time', 'day', 'woman'], 'intruder': 'horrendous', 'wordlist': ['time', 'week', 'woman', 'day', 'baby', 'horrendous'], 'wordliststr': 'time, week, woman, day, baby, horrendous', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 1}, '2': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'intruder': 'germ', 'wordlist': ['delay_clamp', 'due_date_buddy', 'shield', 'germ', 'donate_cord', 'horrendous'], 'wordliststr': 'delay_clamp, due_...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>{'0': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'wordliststr': 'due_date_buddy, delay_clamp, donate_cord, shield, germ, horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'germ', 'detectedIntruder': 'horrendous', 'success': 0}, '1': {'top 5 sample': ['baby', 'week', 'time', 'day', 'woman'], 'wordliststr': 'time, week, woman, day, baby, horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'horrendous', 'detectedIntruder': 'horrendous', 'success': 1}, '2': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'wordliststr': 'delay_clamp, due_date_buddy, shield, germ, donate_cord, horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'germ', 'detectedIntruder': 'horrendous', 'success': 0}, '3': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['hereditary', 'horrendous', 'kilogram', 'ozzydog', 'endometriosis'], 'intruder': 'week', 'wordlist': ['week', 'ozzydog', 'kilogram', 'horrendous', 'hereditary', 'endometriosis'], 'wordliststr': 'week, ozzydog, kilogram, horrendous, hereditary, endometriosis', 'detectedIntruder': 'ozzydog', 'rawLLMOP': 'The least related word in this set is: 000ozzydog000', 'success': 0}, '1': {'top 5 sample': ['ive', 'horrendous', 'kilogram', 'elastin', 'lotion'], 'intruder': 'mae', 'wordlist': ['elastin', 'ive', 'kilogram', 'mae', 'horrendous', 'lotion'], 'wordliststr': 'elastin, ive, kilogram, mae, horrendous, lotion', 'detectedIntruder': 'ive', 'rawLLMOP': 'The least related word in this set is: 000ive000', 'success': 0}, '2': {'top 5 sample': ['endometriosis', 'horrendous', 'kilogram', 'arthritis', 'lange'], 'intruder': 'week', 'wordlist': ['lange', 'arthritis', 'kilogram', 'endometriosis', 'week', 'horrendous'], 'wordliststr': 'lange, arthritis, kilogram, endometriosis,...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['hereditary', 'horrendous', 'kilogram', 'ozzydog', 'endometriosis'], 'intruder': 'week', 'wordlist': ['week', 'ozzydog', 'kilogram', 'horrendous', 'hereditary', 'endometriosis'], 'wordliststr': 'week, ozzydog, kilogram, horrendous, hereditary, endometriosis', 'detectedIntruder': 'ozzydog', 'rawLLMOP': 'The least related word in this set is: 000ozzydog000', 'success': 0}, '1': {'top 5 sample': ['ive', 'horrendous', 'kilogram', 'elastin', 'lotion'], 'intruder': 'mae', 'wordlist': ['elastin', 'ive', 'kilogram', 'mae', 'horrendous', 'lotion'], 'wordliststr': 'elastin, ive, kilogram, mae, horrendous, lotion', 'detectedIntruder': 'ive', 'rawLLMOP': 'The least related word in this set is: 000ive000', 'success': 0}, '2': {'top 5 sample': ['endometriosis', 'horrendous', 'kilogram', 'arthritis', 'lange'], 'intruder': 'week', 'wordlist': ['lange', 'arthritis', 'kilogram', 'endometriosis', 'week', 'horrendous'], 'wordliststr': 'lange, arthritis, kilogram, endometriosis,...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>{'0': {'top 5 sample': ['hereditary', 'horrendous', 'kilogram', 'ozzydog', 'endometriosis'], 'wordliststr': 'week, ozzydog, kilogram, horrendous, hereditary, endometriosis', 'rawLLMOP': 'The least related word in this set is: 000ozzydog000', 'intruder': 'week', 'detectedIntruder': 'ozzydog', 'success': 0}, '1': {'top 5 sample': ['ive', 'horrendous', 'kilogram', 'elastin', 'lotion'], 'wordliststr': 'elastin, ive, kilogram, mae, horrendous, lotion', 'rawLLMOP': 'The least related word in this set is: 000ive000', 'intruder': 'mae', 'detectedIntruder': 'ive', 'success': 0}, '2': {'top 5 sample': ['endometriosis', 'horrendous', 'kilogram', 'arthritis', 'lange'], 'wordliststr': 'lange, arthritis, kilogram, endometriosis, week, horrendous', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'intruder': 'week', 'detectedIntruder': 'kilogram', 'success': 0}, '3': {'top 5 sample': ['endometriosis', 'horrendous', 'kilogram', 'arthritis', 'lange'], 'wordliststr': 'lange, endo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['purposely', 'weapon', 'deadly', 'reputable', 'injury'], 'intruder': 'flair', 'wordlist': ['flair', 'reputable', 'deadly', 'injury', 'weapon', 'purposely'], 'wordliststr': 'flair, reputable, deadly, injury, weapon, purposely', 'detectedIntruder': 'injury', 'rawLLMOP': 'The least related word in this set is: 000injury000', 'success': 0}, '1': {'top 5 sample': ['hereditary', 'due_date_buddy', 'shield', 'arthritis', 'horrendous'], 'intruder': 'squirmy', 'wordlist': ['horrendous', 'arthritis', 'due_date_buddy', 'hereditary', 'shield', 'squirmy'], 'wordliststr': 'horrendous, arthritis, due_date_buddy, hereditary, shield, squirmy', 'detectedIntruder': 'squirmy', 'rawLLMOP': 'The least related word in this set is: 000squirmy000', 'success': 1}, '2': {'top 5 sample': ['lange', 'due_date_buddy', 'shield', 'ozzydog', 'horrendous'], 'intruder': 'squirmy', 'wordlist': ['shield', 'horrendous', 'ozzydog', 'squirmy', 'due_date_buddy', 'lange'], 'wordliststr': 'shield, horr...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['purposely', 'weapon', 'deadly', 'reputable', 'injury'], 'intruder': 'flair', 'wordlist': ['flair', 'reputable', 'deadly', 'injury', 'weapon', 'purposely'], 'wordliststr': 'flair, reputable, deadly, injury, weapon, purposely', 'detectedIntruder': 'injury', 'rawLLMOP': 'The least related word in this set is: 000injury000', 'success': 0}, '1': {'top 5 sample': ['hereditary', 'due_date_buddy', 'shield', 'arthritis', 'horrendous'], 'intruder': 'squirmy', 'wordlist': ['horrendous', 'arthritis', 'due_date_buddy', 'hereditary', 'shield', 'squirmy'], 'wordliststr': 'horrendous, arthritis, due_date_buddy, hereditary, shield, squirmy', 'detectedIntruder': 'squirmy', 'rawLLMOP': 'The least related word in this set is: 000squirmy000', 'success': 1}, '2': {'top 5 sample': ['lange', 'due_date_buddy', 'shield', 'ozzydog', 'horrendous'], 'intruder': 'squirmy', 'wordlist': ['shield', 'horrendous', 'ozzydog', 'squirmy', 'due_date_buddy', 'lange'], 'wordliststr': 'shield, horr...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>{'0': {'top 5 sample': ['purposely', 'weapon', 'deadly', 'reputable', 'injury'], 'wordliststr': 'flair, reputable, deadly, injury, weapon, purposely', 'rawLLMOP': 'The least related word in this set is: 000injury000', 'intruder': 'flair', 'detectedIntruder': 'injury', 'success': 0}, '1': {'top 5 sample': ['hereditary', 'due_date_buddy', 'shield', 'arthritis', 'horrendous'], 'wordliststr': 'horrendous, arthritis, due_date_buddy, hereditary, shield, squirmy', 'rawLLMOP': 'The least related word in this set is: 000squirmy000', 'intruder': 'squirmy', 'detectedIntruder': 'squirmy', 'success': 1}, '2': {'top 5 sample': ['lange', 'due_date_buddy', 'shield', 'ozzydog', 'horrendous'], 'wordliststr': 'shield, horrendous, ozzydog, squirmy, due_date_buddy, lange', 'rawLLMOP': 'The least related word in this set is: 000ozzydog000', 'intruder': 'squirmy', 'detectedIntruder': 'ozzydog', 'success': 0}, '3': {'top 5 sample': ['hereditary', 'due_date_buddy', 'arthritis', 'shield', 'horrendous'], 'wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['arthritis', 'hereditary', 'endometriosis', 'conduct', 'shield', 'due_date_buddy'], 'wordliststr': 'arthritis, hereditary, endometriosis, conduct, shield, due_date_buddy', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '1': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['arthritis', 'hereditary', 'conduct', 'due_date_buddy', 'endometriosis', 'shield'], 'wordliststr': 'arthritis, hereditary, conduct, due_date_buddy, endometriosis, shield', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '2': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['endometriosis', 'shield', 'due...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['arthritis', 'hereditary', 'endometriosis', 'conduct', 'shield', 'due_date_buddy'], 'wordliststr': 'arthritis, hereditary, endometriosis, conduct, shield, due_date_buddy', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '1': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['arthritis', 'hereditary', 'conduct', 'due_date_buddy', 'endometriosis', 'shield'], 'wordliststr': 'arthritis, hereditary, conduct, due_date_buddy, endometriosis, shield', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '2': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['endometriosis', 'shield', 'due...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>{'0': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'wordliststr': 'arthritis, hereditary, endometriosis, conduct, shield, due_date_buddy', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'intruder': 'conduct', 'detectedIntruder': 'shield', 'success': 0}, '1': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'wordliststr': 'arthritis, hereditary, conduct, due_date_buddy, endometriosis, shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'intruder': 'conduct', 'detectedIntruder': 'shield', 'success': 0}, '2': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'wordliststr': 'endometriosis, shield, due_date_buddy, arthritis, conduct, hereditary', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'intruder': 'conduct', 'detectedIntruder': 'shield', 'success': 0}, '3': {'top 5 sample': ['due_date_buddy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['kilogram', 'toxin', 'toxigenic', 'staph', 'agent'], 'intruder': 'mae', 'wordlist': ['staph', 'toxigenic', 'kilogram', 'agent', 'toxin', 'mae'], 'wordliststr': 'staph, toxigenic, kilogram, agent, toxin, mae', 'detectedIntruder': 'kilogram', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'success': 0}, '1': {'top 5 sample': ['kilogram', 'arthritis', 'stretch_mark', 'lange', 'endometriosis'], 'intruder': 'ovarian', 'wordlist': ['arthritis', 'stretch_mark', 'endometriosis', 'lange', 'ovarian', 'kilogram'], 'wordliststr': 'arthritis, stretch_mark, endometriosis, lange, ovarian, kilogram', 'detectedIntruder': 'lange', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'success': 0}, '2': {'top 5 sample': ['kilogram', 'lange', 'delay_clamp', 'endometriosis', 'hereditary'], 'intruder': 'ovarian', 'wordlist': ['ovarian', 'hereditary', 'delay_clamp', 'kilogram', 'lange', 'endometriosis'], 'wordliststr': 'ovarian, hereditary, delay...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['kilogram', 'toxin', 'toxigenic', 'staph', 'agent'], 'intruder': 'mae', 'wordlist': ['staph', 'toxigenic', 'kilogram', 'agent', 'toxin', 'mae'], 'wordliststr': 'staph, toxigenic, kilogram, agent, toxin, mae', 'detectedIntruder': 'kilogram', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'success': 0}, '1': {'top 5 sample': ['kilogram', 'arthritis', 'stretch_mark', 'lange', 'endometriosis'], 'intruder': 'ovarian', 'wordlist': ['arthritis', 'stretch_mark', 'endometriosis', 'lange', 'ovarian', 'kilogram'], 'wordliststr': 'arthritis, stretch_mark, endometriosis, lange, ovarian, kilogram', 'detectedIntruder': 'lange', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'success': 0}, '2': {'top 5 sample': ['kilogram', 'lange', 'delay_clamp', 'endometriosis', 'hereditary'], 'intruder': 'ovarian', 'wordlist': ['ovarian', 'hereditary', 'delay_clamp', 'kilogram', 'lange', 'endometriosis'], 'wordliststr': 'ovarian, hereditary, delay...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>{'0': {'top 5 sample': ['kilogram', 'toxin', 'toxigenic', 'staph', 'agent'], 'wordliststr': 'staph, toxigenic, kilogram, agent, toxin, mae', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'intruder': 'mae', 'detectedIntruder': 'kilogram', 'success': 0}, '1': {'top 5 sample': ['kilogram', 'arthritis', 'stretch_mark', 'lange', 'endometriosis'], 'wordliststr': 'arthritis, stretch_mark, endometriosis, lange, ovarian, kilogram', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'intruder': 'ovarian', 'detectedIntruder': 'lange', 'success': 0}, '2': {'top 5 sample': ['kilogram', 'lange', 'delay_clamp', 'endometriosis', 'hereditary'], 'wordliststr': 'ovarian, hereditary, delay_clamp, kilogram, lange, endometriosis', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'intruder': 'ovarian', 'detectedIntruder': 'lange', 'success': 0}, '3': {'top 5 sample': ['kilogram', 'lange', 'stretch_mark', 'endometriosis', 'hereditary'], 'wordliststr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{'0': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'shield'], 'intruder': 'mammogram', 'wordlist': ['horrendous', 'shield', 'kilogram', 'endometriosis', 'mammogram', 'lange'], 'wordliststr': 'horrendous, shield, kilogram, endometriosis, mammogram, lange', 'detectedIntruder': 'kilogram', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'success': 0}, '1': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'stretch_mark'], 'intruder': 'mammogram', 'wordlist': ['mammogram', 'stretch_mark', 'horrendous', 'endometriosis', 'lange', 'kilogram'], 'wordliststr': 'mammogram, stretch_mark, horrendous, endometriosis, lange, kilogram', 'detectedIntruder': 'lange', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'success': 0}, '2': {'top 5 sample': ['horrendous', 'kilogram', 'muggle_blood', 'lange', 'arthritis'], 'intruder': 'coat_factory', 'wordlist': ['kilogram', 'coat_factory', 'horrendous', 'arthritis', 'muggle...</td>\n",
       "      <td>gensim</td>\n",
       "      <td>{'0': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'shield'], 'intruder': 'mammogram', 'wordlist': ['horrendous', 'shield', 'kilogram', 'endometriosis', 'mammogram', 'lange'], 'wordliststr': 'horrendous, shield, kilogram, endometriosis, mammogram, lange', 'detectedIntruder': 'kilogram', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'success': 0}, '1': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'stretch_mark'], 'intruder': 'mammogram', 'wordlist': ['mammogram', 'stretch_mark', 'horrendous', 'endometriosis', 'lange', 'kilogram'], 'wordliststr': 'mammogram, stretch_mark, horrendous, endometriosis, lange, kilogram', 'detectedIntruder': 'lange', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'success': 0}, '2': {'top 5 sample': ['horrendous', 'kilogram', 'muggle_blood', 'lange', 'arthritis'], 'intruder': 'coat_factory', 'wordlist': ['kilogram', 'coat_factory', 'horrendous', 'arthritis', 'muggle...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>{'0': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'shield'], 'wordliststr': 'horrendous, shield, kilogram, endometriosis, mammogram, lange', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'intruder': 'mammogram', 'detectedIntruder': 'kilogram', 'success': 0}, '1': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'stretch_mark'], 'wordliststr': 'mammogram, stretch_mark, horrendous, endometriosis, lange, kilogram', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'intruder': 'mammogram', 'detectedIntruder': 'lange', 'success': 0}, '2': {'top 5 sample': ['horrendous', 'kilogram', 'muggle_blood', 'lange', 'arthritis'], 'wordliststr': 'kilogram, coat_factory, horrendous, arthritis, muggle_blood, lange', 'rawLLMOP': 'The least related word in this set is: 000coat_factory000', 'intruder': 'coat_factory', 'detectedIntruder': 'coat_factory', 'success': 1}, '3': {'top 5 sample': ['tad', 'surreal', 'anxious'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_topics  seed  score       alpha    eta  \\\n",
       "0           10  1928   0.50  asymmetric   0.01   \n",
       "1           10  3328   0.10          10   0.01   \n",
       "2           10  1062   0.40          10    NaN   \n",
       "3           10  3953   0.10          10   0.01   \n",
       "4           10  1172   0.20          10    NaN   \n",
       "5           20  1928   0.15  asymmetric   0.10   \n",
       "6           20  3328   0.35        0.01    NaN   \n",
       "7           20  1062   0.15          10    NaN   \n",
       "8           20  3953   0.20  asymmetric   0.01   \n",
       "9           20  1172   0.50          10   0.10   \n",
       "10          50  1928   0.10         0.1  10.00   \n",
       "11          50  3328   0.16         0.1  10.00   \n",
       "12          50  1062   0.20         0.1  10.00   \n",
       "13          50  3953   0.16         0.1  10.00   \n",
       "14          50  1172   0.20         0.1  10.00   \n",
       "15         100  1928   0.05         0.1  10.00   \n",
       "16         100  3328   0.34         0.1  10.00   \n",
       "17         100  1062   0.12         0.1  10.00   \n",
       "18         100  3953   0.04         0.1  10.00   \n",
       "19         100  1172   0.17         0.1  10.00   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tests  \\\n",
       "0   {'0': {'top 5 sample': ['start', 'time', 'feel', 'back', 'make'], 'intruder': 'baby', 'wordlist': ['back', 'make', 'feel', 'time', 'start', 'baby'], 'wordliststr': 'back, make, feel, time, start, baby', 'detectedIntruder': 'baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'success': 1}, '1': {'top 5 sample': ['blood', 'sex', 'doctor', 'problem', 'year'], 'intruder': 'week', 'wordlist': ['year', 'problem', 'doctor', 'sex', 'blood', 'week'], 'wordliststr': 'year, problem, doctor, sex, blood, week', 'detectedIntruder': 'sex', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'success': 0}, '2': {'top 5 sample': ['human', 'life', 'abortion', 'make', 'child'], 'intruder': 'week', 'wordlist': ['make', 'abortion', 'human', 'week', 'life', 'child'], 'wordliststr': 'make, abortion, human, week, life, child', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in this set is: 000week000', 'success': 1}, '3': {'top 5 sample': ['hour', 'labor', ...   \n",
       "1   {'0': {'top 5 sample': ['iud', 'month', 'bad', 'heavy', 'period'], 'intruder': 'make', 'wordlist': ['iud', 'bad', 'heavy', 'month', 'make', 'period'], 'wordliststr': 'iud, bad, heavy, month, make, period', 'detectedIntruder': 'iud', 'rawLLMOP': 'The least related word in this set is: 000iud000', 'success': 0}, '1': {'top 5 sample': ['give', 'time', 'thing', 'hard', 'baby'], 'intruder': 'period', 'wordlist': ['time', 'give', 'thing', 'baby', 'hard', 'period'], 'wordliststr': 'time, give, thing, baby, hard, period', 'detectedIntruder': 'baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'success': 0}, '2': {'top 5 sample': ['time', 'pain', 'cervix', 'check', 'doctor'], 'intruder': 'day', 'wordlist': ['check', 'cervix', 'day', 'pain', 'time', 'doctor'], 'wordliststr': 'check, cervix, day, pain, time, doctor', 'detectedIntruder': 'cervix', 'rawLLMOP': 'The least related word in this set is: 000cervix000', 'success': 0}, '3': {'top 5 sample': ['move', 'thing', 'good...   \n",
       "2   {'0': {'top 5 sample': ['cup', 'flow', 'partner', 'wear', 'change'], 'intruder': 'abortion', 'wordlist': ['wear', 'change', 'abortion', 'cup', 'partner', 'flow'], 'wordliststr': 'wear, change, abortion, cup, partner, flow', 'detectedIntruder': 'abortion', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'success': 1}, '1': {'top 5 sample': ['make', 'good', 'feel', 'lot', 'start'], 'intruder': 'abortion', 'wordlist': ['make', 'lot', 'feel', 'abortion', 'good', 'start'], 'wordliststr': 'make, lot, feel, abortion, good, start', 'detectedIntruder': 'abortion', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'success': 1}, '2': {'top 5 sample': ['hospital', 'epidural', 'plan', 'contraction', 'section'], 'intruder': 'abortion', 'wordlist': ['contraction', 'epidural', 'abortion', 'plan', 'hospital', 'section'], 'wordliststr': 'contraction, epidural, abortion, plan, hospital, section', 'detectedIntruder': 'contraction', 'rawLLMOP': 'The least relate...   \n",
       "3   {'0': {'top 5 sample': ['pregnancy', 'early', 'thing', 'pregnant', 'time'], 'intruder': 'tampon', 'wordlist': ['time', 'thing', 'pregnant', 'early', 'tampon', 'pregnancy'], 'wordliststr': 'time, thing, pregnant, early, tampon, pregnancy', 'detectedIntruder': 'thing', 'rawLLMOP': 'The least related word in this set is: 000thing000', 'success': 0}, '1': {'top 5 sample': ['doctor', 'start', 'week', 'check', 'thing'], 'intruder': 'tampon', 'wordlist': ['tampon', 'start', 'check', 'doctor', 'week', 'thing'], 'wordliststr': 'tampon, start, check, doctor, week, thing', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: tampon', 'success': 0}, '2': {'top 5 sample': ['tampon', 'blood', 'bit', 'cup', 'pad'], 'intruder': 'doctor', 'wordlist': ['bit', 'blood', 'tampon', 'pad', 'cup', 'doctor'], 'wordliststr': 'bit, blood, tampon, pad, cup, doctor', 'detectedIntruder': 'doctor', 'rawLLMOP': 'The least related word in this set is: 000doctor000', 'success': 1},...   \n",
       "4   {'0': {'top 5 sample': ['control', 'pill', 'take', 'day', 'side_effect'], 'intruder': 'bad', 'wordlist': ['pill', 'control', 'bad', 'day', 'side_effect', 'take'], 'wordliststr': 'pill, control, bad, day, side_effect, take', 'detectedIntruder': 'day', 'rawLLMOP': 'The least related word in this set is: 000day000', 'success': 0}, '1': {'top 5 sample': ['time', 'baby', 'give', 'hard', 'breastfeed'], 'intruder': 'period', 'wordlist': ['give', 'breastfeed', 'baby', 'hard', 'period', 'time'], 'wordliststr': 'give, breastfeed, baby, hard, period, time', 'detectedIntruder': 'period', 'rawLLMOP': 'The least related word in this set is: 000period000', 'success': 1}, '2': {'top 5 sample': ['pregnancy', 'week', 'doctor', 'gain', 'pregnant'], 'intruder': 'day', 'wordlist': ['pregnant', 'day', 'doctor', 'week', 'pregnancy', 'gain'], 'wordliststr': 'pregnant, day, doctor, week, pregnancy, gain', 'detectedIntruder': 'day', 'rawLLMOP': 'The least related word in this set is: 000day000', 'success': ...   \n",
       "5   {'0': {'top 5 sample': ['good', 'time', 'feel', 'pain', 'thing'], 'intruder': 'week', 'wordlist': ['thing', 'good', 'week', 'time', 'pain', 'feel'], 'wordliststr': 'thing, good, week, time, pain, feel', 'detectedIntruder': 'pain', 'rawLLMOP': 'The least related word in this set is: 000pain000', 'success': 0}, '1': {'top 5 sample': ['water', 'infection', 'doctor', 'make', 'yeast_infection'], 'intruder': 'week', 'wordlist': ['doctor', 'make', 'yeast_infection', 'water', 'week', 'infection'], 'wordliststr': 'doctor, make, yeast_infection, water, week, infection', 'detectedIntruder': 'water', 'rawLLMOP': 'The least related word in this set is: 000water000', 'success': 0}, '2': {'top 5 sample': ['midwife', 'trimester', 'woman', 'class', 'medical'], 'intruder': 'week', 'wordlist': ['medical', 'trimester', 'class', 'midwife', 'woman', 'week'], 'wordliststr': 'medical, trimester, class, midwife, woman, week', 'detectedIntruder': 'class', 'rawLLMOP': 'The least related word in this set is: ...   \n",
       "6   {'0': {'top 5 sample': ['feel', 'time', 'ultrasound', 'weight', 'start'], 'intruder': 'period', 'wordlist': ['time', 'feel', 'start', 'weight', 'period', 'ultrasound'], 'wordliststr': 'time, feel, start, weight, period, ultrasound', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: 'ultrasound'.', 'success': 0}, '1': {'top 5 sample': ['bleed', 'cramp', 'mirena', 'spot', 'month'], 'intruder': 'week', 'wordlist': ['spot', 'cramp', 'week', 'mirena', 'month', 'bleed'], 'wordliststr': 'spot, cramp, week, mirena, month, bleed', 'detectedIntruder': 'cramp', 'rawLLMOP': 'The least related word in this set is: 000cramp000', 'success': 0}, '2': {'top 5 sample': ['painful', 'hurt', 'pressure', 'uncomfortable', 'doctor'], 'intruder': 'week', 'wordlist': ['doctor', 'pressure', 'hurt', 'uncomfortable', 'painful', 'week'], 'wordliststr': 'doctor, pressure, hurt, uncomfortable, painful, week', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in t...   \n",
       "7   {'0': {'top 5 sample': ['pad', 'sex', 'clean', 'yeast_infection', 'buy'], 'intruder': 'labor', 'wordlist': ['pad', 'clean', 'sex', 'buy', 'yeast_infection', 'labor'], 'wordliststr': 'pad, clean, sex, buy, yeast_infection, labor', 'detectedIntruder': 'sex', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'success': 0}, '1': {'top 5 sample': ['feel', 'hour', 'make', 'week', 'nurse'], 'intruder': 'contraction', 'wordlist': ['week', 'make', 'contraction', 'hour', 'nurse', 'feel'], 'wordliststr': 'week, make, contraction, hour, nurse, feel', 'detectedIntruder': 'contraction', 'rawLLMOP': 'The least related word in this set is: 000contraction000', 'success': 1}, '2': {'top 5 sample': ['week', 'hospital', 'maternity', 'feel', 'baby'], 'intruder': 'contraction', 'wordlist': ['hospital', 'maternity', 'baby', 'week', 'contraction', 'feel'], 'wordliststr': 'hospital, maternity, baby, week, contraction, feel', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in t...   \n",
       "8   {'0': {'top 5 sample': ['week', 'doctor', 'day', 'pregnant', 'early'], 'intruder': 'tampon', 'wordlist': ['doctor', 'pregnant', 'tampon', 'week', 'day', 'early'], 'wordliststr': 'doctor, pregnant, tampon, week, day, early', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 1}, '1': {'top 5 sample': ['find', 'midwife', 'size', 'good', 'check'], 'intruder': 'tampon', 'wordlist': ['midwife', 'size', 'find', 'check', 'good', 'tampon'], 'wordliststr': 'midwife, size, find, check, good, tampon', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 1}, '2': {'top 5 sample': ['tampon', 'flow', 'change', 'wear', 'day'], 'intruder': 'doctor', 'wordlist': ['doctor', 'day', 'tampon', 'change', 'wear', 'flow'], 'wordliststr': 'doctor, day, tampon, change, wear, flow', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 0}, '3': ...   \n",
       "9   {'0': {'top 5 sample': ['period', 'pill', 'pack', 'day', 'side_effect'], 'intruder': 'feel', 'wordlist': ['day', 'pill', 'side_effect', 'feel', 'period', 'pack'], 'wordliststr': 'day, pill, side_effect, feel, period, pack', 'detectedIntruder': 'side_effect', 'rawLLMOP': 'The least related word in this set is: 000side_effect000', 'success': 0}, '1': {'top 5 sample': ['breastfeed', 'baby', 'formula', 'eat', 'feed'], 'intruder': 'back', 'wordlist': ['eat', 'feed', 'baby', 'back', 'breastfeed', 'formula'], 'wordliststr': 'eat, feed, baby, back, breastfeed, formula', 'detectedIntruder': 'back', 'rawLLMOP': 'The least related word in this set is: 000back000', 'success': 1}, '2': {'top 5 sample': ['gain', 'week', 'weight', 'doctor', 'start'], 'intruder': 'bit', 'wordlist': ['doctor', 'gain', 'bit', 'start', 'weight', 'week'], 'wordliststr': 'doctor, gain, bit, start, weight, week', 'detectedIntruder': 'bit', 'rawLLMOP': 'The least related word in this set is: 000bit000', 'success': 1}, '3...   \n",
       "10  {'0': {'top 5 sample': ['delay_clamp', 'due_date_buddy', 'horrendous', 'cutip', 'shield'], 'intruder': 'lotion', 'wordlist': ['lotion', 'shield', 'delay_clamp', 'due_date_buddy', 'horrendous', 'cutip'], 'wordliststr': 'lotion, shield, delay_clamp, due_date_buddy, horrendous, cutip', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: horrendous', 'success': 0}, '1': {'top 5 sample': ['offense', 'assault', 'battery', 'unpermitted', 'harmful_offensive'], 'intruder': 'slippage', 'wordlist': ['battery', 'assault', 'harmful_offensive', 'slippage', 'offense', 'unpermitted'], 'wordliststr': 'battery, assault, harmful_offensive, slippage, offense, unpermitted', 'detectedIntruder': 'assault', 'rawLLMOP': 'The least related word in this set is: 000assault000', 'success': 0}, '2': {'top 5 sample': ['extender', 'due_date_buddy', 'horrendous', 'literally', 'strapon'], 'intruder': 'destine', 'wordlist': ['destine', 'strapon', 'literally', 'extender', 'horrendou...   \n",
       "11  {'0': {'top 5 sample': ['smp', 'lange', 'donate_cord', 'cutip', 'due_date_buddy'], 'intruder': 'stretch_mark', 'wordlist': ['stretch_mark', 'smp', 'donate_cord', 'due_date_buddy', 'lange', 'cutip'], 'wordliststr': 'stretch_mark, smp, donate_cord, due_date_buddy, lange, cutip', 'detectedIntruder': 'smoothing_iron', 'rawLLMOP': 'The least related word in this set is: 000smoothing_iron000', 'success': 0}, '1': {'top 5 sample': ['shield', 'stretch_mark', 'slippage', 'delay_clamp', 'due_date_buddy'], 'intruder': 'hydrogel', 'wordlist': ['stretch_mark', 'due_date_buddy', 'shield', 'delay_clamp', 'hydrogel', 'slippage'], 'wordliststr': 'stretch_mark, due_date_buddy, shield, delay_clamp, hydrogel, slippage', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '2': {'top 5 sample': ['minor', 'unconsente', 'cut', 'circumcise', 'ceremony'], 'intruder': 'kilogram', 'wordlist': ['circumcise', 'minor', 'kilogram', 'ceremony', 'unconsent...   \n",
       "12  {'0': {'top 5 sample': ['criminal', 'due_date_buddy', 'threat', 'harmful_offensive', 'offense'], 'intruder': 'conduct', 'wordlist': ['criminal', 'due_date_buddy', 'harmful_offensive', 'conduct', 'threat', 'offense'], 'wordliststr': 'criminal, due_date_buddy, harmful_offensive, conduct, threat, offense', 'detectedIntruder': 'due_date_buddy', 'rawLLMOP': 'The least related word in this set is: 000due_date_buddy000', 'success': 0}, '1': {'top 5 sample': ['ovarian', 'hysterectomy', 'poly', 'cystic', 'smile'], 'intruder': 'conduct', 'wordlist': ['ovarian', 'conduct', 'smile', 'cystic', 'poly', 'hysterectomy'], 'wordliststr': 'ovarian, conduct, smile, cystic, poly, hysterectomy', 'detectedIntruder': 'smile', 'rawLLMOP': 'The least related word in this set is: 000smile000', 'success': 0}, '2': {'top 5 sample': ['ozzydog', 'lbs', 'jump', 'pitbull', 'yike'], 'intruder': 'conduct', 'wordlist': ['ozzydog', 'yike', 'jump', 'conduct', 'pitbull', 'lbs'], 'wordliststr': 'ozzydog, yike, jump, cond...   \n",
       "13  {'0': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'intruder': 'battery', 'wordlist': ['delay_clamp', 'horrendous', 'smp', 'shield', 'donate_cord', 'battery'], 'wordliststr': 'delay_clamp, horrendous, smp, shield, donate_cord, battery', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 0}, '1': {'top 5 sample': ['gastroscopy', 'rule', 'soother', 'colonoscopy', 'celiac_disease'], 'intruder': 'twosie', 'wordlist': ['soother', 'gastroscopy', 'colonoscopy', 'celiac_disease', 'rule', 'twosie'], 'wordliststr': 'soother, gastroscopy, colonoscopy, celiac_disease, rule, twosie', 'detectedIntruder': 'twosie', 'rawLLMOP': 'In this case, the least related word to all other words in terms of meaning is: 000twosie000', 'success': 1}, '2': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'intruder': 'battery', 'wordlist': ['donate_cord', 'horrendous', 'shield', 'smp'...   \n",
       "14  {'0': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'intruder': 'germ', 'wordlist': ['due_date_buddy', 'delay_clamp', 'donate_cord', 'shield', 'germ', 'horrendous'], 'wordliststr': 'due_date_buddy, delay_clamp, donate_cord, shield, germ, horrendous', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 0}, '1': {'top 5 sample': ['baby', 'week', 'time', 'day', 'woman'], 'intruder': 'horrendous', 'wordlist': ['time', 'week', 'woman', 'day', 'baby', 'horrendous'], 'wordliststr': 'time, week, woman, day, baby, horrendous', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 1}, '2': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'intruder': 'germ', 'wordlist': ['delay_clamp', 'due_date_buddy', 'shield', 'germ', 'donate_cord', 'horrendous'], 'wordliststr': 'delay_clamp, due_...   \n",
       "15  {'0': {'top 5 sample': ['hereditary', 'horrendous', 'kilogram', 'ozzydog', 'endometriosis'], 'intruder': 'week', 'wordlist': ['week', 'ozzydog', 'kilogram', 'horrendous', 'hereditary', 'endometriosis'], 'wordliststr': 'week, ozzydog, kilogram, horrendous, hereditary, endometriosis', 'detectedIntruder': 'ozzydog', 'rawLLMOP': 'The least related word in this set is: 000ozzydog000', 'success': 0}, '1': {'top 5 sample': ['ive', 'horrendous', 'kilogram', 'elastin', 'lotion'], 'intruder': 'mae', 'wordlist': ['elastin', 'ive', 'kilogram', 'mae', 'horrendous', 'lotion'], 'wordliststr': 'elastin, ive, kilogram, mae, horrendous, lotion', 'detectedIntruder': 'ive', 'rawLLMOP': 'The least related word in this set is: 000ive000', 'success': 0}, '2': {'top 5 sample': ['endometriosis', 'horrendous', 'kilogram', 'arthritis', 'lange'], 'intruder': 'week', 'wordlist': ['lange', 'arthritis', 'kilogram', 'endometriosis', 'week', 'horrendous'], 'wordliststr': 'lange, arthritis, kilogram, endometriosis,...   \n",
       "16  {'0': {'top 5 sample': ['purposely', 'weapon', 'deadly', 'reputable', 'injury'], 'intruder': 'flair', 'wordlist': ['flair', 'reputable', 'deadly', 'injury', 'weapon', 'purposely'], 'wordliststr': 'flair, reputable, deadly, injury, weapon, purposely', 'detectedIntruder': 'injury', 'rawLLMOP': 'The least related word in this set is: 000injury000', 'success': 0}, '1': {'top 5 sample': ['hereditary', 'due_date_buddy', 'shield', 'arthritis', 'horrendous'], 'intruder': 'squirmy', 'wordlist': ['horrendous', 'arthritis', 'due_date_buddy', 'hereditary', 'shield', 'squirmy'], 'wordliststr': 'horrendous, arthritis, due_date_buddy, hereditary, shield, squirmy', 'detectedIntruder': 'squirmy', 'rawLLMOP': 'The least related word in this set is: 000squirmy000', 'success': 1}, '2': {'top 5 sample': ['lange', 'due_date_buddy', 'shield', 'ozzydog', 'horrendous'], 'intruder': 'squirmy', 'wordlist': ['shield', 'horrendous', 'ozzydog', 'squirmy', 'due_date_buddy', 'lange'], 'wordliststr': 'shield, horr...   \n",
       "17  {'0': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['arthritis', 'hereditary', 'endometriosis', 'conduct', 'shield', 'due_date_buddy'], 'wordliststr': 'arthritis, hereditary, endometriosis, conduct, shield, due_date_buddy', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '1': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['arthritis', 'hereditary', 'conduct', 'due_date_buddy', 'endometriosis', 'shield'], 'wordliststr': 'arthritis, hereditary, conduct, due_date_buddy, endometriosis, shield', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '2': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['endometriosis', 'shield', 'due...   \n",
       "18  {'0': {'top 5 sample': ['kilogram', 'toxin', 'toxigenic', 'staph', 'agent'], 'intruder': 'mae', 'wordlist': ['staph', 'toxigenic', 'kilogram', 'agent', 'toxin', 'mae'], 'wordliststr': 'staph, toxigenic, kilogram, agent, toxin, mae', 'detectedIntruder': 'kilogram', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'success': 0}, '1': {'top 5 sample': ['kilogram', 'arthritis', 'stretch_mark', 'lange', 'endometriosis'], 'intruder': 'ovarian', 'wordlist': ['arthritis', 'stretch_mark', 'endometriosis', 'lange', 'ovarian', 'kilogram'], 'wordliststr': 'arthritis, stretch_mark, endometriosis, lange, ovarian, kilogram', 'detectedIntruder': 'lange', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'success': 0}, '2': {'top 5 sample': ['kilogram', 'lange', 'delay_clamp', 'endometriosis', 'hereditary'], 'intruder': 'ovarian', 'wordlist': ['ovarian', 'hereditary', 'delay_clamp', 'kilogram', 'lange', 'endometriosis'], 'wordliststr': 'ovarian, hereditary, delay...   \n",
       "19  {'0': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'shield'], 'intruder': 'mammogram', 'wordlist': ['horrendous', 'shield', 'kilogram', 'endometriosis', 'mammogram', 'lange'], 'wordliststr': 'horrendous, shield, kilogram, endometriosis, mammogram, lange', 'detectedIntruder': 'kilogram', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'success': 0}, '1': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'stretch_mark'], 'intruder': 'mammogram', 'wordlist': ['mammogram', 'stretch_mark', 'horrendous', 'endometriosis', 'lange', 'kilogram'], 'wordliststr': 'mammogram, stretch_mark, horrendous, endometriosis, lange, kilogram', 'detectedIntruder': 'lange', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'success': 0}, '2': {'top 5 sample': ['horrendous', 'kilogram', 'muggle_blood', 'lange', 'arthritis'], 'intruder': 'coat_factory', 'wordlist': ['kilogram', 'coat_factory', 'horrendous', 'arthritis', 'muggle...   \n",
       "\n",
       "   package  \\\n",
       "0   gensim   \n",
       "1   gensim   \n",
       "2   gensim   \n",
       "3   gensim   \n",
       "4   gensim   \n",
       "5   gensim   \n",
       "6   gensim   \n",
       "7   gensim   \n",
       "8   gensim   \n",
       "9   gensim   \n",
       "10  gensim   \n",
       "11  gensim   \n",
       "12  gensim   \n",
       "13  gensim   \n",
       "14  gensim   \n",
       "15  gensim   \n",
       "16  gensim   \n",
       "17  gensim   \n",
       "18  gensim   \n",
       "19  gensim   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       data  \\\n",
       "0   {'0': {'top 5 sample': ['start', 'time', 'feel', 'back', 'make'], 'intruder': 'baby', 'wordlist': ['back', 'make', 'feel', 'time', 'start', 'baby'], 'wordliststr': 'back, make, feel, time, start, baby', 'detectedIntruder': 'baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'success': 1}, '1': {'top 5 sample': ['blood', 'sex', 'doctor', 'problem', 'year'], 'intruder': 'week', 'wordlist': ['year', 'problem', 'doctor', 'sex', 'blood', 'week'], 'wordliststr': 'year, problem, doctor, sex, blood, week', 'detectedIntruder': 'sex', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'success': 0}, '2': {'top 5 sample': ['human', 'life', 'abortion', 'make', 'child'], 'intruder': 'week', 'wordlist': ['make', 'abortion', 'human', 'week', 'life', 'child'], 'wordliststr': 'make, abortion, human, week, life, child', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in this set is: 000week000', 'success': 1}, '3': {'top 5 sample': ['hour', 'labor', ...   \n",
       "1   {'0': {'top 5 sample': ['iud', 'month', 'bad', 'heavy', 'period'], 'intruder': 'make', 'wordlist': ['iud', 'bad', 'heavy', 'month', 'make', 'period'], 'wordliststr': 'iud, bad, heavy, month, make, period', 'detectedIntruder': 'iud', 'rawLLMOP': 'The least related word in this set is: 000iud000', 'success': 0}, '1': {'top 5 sample': ['give', 'time', 'thing', 'hard', 'baby'], 'intruder': 'period', 'wordlist': ['time', 'give', 'thing', 'baby', 'hard', 'period'], 'wordliststr': 'time, give, thing, baby, hard, period', 'detectedIntruder': 'baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'success': 0}, '2': {'top 5 sample': ['time', 'pain', 'cervix', 'check', 'doctor'], 'intruder': 'day', 'wordlist': ['check', 'cervix', 'day', 'pain', 'time', 'doctor'], 'wordliststr': 'check, cervix, day, pain, time, doctor', 'detectedIntruder': 'cervix', 'rawLLMOP': 'The least related word in this set is: 000cervix000', 'success': 0}, '3': {'top 5 sample': ['move', 'thing', 'good...   \n",
       "2   {'0': {'top 5 sample': ['cup', 'flow', 'partner', 'wear', 'change'], 'intruder': 'abortion', 'wordlist': ['wear', 'change', 'abortion', 'cup', 'partner', 'flow'], 'wordliststr': 'wear, change, abortion, cup, partner, flow', 'detectedIntruder': 'abortion', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'success': 1}, '1': {'top 5 sample': ['make', 'good', 'feel', 'lot', 'start'], 'intruder': 'abortion', 'wordlist': ['make', 'lot', 'feel', 'abortion', 'good', 'start'], 'wordliststr': 'make, lot, feel, abortion, good, start', 'detectedIntruder': 'abortion', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'success': 1}, '2': {'top 5 sample': ['hospital', 'epidural', 'plan', 'contraction', 'section'], 'intruder': 'abortion', 'wordlist': ['contraction', 'epidural', 'abortion', 'plan', 'hospital', 'section'], 'wordliststr': 'contraction, epidural, abortion, plan, hospital, section', 'detectedIntruder': 'contraction', 'rawLLMOP': 'The least relate...   \n",
       "3   {'0': {'top 5 sample': ['pregnancy', 'early', 'thing', 'pregnant', 'time'], 'intruder': 'tampon', 'wordlist': ['time', 'thing', 'pregnant', 'early', 'tampon', 'pregnancy'], 'wordliststr': 'time, thing, pregnant, early, tampon, pregnancy', 'detectedIntruder': 'thing', 'rawLLMOP': 'The least related word in this set is: 000thing000', 'success': 0}, '1': {'top 5 sample': ['doctor', 'start', 'week', 'check', 'thing'], 'intruder': 'tampon', 'wordlist': ['tampon', 'start', 'check', 'doctor', 'week', 'thing'], 'wordliststr': 'tampon, start, check, doctor, week, thing', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: tampon', 'success': 0}, '2': {'top 5 sample': ['tampon', 'blood', 'bit', 'cup', 'pad'], 'intruder': 'doctor', 'wordlist': ['bit', 'blood', 'tampon', 'pad', 'cup', 'doctor'], 'wordliststr': 'bit, blood, tampon, pad, cup, doctor', 'detectedIntruder': 'doctor', 'rawLLMOP': 'The least related word in this set is: 000doctor000', 'success': 1},...   \n",
       "4   {'0': {'top 5 sample': ['control', 'pill', 'take', 'day', 'side_effect'], 'intruder': 'bad', 'wordlist': ['pill', 'control', 'bad', 'day', 'side_effect', 'take'], 'wordliststr': 'pill, control, bad, day, side_effect, take', 'detectedIntruder': 'day', 'rawLLMOP': 'The least related word in this set is: 000day000', 'success': 0}, '1': {'top 5 sample': ['time', 'baby', 'give', 'hard', 'breastfeed'], 'intruder': 'period', 'wordlist': ['give', 'breastfeed', 'baby', 'hard', 'period', 'time'], 'wordliststr': 'give, breastfeed, baby, hard, period, time', 'detectedIntruder': 'period', 'rawLLMOP': 'The least related word in this set is: 000period000', 'success': 1}, '2': {'top 5 sample': ['pregnancy', 'week', 'doctor', 'gain', 'pregnant'], 'intruder': 'day', 'wordlist': ['pregnant', 'day', 'doctor', 'week', 'pregnancy', 'gain'], 'wordliststr': 'pregnant, day, doctor, week, pregnancy, gain', 'detectedIntruder': 'day', 'rawLLMOP': 'The least related word in this set is: 000day000', 'success': ...   \n",
       "5   {'0': {'top 5 sample': ['good', 'time', 'feel', 'pain', 'thing'], 'intruder': 'week', 'wordlist': ['thing', 'good', 'week', 'time', 'pain', 'feel'], 'wordliststr': 'thing, good, week, time, pain, feel', 'detectedIntruder': 'pain', 'rawLLMOP': 'The least related word in this set is: 000pain000', 'success': 0}, '1': {'top 5 sample': ['water', 'infection', 'doctor', 'make', 'yeast_infection'], 'intruder': 'week', 'wordlist': ['doctor', 'make', 'yeast_infection', 'water', 'week', 'infection'], 'wordliststr': 'doctor, make, yeast_infection, water, week, infection', 'detectedIntruder': 'water', 'rawLLMOP': 'The least related word in this set is: 000water000', 'success': 0}, '2': {'top 5 sample': ['midwife', 'trimester', 'woman', 'class', 'medical'], 'intruder': 'week', 'wordlist': ['medical', 'trimester', 'class', 'midwife', 'woman', 'week'], 'wordliststr': 'medical, trimester, class, midwife, woman, week', 'detectedIntruder': 'class', 'rawLLMOP': 'The least related word in this set is: ...   \n",
       "6   {'0': {'top 5 sample': ['feel', 'time', 'ultrasound', 'weight', 'start'], 'intruder': 'period', 'wordlist': ['time', 'feel', 'start', 'weight', 'period', 'ultrasound'], 'wordliststr': 'time, feel, start, weight, period, ultrasound', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: 'ultrasound'.', 'success': 0}, '1': {'top 5 sample': ['bleed', 'cramp', 'mirena', 'spot', 'month'], 'intruder': 'week', 'wordlist': ['spot', 'cramp', 'week', 'mirena', 'month', 'bleed'], 'wordliststr': 'spot, cramp, week, mirena, month, bleed', 'detectedIntruder': 'cramp', 'rawLLMOP': 'The least related word in this set is: 000cramp000', 'success': 0}, '2': {'top 5 sample': ['painful', 'hurt', 'pressure', 'uncomfortable', 'doctor'], 'intruder': 'week', 'wordlist': ['doctor', 'pressure', 'hurt', 'uncomfortable', 'painful', 'week'], 'wordliststr': 'doctor, pressure, hurt, uncomfortable, painful, week', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in t...   \n",
       "7   {'0': {'top 5 sample': ['pad', 'sex', 'clean', 'yeast_infection', 'buy'], 'intruder': 'labor', 'wordlist': ['pad', 'clean', 'sex', 'buy', 'yeast_infection', 'labor'], 'wordliststr': 'pad, clean, sex, buy, yeast_infection, labor', 'detectedIntruder': 'sex', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'success': 0}, '1': {'top 5 sample': ['feel', 'hour', 'make', 'week', 'nurse'], 'intruder': 'contraction', 'wordlist': ['week', 'make', 'contraction', 'hour', 'nurse', 'feel'], 'wordliststr': 'week, make, contraction, hour, nurse, feel', 'detectedIntruder': 'contraction', 'rawLLMOP': 'The least related word in this set is: 000contraction000', 'success': 1}, '2': {'top 5 sample': ['week', 'hospital', 'maternity', 'feel', 'baby'], 'intruder': 'contraction', 'wordlist': ['hospital', 'maternity', 'baby', 'week', 'contraction', 'feel'], 'wordliststr': 'hospital, maternity, baby, week, contraction, feel', 'detectedIntruder': 'week', 'rawLLMOP': 'The least related word in t...   \n",
       "8   {'0': {'top 5 sample': ['week', 'doctor', 'day', 'pregnant', 'early'], 'intruder': 'tampon', 'wordlist': ['doctor', 'pregnant', 'tampon', 'week', 'day', 'early'], 'wordliststr': 'doctor, pregnant, tampon, week, day, early', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 1}, '1': {'top 5 sample': ['find', 'midwife', 'size', 'good', 'check'], 'intruder': 'tampon', 'wordlist': ['midwife', 'size', 'find', 'check', 'good', 'tampon'], 'wordliststr': 'midwife, size, find, check, good, tampon', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 1}, '2': {'top 5 sample': ['tampon', 'flow', 'change', 'wear', 'day'], 'intruder': 'doctor', 'wordlist': ['doctor', 'day', 'tampon', 'change', 'wear', 'flow'], 'wordliststr': 'doctor, day, tampon, change, wear, flow', 'detectedIntruder': 'tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'success': 0}, '3': ...   \n",
       "9   {'0': {'top 5 sample': ['period', 'pill', 'pack', 'day', 'side_effect'], 'intruder': 'feel', 'wordlist': ['day', 'pill', 'side_effect', 'feel', 'period', 'pack'], 'wordliststr': 'day, pill, side_effect, feel, period, pack', 'detectedIntruder': 'side_effect', 'rawLLMOP': 'The least related word in this set is: 000side_effect000', 'success': 0}, '1': {'top 5 sample': ['breastfeed', 'baby', 'formula', 'eat', 'feed'], 'intruder': 'back', 'wordlist': ['eat', 'feed', 'baby', 'back', 'breastfeed', 'formula'], 'wordliststr': 'eat, feed, baby, back, breastfeed, formula', 'detectedIntruder': 'back', 'rawLLMOP': 'The least related word in this set is: 000back000', 'success': 1}, '2': {'top 5 sample': ['gain', 'week', 'weight', 'doctor', 'start'], 'intruder': 'bit', 'wordlist': ['doctor', 'gain', 'bit', 'start', 'weight', 'week'], 'wordliststr': 'doctor, gain, bit, start, weight, week', 'detectedIntruder': 'bit', 'rawLLMOP': 'The least related word in this set is: 000bit000', 'success': 1}, '3...   \n",
       "10  {'0': {'top 5 sample': ['delay_clamp', 'due_date_buddy', 'horrendous', 'cutip', 'shield'], 'intruder': 'lotion', 'wordlist': ['lotion', 'shield', 'delay_clamp', 'due_date_buddy', 'horrendous', 'cutip'], 'wordliststr': 'lotion, shield, delay_clamp, due_date_buddy, horrendous, cutip', 'detectedIntruder': 'NOTDETECTED', 'rawLLMOP': 'The least related word in this set is: horrendous', 'success': 0}, '1': {'top 5 sample': ['offense', 'assault', 'battery', 'unpermitted', 'harmful_offensive'], 'intruder': 'slippage', 'wordlist': ['battery', 'assault', 'harmful_offensive', 'slippage', 'offense', 'unpermitted'], 'wordliststr': 'battery, assault, harmful_offensive, slippage, offense, unpermitted', 'detectedIntruder': 'assault', 'rawLLMOP': 'The least related word in this set is: 000assault000', 'success': 0}, '2': {'top 5 sample': ['extender', 'due_date_buddy', 'horrendous', 'literally', 'strapon'], 'intruder': 'destine', 'wordlist': ['destine', 'strapon', 'literally', 'extender', 'horrendou...   \n",
       "11  {'0': {'top 5 sample': ['smp', 'lange', 'donate_cord', 'cutip', 'due_date_buddy'], 'intruder': 'stretch_mark', 'wordlist': ['stretch_mark', 'smp', 'donate_cord', 'due_date_buddy', 'lange', 'cutip'], 'wordliststr': 'stretch_mark, smp, donate_cord, due_date_buddy, lange, cutip', 'detectedIntruder': 'smoothing_iron', 'rawLLMOP': 'The least related word in this set is: 000smoothing_iron000', 'success': 0}, '1': {'top 5 sample': ['shield', 'stretch_mark', 'slippage', 'delay_clamp', 'due_date_buddy'], 'intruder': 'hydrogel', 'wordlist': ['stretch_mark', 'due_date_buddy', 'shield', 'delay_clamp', 'hydrogel', 'slippage'], 'wordliststr': 'stretch_mark, due_date_buddy, shield, delay_clamp, hydrogel, slippage', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '2': {'top 5 sample': ['minor', 'unconsente', 'cut', 'circumcise', 'ceremony'], 'intruder': 'kilogram', 'wordlist': ['circumcise', 'minor', 'kilogram', 'ceremony', 'unconsent...   \n",
       "12  {'0': {'top 5 sample': ['criminal', 'due_date_buddy', 'threat', 'harmful_offensive', 'offense'], 'intruder': 'conduct', 'wordlist': ['criminal', 'due_date_buddy', 'harmful_offensive', 'conduct', 'threat', 'offense'], 'wordliststr': 'criminal, due_date_buddy, harmful_offensive, conduct, threat, offense', 'detectedIntruder': 'due_date_buddy', 'rawLLMOP': 'The least related word in this set is: 000due_date_buddy000', 'success': 0}, '1': {'top 5 sample': ['ovarian', 'hysterectomy', 'poly', 'cystic', 'smile'], 'intruder': 'conduct', 'wordlist': ['ovarian', 'conduct', 'smile', 'cystic', 'poly', 'hysterectomy'], 'wordliststr': 'ovarian, conduct, smile, cystic, poly, hysterectomy', 'detectedIntruder': 'smile', 'rawLLMOP': 'The least related word in this set is: 000smile000', 'success': 0}, '2': {'top 5 sample': ['ozzydog', 'lbs', 'jump', 'pitbull', 'yike'], 'intruder': 'conduct', 'wordlist': ['ozzydog', 'yike', 'jump', 'conduct', 'pitbull', 'lbs'], 'wordliststr': 'ozzydog, yike, jump, cond...   \n",
       "13  {'0': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'intruder': 'battery', 'wordlist': ['delay_clamp', 'horrendous', 'smp', 'shield', 'donate_cord', 'battery'], 'wordliststr': 'delay_clamp, horrendous, smp, shield, donate_cord, battery', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 0}, '1': {'top 5 sample': ['gastroscopy', 'rule', 'soother', 'colonoscopy', 'celiac_disease'], 'intruder': 'twosie', 'wordlist': ['soother', 'gastroscopy', 'colonoscopy', 'celiac_disease', 'rule', 'twosie'], 'wordliststr': 'soother, gastroscopy, colonoscopy, celiac_disease, rule, twosie', 'detectedIntruder': 'twosie', 'rawLLMOP': 'In this case, the least related word to all other words in terms of meaning is: 000twosie000', 'success': 1}, '2': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'intruder': 'battery', 'wordlist': ['donate_cord', 'horrendous', 'shield', 'smp'...   \n",
       "14  {'0': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'intruder': 'germ', 'wordlist': ['due_date_buddy', 'delay_clamp', 'donate_cord', 'shield', 'germ', 'horrendous'], 'wordliststr': 'due_date_buddy, delay_clamp, donate_cord, shield, germ, horrendous', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 0}, '1': {'top 5 sample': ['baby', 'week', 'time', 'day', 'woman'], 'intruder': 'horrendous', 'wordlist': ['time', 'week', 'woman', 'day', 'baby', 'horrendous'], 'wordliststr': 'time, week, woman, day, baby, horrendous', 'detectedIntruder': 'horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'success': 1}, '2': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'intruder': 'germ', 'wordlist': ['delay_clamp', 'due_date_buddy', 'shield', 'germ', 'donate_cord', 'horrendous'], 'wordliststr': 'delay_clamp, due_...   \n",
       "15  {'0': {'top 5 sample': ['hereditary', 'horrendous', 'kilogram', 'ozzydog', 'endometriosis'], 'intruder': 'week', 'wordlist': ['week', 'ozzydog', 'kilogram', 'horrendous', 'hereditary', 'endometriosis'], 'wordliststr': 'week, ozzydog, kilogram, horrendous, hereditary, endometriosis', 'detectedIntruder': 'ozzydog', 'rawLLMOP': 'The least related word in this set is: 000ozzydog000', 'success': 0}, '1': {'top 5 sample': ['ive', 'horrendous', 'kilogram', 'elastin', 'lotion'], 'intruder': 'mae', 'wordlist': ['elastin', 'ive', 'kilogram', 'mae', 'horrendous', 'lotion'], 'wordliststr': 'elastin, ive, kilogram, mae, horrendous, lotion', 'detectedIntruder': 'ive', 'rawLLMOP': 'The least related word in this set is: 000ive000', 'success': 0}, '2': {'top 5 sample': ['endometriosis', 'horrendous', 'kilogram', 'arthritis', 'lange'], 'intruder': 'week', 'wordlist': ['lange', 'arthritis', 'kilogram', 'endometriosis', 'week', 'horrendous'], 'wordliststr': 'lange, arthritis, kilogram, endometriosis,...   \n",
       "16  {'0': {'top 5 sample': ['purposely', 'weapon', 'deadly', 'reputable', 'injury'], 'intruder': 'flair', 'wordlist': ['flair', 'reputable', 'deadly', 'injury', 'weapon', 'purposely'], 'wordliststr': 'flair, reputable, deadly, injury, weapon, purposely', 'detectedIntruder': 'injury', 'rawLLMOP': 'The least related word in this set is: 000injury000', 'success': 0}, '1': {'top 5 sample': ['hereditary', 'due_date_buddy', 'shield', 'arthritis', 'horrendous'], 'intruder': 'squirmy', 'wordlist': ['horrendous', 'arthritis', 'due_date_buddy', 'hereditary', 'shield', 'squirmy'], 'wordliststr': 'horrendous, arthritis, due_date_buddy, hereditary, shield, squirmy', 'detectedIntruder': 'squirmy', 'rawLLMOP': 'The least related word in this set is: 000squirmy000', 'success': 1}, '2': {'top 5 sample': ['lange', 'due_date_buddy', 'shield', 'ozzydog', 'horrendous'], 'intruder': 'squirmy', 'wordlist': ['shield', 'horrendous', 'ozzydog', 'squirmy', 'due_date_buddy', 'lange'], 'wordliststr': 'shield, horr...   \n",
       "17  {'0': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['arthritis', 'hereditary', 'endometriosis', 'conduct', 'shield', 'due_date_buddy'], 'wordliststr': 'arthritis, hereditary, endometriosis, conduct, shield, due_date_buddy', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '1': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['arthritis', 'hereditary', 'conduct', 'due_date_buddy', 'endometriosis', 'shield'], 'wordliststr': 'arthritis, hereditary, conduct, due_date_buddy, endometriosis, shield', 'detectedIntruder': 'shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'success': 0}, '2': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'intruder': 'conduct', 'wordlist': ['endometriosis', 'shield', 'due...   \n",
       "18  {'0': {'top 5 sample': ['kilogram', 'toxin', 'toxigenic', 'staph', 'agent'], 'intruder': 'mae', 'wordlist': ['staph', 'toxigenic', 'kilogram', 'agent', 'toxin', 'mae'], 'wordliststr': 'staph, toxigenic, kilogram, agent, toxin, mae', 'detectedIntruder': 'kilogram', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'success': 0}, '1': {'top 5 sample': ['kilogram', 'arthritis', 'stretch_mark', 'lange', 'endometriosis'], 'intruder': 'ovarian', 'wordlist': ['arthritis', 'stretch_mark', 'endometriosis', 'lange', 'ovarian', 'kilogram'], 'wordliststr': 'arthritis, stretch_mark, endometriosis, lange, ovarian, kilogram', 'detectedIntruder': 'lange', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'success': 0}, '2': {'top 5 sample': ['kilogram', 'lange', 'delay_clamp', 'endometriosis', 'hereditary'], 'intruder': 'ovarian', 'wordlist': ['ovarian', 'hereditary', 'delay_clamp', 'kilogram', 'lange', 'endometriosis'], 'wordliststr': 'ovarian, hereditary, delay...   \n",
       "19  {'0': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'shield'], 'intruder': 'mammogram', 'wordlist': ['horrendous', 'shield', 'kilogram', 'endometriosis', 'mammogram', 'lange'], 'wordliststr': 'horrendous, shield, kilogram, endometriosis, mammogram, lange', 'detectedIntruder': 'kilogram', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'success': 0}, '1': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'stretch_mark'], 'intruder': 'mammogram', 'wordlist': ['mammogram', 'stretch_mark', 'horrendous', 'endometriosis', 'lange', 'kilogram'], 'wordliststr': 'mammogram, stretch_mark, horrendous, endometriosis, lange, kilogram', 'detectedIntruder': 'lange', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'success': 0}, '2': {'top 5 sample': ['horrendous', 'kilogram', 'muggle_blood', 'lange', 'arthritis'], 'intruder': 'coat_factory', 'wordlist': ['kilogram', 'coat_factory', 'horrendous', 'arthritis', 'muggle...   \n",
       "\n",
       "    NewScore  \\\n",
       "0       0.50   \n",
       "1       0.10   \n",
       "2       0.40   \n",
       "3       0.10   \n",
       "4       0.20   \n",
       "5       0.15   \n",
       "6       0.35   \n",
       "7       0.15   \n",
       "8       0.20   \n",
       "9       0.50   \n",
       "10      0.10   \n",
       "11      0.18   \n",
       "12      0.20   \n",
       "13      0.16   \n",
       "14      0.20   \n",
       "15      0.05   \n",
       "16      0.34   \n",
       "17      0.12   \n",
       "18      0.04   \n",
       "19      0.17   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  fixedData  \n",
       "0   {'0': {'top 5 sample': ['start', 'time', 'feel', 'back', 'make'], 'wordliststr': 'back, make, feel, time, start, baby', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'intruder': 'baby', 'detectedIntruder': 'baby', 'success': 1}, '1': {'top 5 sample': ['blood', 'sex', 'doctor', 'problem', 'year'], 'wordliststr': 'year, problem, doctor, sex, blood, week', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'intruder': 'week', 'detectedIntruder': 'sex', 'success': 0}, '2': {'top 5 sample': ['human', 'life', 'abortion', 'make', 'child'], 'wordliststr': 'make, abortion, human, week, life, child', 'rawLLMOP': 'The least related word in this set is: 000week000', 'intruder': 'week', 'detectedIntruder': 'week', 'success': 1}, '3': {'top 5 sample': ['hour', 'labor', 'birth', 'push', 'hospital'], 'wordliststr': 'week, hour, hospital, birth, labor, push', 'rawLLMOP': 'The least related word in this set is: 000hospital000', 'intruder': 'week', 'detectedIntruder': ...  \n",
       "1   {'0': {'top 5 sample': ['iud', 'month', 'bad', 'heavy', 'period'], 'wordliststr': 'iud, bad, heavy, month, make, period', 'rawLLMOP': 'The least related word in this set is: 000iud000', 'intruder': 'make', 'detectedIntruder': 'iud', 'success': 0}, '1': {'top 5 sample': ['give', 'time', 'thing', 'hard', 'baby'], 'wordliststr': 'time, give, thing, baby, hard, period', 'rawLLMOP': 'The least related word in this set is: 000baby000', 'intruder': 'period', 'detectedIntruder': 'baby', 'success': 0}, '2': {'top 5 sample': ['time', 'pain', 'cervix', 'check', 'doctor'], 'wordliststr': 'check, cervix, day, pain, time, doctor', 'rawLLMOP': 'The least related word in this set is: 000cervix000', 'intruder': 'day', 'detectedIntruder': 'cervix', 'success': 0}, '3': {'top 5 sample': ['move', 'thing', 'good', 'make', 'feel'], 'wordliststr': 'good, feel, thing, day, make, move', 'rawLLMOP': 'The least related word in this set is: 000move000', 'intruder': 'day', 'detectedIntruder': 'move', 'success':...  \n",
       "2   {'0': {'top 5 sample': ['cup', 'flow', 'partner', 'wear', 'change'], 'wordliststr': 'wear, change, abortion, cup, partner, flow', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'intruder': 'abortion', 'detectedIntruder': 'abortion', 'success': 1}, '1': {'top 5 sample': ['make', 'good', 'feel', 'lot', 'start'], 'wordliststr': 'make, lot, feel, abortion, good, start', 'rawLLMOP': 'The least related word in this set is: 000abortion000', 'intruder': 'abortion', 'detectedIntruder': 'abortion', 'success': 1}, '2': {'top 5 sample': ['hospital', 'epidural', 'plan', 'contraction', 'section'], 'wordliststr': 'contraction, epidural, abortion, plan, hospital, section', 'rawLLMOP': 'The least related word in this set is: 000contraction000', 'intruder': 'abortion', 'detectedIntruder': 'contraction', 'success': 0}, '3': {'top 5 sample': ['make', 'risk', 'result', 'blood', 'year'], 'wordliststr': 'risk, abortion, result, year, blood, make', 'rawLLMOP': 'The least related word...  \n",
       "3   {'0': {'top 5 sample': ['pregnancy', 'early', 'thing', 'pregnant', 'time'], 'wordliststr': 'time, thing, pregnant, early, tampon, pregnancy', 'rawLLMOP': 'The least related word in this set is: 000thing000', 'intruder': 'tampon', 'detectedIntruder': 'thing', 'success': 0}, '1': {'top 5 sample': ['doctor', 'start', 'week', 'check', 'thing'], 'wordliststr': 'tampon, start, check, doctor, week, thing', 'rawLLMOP': 'The least related word in this set is: tampon', 'intruder': 'tampon', 'detectedIntruder': 'NOTDETECTED', 'success': 0}, '2': {'top 5 sample': ['tampon', 'blood', 'bit', 'cup', 'pad'], 'wordliststr': 'bit, blood, tampon, pad, cup, doctor', 'rawLLMOP': 'The least related word in this set is: 000doctor000', 'intruder': 'doctor', 'detectedIntruder': 'doctor', 'success': 1}, '3': {'top 5 sample': ['abortion', 'person', 'people', 'child', 'human'], 'wordliststr': 'doctor, child, person, human, abortion, people', 'rawLLMOP': 'The least related word in this set is: 000abortion000',...  \n",
       "4   {'0': {'top 5 sample': ['control', 'pill', 'take', 'day', 'side_effect'], 'wordliststr': 'pill, control, bad, day, side_effect, take', 'rawLLMOP': 'The least related word in this set is: 000day000', 'intruder': 'bad', 'detectedIntruder': 'day', 'success': 0}, '1': {'top 5 sample': ['time', 'baby', 'give', 'hard', 'breastfeed'], 'wordliststr': 'give, breastfeed, baby, hard, period, time', 'rawLLMOP': 'The least related word in this set is: 000period000', 'intruder': 'period', 'detectedIntruder': 'period', 'success': 1}, '2': {'top 5 sample': ['pregnancy', 'week', 'doctor', 'gain', 'pregnant'], 'wordliststr': 'pregnant, day, doctor, week, pregnancy, gain', 'rawLLMOP': 'The least related word in this set is: 000day000', 'intruder': 'day', 'detectedIntruder': 'day', 'success': 1}, '3': {'top 5 sample': ['lot', 'good', 'doctor', 'test', 'common'], 'wordliststr': 'day, test, lot, common, doctor, good', 'rawLLMOP': 'The least related word in this set is: 000doctor000', 'intruder': 'day', ...  \n",
       "5   {'0': {'top 5 sample': ['good', 'time', 'feel', 'pain', 'thing'], 'wordliststr': 'thing, good, week, time, pain, feel', 'rawLLMOP': 'The least related word in this set is: 000pain000', 'intruder': 'week', 'detectedIntruder': 'pain', 'success': 0}, '1': {'top 5 sample': ['water', 'infection', 'doctor', 'make', 'yeast_infection'], 'wordliststr': 'doctor, make, yeast_infection, water, week, infection', 'rawLLMOP': 'The least related word in this set is: 000water000', 'intruder': 'week', 'detectedIntruder': 'water', 'success': 0}, '2': {'top 5 sample': ['midwife', 'trimester', 'woman', 'class', 'medical'], 'wordliststr': 'medical, trimester, class, midwife, woman, week', 'rawLLMOP': 'The least related word in this set is: 000class000', 'intruder': 'week', 'detectedIntruder': 'class', 'success': 0}, '3': {'top 5 sample': ['woman', 'life', 'abortion', 'baby', 'human'], 'wordliststr': 'human, abortion, life, week, baby, woman', 'rawLLMOP': 'The least related word in this set is: 000week00...  \n",
       "6   {'0': {'top 5 sample': ['feel', 'time', 'ultrasound', 'weight', 'start'], 'wordliststr': 'time, feel, start, weight, period, ultrasound', 'rawLLMOP': 'The least related word in this set is: 'ultrasound'.', 'intruder': 'period', 'detectedIntruder': 'ultrasound', 'success': 0}, '1': {'top 5 sample': ['bleed', 'cramp', 'mirena', 'spot', 'month'], 'wordliststr': 'spot, cramp, week, mirena, month, bleed', 'rawLLMOP': 'The least related word in this set is: 000cramp000', 'intruder': 'week', 'detectedIntruder': 'cramp', 'success': 0}, '2': {'top 5 sample': ['painful', 'hurt', 'pressure', 'uncomfortable', 'doctor'], 'wordliststr': 'doctor, pressure, hurt, uncomfortable, painful, week', 'rawLLMOP': 'The least related word in this set is: 000week000', 'intruder': 'week', 'detectedIntruder': 'week', 'success': 1}, '3': {'top 5 sample': ['remove', 'bathroom', 'mine', 'position', 'pull'], 'wordliststr': 'bathroom, mine, position, week, pull, remove', 'rawLLMOP': 'The least related word in this ...  \n",
       "7   {'0': {'top 5 sample': ['pad', 'sex', 'clean', 'yeast_infection', 'buy'], 'wordliststr': 'pad, clean, sex, buy, yeast_infection, labor', 'rawLLMOP': 'The least related word in this set is: 000sex000', 'intruder': 'labor', 'detectedIntruder': 'sex', 'success': 0}, '1': {'top 5 sample': ['feel', 'hour', 'make', 'week', 'nurse'], 'wordliststr': 'week, make, contraction, hour, nurse, feel', 'rawLLMOP': 'The least related word in this set is: 000contraction000', 'intruder': 'contraction', 'detectedIntruder': 'contraction', 'success': 1}, '2': {'top 5 sample': ['week', 'hospital', 'maternity', 'feel', 'baby'], 'wordliststr': 'hospital, maternity, baby, week, contraction, feel', 'rawLLMOP': 'The least related word in this set is: 000week000', 'intruder': 'contraction', 'detectedIntruder': 'week', 'success': 0}, '3': {'top 5 sample': ['time', 'baby', 'doctor', 'birth', 'woman'], 'wordliststr': 'labor, time, birth, woman, baby, doctor', 'rawLLMOP': 'The least related word in this set is: 00...  \n",
       "8   {'0': {'top 5 sample': ['week', 'doctor', 'day', 'pregnant', 'early'], 'wordliststr': 'doctor, pregnant, tampon, week, day, early', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'intruder': 'tampon', 'detectedIntruder': 'tampon', 'success': 1}, '1': {'top 5 sample': ['find', 'midwife', 'size', 'good', 'check'], 'wordliststr': 'midwife, size, find, check, good, tampon', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'intruder': 'tampon', 'detectedIntruder': 'tampon', 'success': 1}, '2': {'top 5 sample': ['tampon', 'flow', 'change', 'wear', 'day'], 'wordliststr': 'doctor, day, tampon, change, wear, flow', 'rawLLMOP': 'The least related word in this set is: 000tampon000', 'intruder': 'doctor', 'detectedIntruder': 'tampon', 'success': 0}, '3': {'top 5 sample': ['leave', 'baby', 'work', 'kick', 'trimester'], 'wordliststr': 'work, trimester, baby, find, kick, leave', 'rawLLMOP': 'The least related word in this set is: 000kick000', 'intruder': 'fin...  \n",
       "9   {'0': {'top 5 sample': ['period', 'pill', 'pack', 'day', 'side_effect'], 'wordliststr': 'day, pill, side_effect, feel, period, pack', 'rawLLMOP': 'The least related word in this set is: 000side_effect000', 'intruder': 'feel', 'detectedIntruder': 'side_effect', 'success': 0}, '1': {'top 5 sample': ['breastfeed', 'baby', 'formula', 'eat', 'feed'], 'wordliststr': 'eat, feed, baby, back, breastfeed, formula', 'rawLLMOP': 'The least related word in this set is: 000back000', 'intruder': 'back', 'detectedIntruder': 'back', 'success': 1}, '2': {'top 5 sample': ['gain', 'week', 'weight', 'doctor', 'start'], 'wordliststr': 'doctor, gain, bit, start, weight, week', 'rawLLMOP': 'The least related word in this set is: 000bit000', 'intruder': 'bit', 'detectedIntruder': 'bit', 'success': 1}, '3': {'top 5 sample': ['push', 'labor', 'section', 'epidural', 'natural'], 'wordliststr': 'push, natural, epidural, start, section, labor', 'rawLLMOP': 'The least related word in this set is: 000epidural000',...  \n",
       "10  {'0': {'top 5 sample': ['delay_clamp', 'due_date_buddy', 'horrendous', 'cutip', 'shield'], 'wordliststr': 'lotion, shield, delay_clamp, due_date_buddy, horrendous, cutip', 'rawLLMOP': 'The least related word in this set is: horrendous', 'intruder': 'lotion', 'detectedIntruder': 'NOTDETECTED', 'success': 0}, '1': {'top 5 sample': ['offense', 'assault', 'battery', 'unpermitted', 'harmful_offensive'], 'wordliststr': 'battery, assault, harmful_offensive, slippage, offense, unpermitted', 'rawLLMOP': 'The least related word in this set is: 000assault000', 'intruder': 'slippage', 'detectedIntruder': 'assault', 'success': 0}, '2': {'top 5 sample': ['extender', 'due_date_buddy', 'horrendous', 'literally', 'strapon'], 'wordliststr': 'destine, strapon, literally, extender, horrendous, due_date_buddy', 'rawLLMOP': 'The least related word in this set is: 000strapon000', 'intruder': 'destine', 'detectedIntruder': 'strapon', 'success': 0}, '3': {'top 5 sample': ['colonoscopy', 'ulcerative', 'gast...  \n",
       "11  {'0': {'top 5 sample': ['smp', 'lange', 'donate_cord', 'cutip', 'due_date_buddy'], 'wordliststr': 'stretch_mark, smp, donate_cord, due_date_buddy, lange, cutip', 'rawLLMOP': 'The least related word in this set is: 000smoothing_iron000', 'intruder': 'stretch_mark', 'detectedIntruder': 'smoothing_iron', 'success': 0}, '1': {'top 5 sample': ['shield', 'stretch_mark', 'slippage', 'delay_clamp', 'due_date_buddy'], 'wordliststr': 'stretch_mark, due_date_buddy, shield, delay_clamp, hydrogel, slippage', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'intruder': 'hydrogel', 'detectedIntruder': 'shield', 'success': 0}, '2': {'top 5 sample': ['minor', 'unconsente', 'cut', 'circumcise', 'ceremony'], 'wordliststr': 'circumcise, minor, kilogram, ceremony, unconsente, cut', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'intruder': 'kilogram', 'detectedIntruder': 'kilogram', 'success': 1}, '3': {'top 5 sample': ['advanced', 'chub', 'ozzydog', 'swollen', '...  \n",
       "12  {'0': {'top 5 sample': ['criminal', 'due_date_buddy', 'threat', 'harmful_offensive', 'offense'], 'wordliststr': 'criminal, due_date_buddy, harmful_offensive, conduct, threat, offense', 'rawLLMOP': 'The least related word in this set is: 000due_date_buddy000', 'intruder': 'conduct', 'detectedIntruder': 'due_date_buddy', 'success': 0}, '1': {'top 5 sample': ['ovarian', 'hysterectomy', 'poly', 'cystic', 'smile'], 'wordliststr': 'ovarian, conduct, smile, cystic, poly, hysterectomy', 'rawLLMOP': 'The least related word in this set is: 000smile000', 'intruder': 'conduct', 'detectedIntruder': 'smile', 'success': 0}, '2': {'top 5 sample': ['ozzydog', 'lbs', 'jump', 'pitbull', 'yike'], 'wordliststr': 'ozzydog, yike, jump, conduct, pitbull, lbs', 'rawLLMOP': 'The least related word in this set is: 000yike000', 'intruder': 'conduct', 'detectedIntruder': 'yike', 'success': 0}, '3': {'top 5 sample': ['due_date_buddy', 'slippage', 'smp', 'shield', 'delay_clamp'], 'wordliststr': 'smp, slippage, d...  \n",
       "13  {'0': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'wordliststr': 'delay_clamp, horrendous, smp, shield, donate_cord, battery', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'battery', 'detectedIntruder': 'horrendous', 'success': 0}, '1': {'top 5 sample': ['gastroscopy', 'rule', 'soother', 'colonoscopy', 'celiac_disease'], 'wordliststr': 'soother, gastroscopy, colonoscopy, celiac_disease, rule, twosie', 'rawLLMOP': 'In this case, the least related word to all other words in terms of meaning is: 000twosie000', 'intruder': 'twosie', 'detectedIntruder': 'twosie', 'success': 1}, '2': {'top 5 sample': ['horrendous', 'smp', 'donate_cord', 'shield', 'delay_clamp'], 'wordliststr': 'donate_cord, horrendous, shield, smp, battery, delay_clamp', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'battery', 'detectedIntruder': 'horrendous', 'success': 0}, '3': {'top 5 sample': ['horrendous', ...  \n",
       "14  {'0': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'wordliststr': 'due_date_buddy, delay_clamp, donate_cord, shield, germ, horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'germ', 'detectedIntruder': 'horrendous', 'success': 0}, '1': {'top 5 sample': ['baby', 'week', 'time', 'day', 'woman'], 'wordliststr': 'time, week, woman, day, baby, horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'horrendous', 'detectedIntruder': 'horrendous', 'success': 1}, '2': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'donate_cord'], 'wordliststr': 'delay_clamp, due_date_buddy, shield, germ, donate_cord, horrendous', 'rawLLMOP': 'The least related word in this set is: 000horrendous000', 'intruder': 'germ', 'detectedIntruder': 'horrendous', 'success': 0}, '3': {'top 5 sample': ['due_date_buddy', 'horrendous', 'shield', 'delay_clamp', 'don...  \n",
       "15  {'0': {'top 5 sample': ['hereditary', 'horrendous', 'kilogram', 'ozzydog', 'endometriosis'], 'wordliststr': 'week, ozzydog, kilogram, horrendous, hereditary, endometriosis', 'rawLLMOP': 'The least related word in this set is: 000ozzydog000', 'intruder': 'week', 'detectedIntruder': 'ozzydog', 'success': 0}, '1': {'top 5 sample': ['ive', 'horrendous', 'kilogram', 'elastin', 'lotion'], 'wordliststr': 'elastin, ive, kilogram, mae, horrendous, lotion', 'rawLLMOP': 'The least related word in this set is: 000ive000', 'intruder': 'mae', 'detectedIntruder': 'ive', 'success': 0}, '2': {'top 5 sample': ['endometriosis', 'horrendous', 'kilogram', 'arthritis', 'lange'], 'wordliststr': 'lange, arthritis, kilogram, endometriosis, week, horrendous', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'intruder': 'week', 'detectedIntruder': 'kilogram', 'success': 0}, '3': {'top 5 sample': ['endometriosis', 'horrendous', 'kilogram', 'arthritis', 'lange'], 'wordliststr': 'lange, endo...  \n",
       "16  {'0': {'top 5 sample': ['purposely', 'weapon', 'deadly', 'reputable', 'injury'], 'wordliststr': 'flair, reputable, deadly, injury, weapon, purposely', 'rawLLMOP': 'The least related word in this set is: 000injury000', 'intruder': 'flair', 'detectedIntruder': 'injury', 'success': 0}, '1': {'top 5 sample': ['hereditary', 'due_date_buddy', 'shield', 'arthritis', 'horrendous'], 'wordliststr': 'horrendous, arthritis, due_date_buddy, hereditary, shield, squirmy', 'rawLLMOP': 'The least related word in this set is: 000squirmy000', 'intruder': 'squirmy', 'detectedIntruder': 'squirmy', 'success': 1}, '2': {'top 5 sample': ['lange', 'due_date_buddy', 'shield', 'ozzydog', 'horrendous'], 'wordliststr': 'shield, horrendous, ozzydog, squirmy, due_date_buddy, lange', 'rawLLMOP': 'The least related word in this set is: 000ozzydog000', 'intruder': 'squirmy', 'detectedIntruder': 'ozzydog', 'success': 0}, '3': {'top 5 sample': ['hereditary', 'due_date_buddy', 'arthritis', 'shield', 'horrendous'], 'wo...  \n",
       "17  {'0': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'wordliststr': 'arthritis, hereditary, endometriosis, conduct, shield, due_date_buddy', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'intruder': 'conduct', 'detectedIntruder': 'shield', 'success': 0}, '1': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'wordliststr': 'arthritis, hereditary, conduct, due_date_buddy, endometriosis, shield', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'intruder': 'conduct', 'detectedIntruder': 'shield', 'success': 0}, '2': {'top 5 sample': ['due_date_buddy', 'arthritis', 'shield', 'endometriosis', 'hereditary'], 'wordliststr': 'endometriosis, shield, due_date_buddy, arthritis, conduct, hereditary', 'rawLLMOP': 'The least related word in this set is: 000shield000', 'intruder': 'conduct', 'detectedIntruder': 'shield', 'success': 0}, '3': {'top 5 sample': ['due_date_buddy...  \n",
       "18  {'0': {'top 5 sample': ['kilogram', 'toxin', 'toxigenic', 'staph', 'agent'], 'wordliststr': 'staph, toxigenic, kilogram, agent, toxin, mae', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'intruder': 'mae', 'detectedIntruder': 'kilogram', 'success': 0}, '1': {'top 5 sample': ['kilogram', 'arthritis', 'stretch_mark', 'lange', 'endometriosis'], 'wordliststr': 'arthritis, stretch_mark, endometriosis, lange, ovarian, kilogram', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'intruder': 'ovarian', 'detectedIntruder': 'lange', 'success': 0}, '2': {'top 5 sample': ['kilogram', 'lange', 'delay_clamp', 'endometriosis', 'hereditary'], 'wordliststr': 'ovarian, hereditary, delay_clamp, kilogram, lange, endometriosis', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'intruder': 'ovarian', 'detectedIntruder': 'lange', 'success': 0}, '3': {'top 5 sample': ['kilogram', 'lange', 'stretch_mark', 'endometriosis', 'hereditary'], 'wordliststr':...  \n",
       "19  {'0': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'shield'], 'wordliststr': 'horrendous, shield, kilogram, endometriosis, mammogram, lange', 'rawLLMOP': 'The least related word in this set is: 000kilogram000', 'intruder': 'mammogram', 'detectedIntruder': 'kilogram', 'success': 0}, '1': {'top 5 sample': ['horrendous', 'kilogram', 'lange', 'endometriosis', 'stretch_mark'], 'wordliststr': 'mammogram, stretch_mark, horrendous, endometriosis, lange, kilogram', 'rawLLMOP': 'The least related word in this set is: 000lange000', 'intruder': 'mammogram', 'detectedIntruder': 'lange', 'success': 0}, '2': {'top 5 sample': ['horrendous', 'kilogram', 'muggle_blood', 'lange', 'arthritis'], 'wordliststr': 'kilogram, coat_factory, horrendous, arthritis, muggle_blood, lange', 'rawLLMOP': 'The least related word in this set is: 000coat_factory000', 'intruder': 'coat_factory', 'detectedIntruder': 'coat_factory', 'success': 1}, '3': {'top 5 sample': ['tad', 'surreal', 'anxious'...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top 5 sample</th>\n",
       "      <th>wordliststr</th>\n",
       "      <th>rawLLMOP</th>\n",
       "      <th>intruder</th>\n",
       "      <th>detectedIntruder</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>horrendous, shield, kilogram, endometriosis, mammogram, lange</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>mammogram, stretch_mark, horrendous, endometriosis, lange, kilogram</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[horrendous, kilogram, muggle_blood, lange, arthritis]</td>\n",
       "      <td>kilogram, coat_factory, horrendous, arthritis, muggle_blood, lange</td>\n",
       "      <td>The least related word in this set is: 000coat_factory000</td>\n",
       "      <td>coat_factory</td>\n",
       "      <td>coat_factory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tad, surreal, anxious, kilogram, endometriosis]</td>\n",
       "      <td>compute, anxious, endometriosis, kilogram, surreal, tad</td>\n",
       "      <td>The least related word in this set is: kilogram</td>\n",
       "      <td>compute</td>\n",
       "      <td>NOTDETECTED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>horrendous, shield, kilogram, mammogram, endometriosis, lange</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>ozzydog, lange, mammogram, shield, kilogram, horrendous</td>\n",
       "      <td>The least related word in this set is: 000horrendous000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>horrendous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>horrendous, mammogram, endometriosis, kilogram, lange, shield</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>lange, kilogram, shield, ozzydog, horrendous, mammogram</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>lange, kilogram, horrendous, mammogram, shield, ozzydog</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>shield, horrendous, mammogram, lange, endometriosis, kilogram</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>shield, mammogram, kilogram, ozzydog, lange, horrendous</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, hereditary]</td>\n",
       "      <td>endometriosis, horrendous, kilogram, hereditary, mammogram, lange</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>mammogram</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[pitbull, ozzydog, yike, lbs, horrendous]</td>\n",
       "      <td>horrendous, ozzydog, yike, lbs, pitbull, hopeful</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>hopeful</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[kilogram, elemental, horrendous, fumarate, due_date_buddy]</td>\n",
       "      <td>elemental, due_date_buddy, kilogram, horrendous, flutter, fumarate</td>\n",
       "      <td>The least related word in this set is: 000due_date_buddy000</td>\n",
       "      <td>flutter</td>\n",
       "      <td>due_date_buddy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[physiotherapy, torticolli, diagnose, kilogram, endometriosis]</td>\n",
       "      <td>physiotherapy, torticolli, muscle_twitch, diagnose, kilogram, endometriosis</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>muscle_twitch</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[horrendous, kilogram, endometriosis, hereditary, stretch_mark]</td>\n",
       "      <td>endometriosis, torticolli, kilogram, horrendous, hereditary, stretch_mark</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>ozzydog, torticolli, horrendous, shield, lange, kilogram</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>shield, lange, kilogram, endometriosis, torticolli, horrendous</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[caller, mammogram, fq_blog, giqaacw, congressional]</td>\n",
       "      <td>torticolli, giqaacw, mammogram, caller, fq_blog, congressional</td>\n",
       "      <td>The least related word in this set is: 000giqaacw000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>giqaacw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>torticolli, shield, lange, endometriosis, horrendous, kilogram</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000shield000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>shield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[anxious, surreal, aha, kilogram, endometriosis]</td>\n",
       "      <td>surreal, endometriosis, aha, kilogram, anxious, torticolli</td>\n",
       "      <td>The least related word in this set is: 000aha000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>aha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[horrendous, kilogram, bodily, injury, statute]</td>\n",
       "      <td>horrendous, bodily, injury, statute, torticolli, kilogram</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>kilogram, shield, horrendous, endometriosis, torticolli, lange</td>\n",
       "      <td>The least related word in this set is: 000endometriosis000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>endometriosis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[horrendous, kilogram, battery, lange, hereditary]</td>\n",
       "      <td>lange, torticolli, hereditary, battery, kilogram, horrendous</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>ozzydog, torticolli, shield, kilogram, horrendous, lange</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[elastin, lotion, palmer, preggie, combine]</td>\n",
       "      <td>palmer, preggie, combine, torticolli, lotion, elastin</td>\n",
       "      <td>The least related word in this set is: 000preggie000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>preggie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>shield, horrendous, torticolli, kilogram, ozzydog, lange</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[horrendous, kilogram, jewish, unconsente, tradition]</td>\n",
       "      <td>horrendous, kilogram, jewish, unconsente, torticolli, tradition</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[horrendous, kilogram, endometriosis, lange, shield]</td>\n",
       "      <td>lange, endometriosis, shield, horrendous, torticolli, kilogram</td>\n",
       "      <td>The least related word in this set is: 000shield000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>shield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[horrendous, kilogram, endometriosis, hereditary, shield]</td>\n",
       "      <td>hereditary, endometriosis, torticolli, shield, horrendous, kilogram</td>\n",
       "      <td>The least related word in this set is: 000shield000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>shield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>kilogram, lange, ozzydog, torticolli, horrendous, shield</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, stretch_mark]</td>\n",
       "      <td>torticolli, kilogram, lange, ozzydog, stretch_mark, horrendous</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>lange, endometriosis, kilogram, horrendous, torticolli, shield</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[horrendous, kilogram, conduct, lange, arthritis]</td>\n",
       "      <td>conduct, arthritis, torticolli, kilogram, lange, horrendous</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>stretch_mark, endometriosis, lange, torticolli, kilogram, horrendous</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[ovarian, endometriosis, smile, hysterectomy, horrendous]</td>\n",
       "      <td>hysterectomy, endometriosis, smile, ovarian, torticolli, horrendous</td>\n",
       "      <td>The least related word in this set is: 000smile000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>smile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>horrendous, torticolli, endometriosis, shield, kilogram, lange</td>\n",
       "      <td>The least related word in this set is: 000shield000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>shield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>lange, torticolli, horrendous, endometriosis, shield, kilogram</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>lange, ozzydog, shield, torticolli, kilogram, horrendous</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>lange, ozzydog, horrendous, shield, kilogram, torticolli</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, stretch_mark]</td>\n",
       "      <td>kilogram, horrendous, stretch_mark, torticolli, ozzydog, lange</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>stretch_mark, torticolli, horrendous, kilogram, lange, endometriosis</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>kilogram, shield, lange, torticolli, horrendous, ozzydog</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>lange, shield, torticolli, horrendous, endometriosis, kilogram</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>torticolli, endometriosis, lange, stretch_mark, kilogram, horrendous</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>endometriosis, lange, torticolli, horrendous, shield, kilogram</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>horrendous, endometriosis, kilogram, lange, shield, torticolli</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[injury, bodily, statute, negligently, deadly]</td>\n",
       "      <td>injury, bodily, deadly, negligently, torticolli, statute</td>\n",
       "      <td>The least related word in this set is: 000statute000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>statute</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>lange, torticolli, shield, kilogram, endometriosis, horrendous</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>shield, lange, kilogram, ozzydog, horrendous, torticolli</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[horrendous, kilogram, staph, agent, causative]</td>\n",
       "      <td>horrendous, staph, kilogram, agent, torticolli, causative</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[assault, battery, harmful_offensive, offense, offenses]</td>\n",
       "      <td>battery, torticolli, offenses, harmful_offensive, assault, offense</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>torticolli, horrendous, lange, endometriosis, kilogram, shield</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000horrendous000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>horrendous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[horrendous, kilogram, saliva, sebum, lange]</td>\n",
       "      <td>horrendous, torticolli, kilogram, saliva, lange, sebum</td>\n",
       "      <td>The least related word in this set is: 000saliva000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>saliva</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, hereditary]</td>\n",
       "      <td>ozzydog, lange, horrendous, hereditary, torticolli, kilogram</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[horrendous, kilogram, endometriosis, ovarian, hysterectomy]</td>\n",
       "      <td>endometriosis, torticolli, kilogram, ovarian, hysterectomy, horrendous</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[verbal, sexual_harassment, appearance, manner, history]</td>\n",
       "      <td>history, appearance, verbal, manner, sexual_harassment, torticolli</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>lange, kilogram, horrendous, endometriosis, torticolli, stretch_mark</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>kilogram, shield, torticolli, endometriosis, lange, horrendous</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>kilogram, horrendous, lange, endometriosis, shield, torticolli</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>shield, lange, horrendous, endometriosis, torticolli, kilogram</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>[nerdery, staph, toxigenic, toxin, cause]</td>\n",
       "      <td>toxigenic, cause, torticolli, toxin, staph, nerdery</td>\n",
       "      <td>The least related word in this set is: 000nerdery000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>nerdery</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>[kilogram, muggle_blood, due_date_buddy, lange, arthritis]</td>\n",
       "      <td>arthritis, lange, kilogram, torticolli, muggle_blood, due_date_buddy</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[assault, battery, harmful_offensive, offense, threat]</td>\n",
       "      <td>torticolli, harmful_offensive, assault, threat, offense, battery</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[sexual_harassment, kilogram, due_date_buddy, verbal, ass]</td>\n",
       "      <td>kilogram, due_date_buddy, sexual_harassment, ass, verbal, torticolli</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>ozzydog, shield, horrendous, torticolli, kilogram, lange</td>\n",
       "      <td>The least related word in this set is: 000horrendous000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>horrendous</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, stretch_mark]</td>\n",
       "      <td>horrendous, kilogram, stretch_mark, torticolli, ozzydog, lange</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[horrendous, kilogram, battery, assault, threat]</td>\n",
       "      <td>battery, horrendous, assault, threat, torticolli, kilogram</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>horrendous, lange, shield, endometriosis, torticolli, kilogram</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>kilogram, endometriosis, horrendous, lange, torticolli, shield</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>torticolli, endometriosis, lange, horrendous, kilogram, shield</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>kilogram, endometriosis, shield, lange, torticolli, horrendous</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000shield000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>shield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>lange, shield, endometriosis, torticolli, kilogram, horrendous</td>\n",
       "      <td>The least related word in this set is: 000endometriosis000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>endometriosis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>[horrendous, kilogram, surreal, anxious, ozzydog]</td>\n",
       "      <td>anxious, torticolli, ozzydog, surreal, horrendous, kilogram</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>endometriosis, torticolli, stretch_mark, horrendous, kilogram, lange</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>[horrendous, kilogram, endometriosis, hereditary, shield]</td>\n",
       "      <td>shield, endometriosis, horrendous, torticolli, kilogram, hereditary</td>\n",
       "      <td>The least related word in this set is: 000endometriosis000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>endometriosis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>horrendous, lange, shield, endometriosis, torticolli, kilogram</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>[horrendous, kilogram, ply, clog, endometriosis]</td>\n",
       "      <td>ply, torticolli, kilogram, clog, endometriosis, horrendous</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>kilogram, shield, lange, torticolli, endometriosis, horrendous</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>lange, shield, kilogram, torticolli, ozzydog, horrendous</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>kilogram, lange, horrendous, torticolli, shield, endometriosis</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>horrendous, lange, shield, kilogram, ozzydog, torticolli</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>[kilogram, muggle_blood, due_date_buddy, lange, arthritis]</td>\n",
       "      <td>kilogram, lange, muggle_blood, due_date_buddy, torticolli, arthritis</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>[discontinue, albuquerque, clearance_rack, shipping, item]</td>\n",
       "      <td>clearance_rack, albuquerque, torticolli, discontinue, shipping, item</td>\n",
       "      <td>The least related word in this set is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[horrendous, kilogram, endometriosis, hereditary, shield]</td>\n",
       "      <td>torticolli, kilogram, endometriosis, shield, hereditary, horrendous</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>shield, endometriosis, torticolli, horrendous, kilogram, lange</td>\n",
       "      <td>The least related word in this set is: 000endometriosis000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>endometriosis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, stretch_mark]</td>\n",
       "      <td>kilogram, stretch_mark, torticolli, ozzydog, lange, horrendous</td>\n",
       "      <td>The least related word in this set is: 000ozzydog000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>ozzydog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>horrendous, lange, endometriosis, torticolli, kilogram, stretch_mark</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>horrendous, torticolli, kilogram, lange, shield, endometriosis</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[horrendous, kilogram, lange, ozzydog, shield]</td>\n",
       "      <td>shield, lange, ozzydog, torticolli, kilogram, horrendous</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>horrendous, endometriosis, kilogram, torticolli, lange, stretch_mark</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, battery]</td>\n",
       "      <td>lange, torticolli, endometriosis, horrendous, kilogram, battery</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[horrendous, kilogram, stretch_mark, stripe, endometriosis]</td>\n",
       "      <td>endometriosis, torticolli, stretch_mark, horrendous, stripe, kilogram</td>\n",
       "      <td>The least related word in this set is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[horrendous, kilogram, endometriosis, lange, shield]</td>\n",
       "      <td>endometriosis, torticolli, horrendous, lange, shield, kilogram</td>\n",
       "      <td>The least related word in this set is: 000lange000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>lange</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>torticolli, endometriosis, shield, horrendous, kilogram, lange</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000shield000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>shield</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, stretch_mark]</td>\n",
       "      <td>horrendous, kilogram, lange, torticolli, endometriosis, stretch_mark</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>shield, kilogram, endometriosis, horrendous, lange, torticolli</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000kilogram000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>kilogram</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[baby, week, time, day, woman]</td>\n",
       "      <td>time, baby, week, torticolli, day, woman</td>\n",
       "      <td>The least related word in this set is: torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>NOTDETECTED</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[horrendous, kilogram, lange, endometriosis, shield]</td>\n",
       "      <td>shield, torticolli, endometriosis, lange, horrendous, kilogram</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000torticolli000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[horrendous, kilogram, ozzydog, lange, pitbull]</td>\n",
       "      <td>torticolli, pitbull, kilogram, horrendous, ozzydog, lange</td>\n",
       "      <td>In this case, the least related word to all other words in terms of meaning is: 000pitbull000</td>\n",
       "      <td>torticolli</td>\n",
       "      <td>pitbull</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       top 5 sample  \\\n",
       "0              [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "1        [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "2            [horrendous, kilogram, muggle_blood, lange, arthritis]   \n",
       "3                  [tad, surreal, anxious, kilogram, endometriosis]   \n",
       "4              [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "5                    [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "6              [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "7                    [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "8                    [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "9              [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "10                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "11         [horrendous, kilogram, lange, endometriosis, hereditary]   \n",
       "12                        [pitbull, ozzydog, yike, lbs, horrendous]   \n",
       "13      [kilogram, elemental, horrendous, fumarate, due_date_buddy]   \n",
       "14   [physiotherapy, torticolli, diagnose, kilogram, endometriosis]   \n",
       "15  [horrendous, kilogram, endometriosis, hereditary, stretch_mark]   \n",
       "16                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "17             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "18             [caller, mammogram, fq_blog, giqaacw, congressional]   \n",
       "19             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "20                 [anxious, surreal, aha, kilogram, endometriosis]   \n",
       "21                  [horrendous, kilogram, bodily, injury, statute]   \n",
       "22             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "23               [horrendous, kilogram, battery, lange, hereditary]   \n",
       "24                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "25                      [elastin, lotion, palmer, preggie, combine]   \n",
       "26                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "27            [horrendous, kilogram, jewish, unconsente, tradition]   \n",
       "28             [horrendous, kilogram, endometriosis, lange, shield]   \n",
       "29        [horrendous, kilogram, endometriosis, hereditary, shield]   \n",
       "30                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "31             [horrendous, kilogram, lange, ozzydog, stretch_mark]   \n",
       "32             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "33                [horrendous, kilogram, conduct, lange, arthritis]   \n",
       "34       [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "35        [ovarian, endometriosis, smile, hysterectomy, horrendous]   \n",
       "36             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "37             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "38                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "39                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "40             [horrendous, kilogram, lange, ozzydog, stretch_mark]   \n",
       "41       [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "42                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "43             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "44       [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "45             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "46             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "47                   [injury, bodily, statute, negligently, deadly]   \n",
       "48             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "49                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "50                  [horrendous, kilogram, staph, agent, causative]   \n",
       "51         [assault, battery, harmful_offensive, offense, offenses]   \n",
       "52             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "53                     [horrendous, kilogram, saliva, sebum, lange]   \n",
       "54               [horrendous, kilogram, lange, ozzydog, hereditary]   \n",
       "55     [horrendous, kilogram, endometriosis, ovarian, hysterectomy]   \n",
       "56         [verbal, sexual_harassment, appearance, manner, history]   \n",
       "57       [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "58             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "59             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "60             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "61                        [nerdery, staph, toxigenic, toxin, cause]   \n",
       "62       [kilogram, muggle_blood, due_date_buddy, lange, arthritis]   \n",
       "63           [assault, battery, harmful_offensive, offense, threat]   \n",
       "64       [sexual_harassment, kilogram, due_date_buddy, verbal, ass]   \n",
       "65                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "66             [horrendous, kilogram, lange, ozzydog, stretch_mark]   \n",
       "67                 [horrendous, kilogram, battery, assault, threat]   \n",
       "68             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "69             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "70             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "71             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "72             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "73                [horrendous, kilogram, surreal, anxious, ozzydog]   \n",
       "74       [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "75        [horrendous, kilogram, endometriosis, hereditary, shield]   \n",
       "76             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "77                 [horrendous, kilogram, ply, clog, endometriosis]   \n",
       "78             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "79                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "80             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "81                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "82       [kilogram, muggle_blood, due_date_buddy, lange, arthritis]   \n",
       "83       [discontinue, albuquerque, clearance_rack, shipping, item]   \n",
       "84        [horrendous, kilogram, endometriosis, hereditary, shield]   \n",
       "85             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "86             [horrendous, kilogram, lange, ozzydog, stretch_mark]   \n",
       "87       [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "88             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "89                   [horrendous, kilogram, lange, ozzydog, shield]   \n",
       "90       [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "91            [horrendous, kilogram, lange, endometriosis, battery]   \n",
       "92      [horrendous, kilogram, stretch_mark, stripe, endometriosis]   \n",
       "93             [horrendous, kilogram, endometriosis, lange, shield]   \n",
       "94             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "95       [horrendous, kilogram, lange, endometriosis, stretch_mark]   \n",
       "96             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "97                                   [baby, week, time, day, woman]   \n",
       "98             [horrendous, kilogram, lange, endometriosis, shield]   \n",
       "99                  [horrendous, kilogram, ozzydog, lange, pitbull]   \n",
       "\n",
       "                                                                    wordliststr  \\\n",
       "0                 horrendous, shield, kilogram, endometriosis, mammogram, lange   \n",
       "1           mammogram, stretch_mark, horrendous, endometriosis, lange, kilogram   \n",
       "2            kilogram, coat_factory, horrendous, arthritis, muggle_blood, lange   \n",
       "3                       compute, anxious, endometriosis, kilogram, surreal, tad   \n",
       "4                 horrendous, shield, kilogram, mammogram, endometriosis, lange   \n",
       "5                       ozzydog, lange, mammogram, shield, kilogram, horrendous   \n",
       "6                 horrendous, mammogram, endometriosis, kilogram, lange, shield   \n",
       "7                       lange, kilogram, shield, ozzydog, horrendous, mammogram   \n",
       "8                       lange, kilogram, horrendous, mammogram, shield, ozzydog   \n",
       "9                 shield, horrendous, mammogram, lange, endometriosis, kilogram   \n",
       "10                      shield, mammogram, kilogram, ozzydog, lange, horrendous   \n",
       "11            endometriosis, horrendous, kilogram, hereditary, mammogram, lange   \n",
       "12                             horrendous, ozzydog, yike, lbs, pitbull, hopeful   \n",
       "13           elemental, due_date_buddy, kilogram, horrendous, flutter, fumarate   \n",
       "14  physiotherapy, torticolli, muscle_twitch, diagnose, kilogram, endometriosis   \n",
       "15    endometriosis, torticolli, kilogram, horrendous, hereditary, stretch_mark   \n",
       "16                     ozzydog, torticolli, horrendous, shield, lange, kilogram   \n",
       "17               shield, lange, kilogram, endometriosis, torticolli, horrendous   \n",
       "18               torticolli, giqaacw, mammogram, caller, fq_blog, congressional   \n",
       "19               torticolli, shield, lange, endometriosis, horrendous, kilogram   \n",
       "20                   surreal, endometriosis, aha, kilogram, anxious, torticolli   \n",
       "21                    horrendous, bodily, injury, statute, torticolli, kilogram   \n",
       "22               kilogram, shield, horrendous, endometriosis, torticolli, lange   \n",
       "23                 lange, torticolli, hereditary, battery, kilogram, horrendous   \n",
       "24                     ozzydog, torticolli, shield, kilogram, horrendous, lange   \n",
       "25                        palmer, preggie, combine, torticolli, lotion, elastin   \n",
       "26                     shield, horrendous, torticolli, kilogram, ozzydog, lange   \n",
       "27              horrendous, kilogram, jewish, unconsente, torticolli, tradition   \n",
       "28               lange, endometriosis, shield, horrendous, torticolli, kilogram   \n",
       "29          hereditary, endometriosis, torticolli, shield, horrendous, kilogram   \n",
       "30                     kilogram, lange, ozzydog, torticolli, horrendous, shield   \n",
       "31               torticolli, kilogram, lange, ozzydog, stretch_mark, horrendous   \n",
       "32               lange, endometriosis, kilogram, horrendous, torticolli, shield   \n",
       "33                  conduct, arthritis, torticolli, kilogram, lange, horrendous   \n",
       "34         stretch_mark, endometriosis, lange, torticolli, kilogram, horrendous   \n",
       "35          hysterectomy, endometriosis, smile, ovarian, torticolli, horrendous   \n",
       "36               horrendous, torticolli, endometriosis, shield, kilogram, lange   \n",
       "37               lange, torticolli, horrendous, endometriosis, shield, kilogram   \n",
       "38                     lange, ozzydog, shield, torticolli, kilogram, horrendous   \n",
       "39                     lange, ozzydog, horrendous, shield, kilogram, torticolli   \n",
       "40               kilogram, horrendous, stretch_mark, torticolli, ozzydog, lange   \n",
       "41         stretch_mark, torticolli, horrendous, kilogram, lange, endometriosis   \n",
       "42                     kilogram, shield, lange, torticolli, horrendous, ozzydog   \n",
       "43               lange, shield, torticolli, horrendous, endometriosis, kilogram   \n",
       "44         torticolli, endometriosis, lange, stretch_mark, kilogram, horrendous   \n",
       "45               endometriosis, lange, torticolli, horrendous, shield, kilogram   \n",
       "46               horrendous, endometriosis, kilogram, lange, shield, torticolli   \n",
       "47                     injury, bodily, deadly, negligently, torticolli, statute   \n",
       "48               lange, torticolli, shield, kilogram, endometriosis, horrendous   \n",
       "49                     shield, lange, kilogram, ozzydog, horrendous, torticolli   \n",
       "50                    horrendous, staph, kilogram, agent, torticolli, causative   \n",
       "51           battery, torticolli, offenses, harmful_offensive, assault, offense   \n",
       "52               torticolli, horrendous, lange, endometriosis, kilogram, shield   \n",
       "53                       horrendous, torticolli, kilogram, saliva, lange, sebum   \n",
       "54                 ozzydog, lange, horrendous, hereditary, torticolli, kilogram   \n",
       "55       endometriosis, torticolli, kilogram, ovarian, hysterectomy, horrendous   \n",
       "56           history, appearance, verbal, manner, sexual_harassment, torticolli   \n",
       "57         lange, kilogram, horrendous, endometriosis, torticolli, stretch_mark   \n",
       "58               kilogram, shield, torticolli, endometriosis, lange, horrendous   \n",
       "59               kilogram, horrendous, lange, endometriosis, shield, torticolli   \n",
       "60               shield, lange, horrendous, endometriosis, torticolli, kilogram   \n",
       "61                          toxigenic, cause, torticolli, toxin, staph, nerdery   \n",
       "62         arthritis, lange, kilogram, torticolli, muggle_blood, due_date_buddy   \n",
       "63             torticolli, harmful_offensive, assault, threat, offense, battery   \n",
       "64         kilogram, due_date_buddy, sexual_harassment, ass, verbal, torticolli   \n",
       "65                     ozzydog, shield, horrendous, torticolli, kilogram, lange   \n",
       "66               horrendous, kilogram, stretch_mark, torticolli, ozzydog, lange   \n",
       "67                   battery, horrendous, assault, threat, torticolli, kilogram   \n",
       "68               horrendous, lange, shield, endometriosis, torticolli, kilogram   \n",
       "69               kilogram, endometriosis, horrendous, lange, torticolli, shield   \n",
       "70               torticolli, endometriosis, lange, horrendous, kilogram, shield   \n",
       "71               kilogram, endometriosis, shield, lange, torticolli, horrendous   \n",
       "72               lange, shield, endometriosis, torticolli, kilogram, horrendous   \n",
       "73                  anxious, torticolli, ozzydog, surreal, horrendous, kilogram   \n",
       "74         endometriosis, torticolli, stretch_mark, horrendous, kilogram, lange   \n",
       "75          shield, endometriosis, horrendous, torticolli, kilogram, hereditary   \n",
       "76               horrendous, lange, shield, endometriosis, torticolli, kilogram   \n",
       "77                   ply, torticolli, kilogram, clog, endometriosis, horrendous   \n",
       "78               kilogram, shield, lange, torticolli, endometriosis, horrendous   \n",
       "79                     lange, shield, kilogram, torticolli, ozzydog, horrendous   \n",
       "80               kilogram, lange, horrendous, torticolli, shield, endometriosis   \n",
       "81                     horrendous, lange, shield, kilogram, ozzydog, torticolli   \n",
       "82         kilogram, lange, muggle_blood, due_date_buddy, torticolli, arthritis   \n",
       "83         clearance_rack, albuquerque, torticolli, discontinue, shipping, item   \n",
       "84          torticolli, kilogram, endometriosis, shield, hereditary, horrendous   \n",
       "85               shield, endometriosis, torticolli, horrendous, kilogram, lange   \n",
       "86               kilogram, stretch_mark, torticolli, ozzydog, lange, horrendous   \n",
       "87         horrendous, lange, endometriosis, torticolli, kilogram, stretch_mark   \n",
       "88               horrendous, torticolli, kilogram, lange, shield, endometriosis   \n",
       "89                     shield, lange, ozzydog, torticolli, kilogram, horrendous   \n",
       "90         horrendous, endometriosis, kilogram, torticolli, lange, stretch_mark   \n",
       "91              lange, torticolli, endometriosis, horrendous, kilogram, battery   \n",
       "92        endometriosis, torticolli, stretch_mark, horrendous, stripe, kilogram   \n",
       "93               endometriosis, torticolli, horrendous, lange, shield, kilogram   \n",
       "94               torticolli, endometriosis, shield, horrendous, kilogram, lange   \n",
       "95         horrendous, kilogram, lange, torticolli, endometriosis, stretch_mark   \n",
       "96               shield, kilogram, endometriosis, horrendous, lange, torticolli   \n",
       "97                                     time, baby, week, torticolli, day, woman   \n",
       "98               shield, torticolli, endometriosis, lange, horrendous, kilogram   \n",
       "99                    torticolli, pitbull, kilogram, horrendous, ozzydog, lange   \n",
       "\n",
       "                                                                                            rawLLMOP  \\\n",
       "0                                              The least related word in this set is: 000kilogram000   \n",
       "1                                                 The least related word in this set is: 000lange000   \n",
       "2                                          The least related word in this set is: 000coat_factory000   \n",
       "3                                                    The least related word in this set is: kilogram   \n",
       "4                                              The least related word in this set is: 000kilogram000   \n",
       "5                                            The least related word in this set is: 000horrendous000   \n",
       "6                                                 The least related word in this set is: 000lange000   \n",
       "7                                               The least related word in this set is: 000ozzydog000   \n",
       "8                                               The least related word in this set is: 000ozzydog000   \n",
       "9                                              The least related word in this set is: 000kilogram000   \n",
       "10                                              The least related word in this set is: 000ozzydog000   \n",
       "11                                                The least related word in this set is: 000lange000   \n",
       "12                                              The least related word in this set is: 000ozzydog000   \n",
       "13                                       The least related word in this set is: 000due_date_buddy000   \n",
       "14                                             The least related word in this set is: 000kilogram000   \n",
       "15                                             The least related word in this set is: 000kilogram000   \n",
       "16  In this case, the least related word to all other words in terms of meaning is: 000torticolli000   \n",
       "17                                                The least related word in this set is: 000lange000   \n",
       "18                                              The least related word in this set is: 000giqaacw000   \n",
       "19      In this case, the least related word to all other words in terms of meaning is: 000shield000   \n",
       "20                                                  The least related word in this set is: 000aha000   \n",
       "21                                             The least related word in this set is: 000kilogram000   \n",
       "22                                        The least related word in this set is: 000endometriosis000   \n",
       "23                                             The least related word in this set is: 000kilogram000   \n",
       "24  In this case, the least related word to all other words in terms of meaning is: 000torticolli000   \n",
       "25                                              The least related word in this set is: 000preggie000   \n",
       "26                                              The least related word in this set is: 000ozzydog000   \n",
       "27                                             The least related word in this set is: 000kilogram000   \n",
       "28                                               The least related word in this set is: 000shield000   \n",
       "29                                               The least related word in this set is: 000shield000   \n",
       "30       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "31    In this case, the least related word to all other words in terms of meaning is: 000kilogram000   \n",
       "32                                             The least related word in this set is: 000kilogram000   \n",
       "33                                                The least related word in this set is: 000lange000   \n",
       "34                                                The least related word in this set is: 000lange000   \n",
       "35                                                The least related word in this set is: 000smile000   \n",
       "36                                               The least related word in this set is: 000shield000   \n",
       "37                                           The least related word in this set is: 000torticolli000   \n",
       "38                                              The least related word in this set is: 000ozzydog000   \n",
       "39                                              The least related word in this set is: 000ozzydog000   \n",
       "40                                              The least related word in this set is: 000ozzydog000   \n",
       "41                                             The least related word in this set is: 000kilogram000   \n",
       "42       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "43                                           The least related word in this set is: 000torticolli000   \n",
       "44                                                The least related word in this set is: 000lange000   \n",
       "45       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "46                                             The least related word in this set is: 000kilogram000   \n",
       "47                                              The least related word in this set is: 000statute000   \n",
       "48                                           The least related word in this set is: 000torticolli000   \n",
       "49       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "50    In this case, the least related word to all other words in terms of meaning is: 000kilogram000   \n",
       "51                                           The least related word in this set is: 000torticolli000   \n",
       "52  In this case, the least related word to all other words in terms of meaning is: 000horrendous000   \n",
       "53                                               The least related word in this set is: 000saliva000   \n",
       "54                                                The least related word in this set is: 000lange000   \n",
       "55                                             The least related word in this set is: 000kilogram000   \n",
       "56                                           The least related word in this set is: 000torticolli000   \n",
       "57    In this case, the least related word to all other words in terms of meaning is: 000kilogram000   \n",
       "58  In this case, the least related word to all other words in terms of meaning is: 000torticolli000   \n",
       "59       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "60                                                The least related word in this set is: 000lange000   \n",
       "61                                              The least related word in this set is: 000nerdery000   \n",
       "62                                                The least related word in this set is: 000lange000   \n",
       "63                                           The least related word in this set is: 000torticolli000   \n",
       "64                                           The least related word in this set is: 000torticolli000   \n",
       "65                                           The least related word in this set is: 000horrendous000   \n",
       "66    In this case, the least related word to all other words in terms of meaning is: 000kilogram000   \n",
       "67                                           The least related word in this set is: 000torticolli000   \n",
       "68                                                The least related word in this set is: 000lange000   \n",
       "69       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "70       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "71      In this case, the least related word to all other words in terms of meaning is: 000shield000   \n",
       "72                                        The least related word in this set is: 000endometriosis000   \n",
       "73  In this case, the least related word to all other words in terms of meaning is: 000torticolli000   \n",
       "74                                             The least related word in this set is: 000kilogram000   \n",
       "75                                        The least related word in this set is: 000endometriosis000   \n",
       "76                                                The least related word in this set is: 000lange000   \n",
       "77                                           The least related word in this set is: 000torticolli000   \n",
       "78       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "79                                           The least related word in this set is: 000torticolli000   \n",
       "80                                                The least related word in this set is: 000lange000   \n",
       "81                                                The least related word in this set is: 000lange000   \n",
       "82       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "83                                           The least related word in this set is: 000torticolli000   \n",
       "84                                             The least related word in this set is: 000kilogram000   \n",
       "85                                        The least related word in this set is: 000endometriosis000   \n",
       "86                                              The least related word in this set is: 000ozzydog000   \n",
       "87       In this case, the least related word to all other words in terms of meaning is: 000lange000   \n",
       "88                                             The least related word in this set is: 000kilogram000   \n",
       "89                                                The least related word in this set is: 000lange000   \n",
       "90    In this case, the least related word to all other words in terms of meaning is: 000kilogram000   \n",
       "91                                             The least related word in this set is: 000kilogram000   \n",
       "92                                             The least related word in this set is: 000kilogram000   \n",
       "93                                                The least related word in this set is: 000lange000   \n",
       "94      In this case, the least related word to all other words in terms of meaning is: 000shield000   \n",
       "95    In this case, the least related word to all other words in terms of meaning is: 000kilogram000   \n",
       "96    In this case, the least related word to all other words in terms of meaning is: 000kilogram000   \n",
       "97                                                 The least related word in this set is: torticolli   \n",
       "98  In this case, the least related word to all other words in terms of meaning is: 000torticolli000   \n",
       "99     In this case, the least related word to all other words in terms of meaning is: 000pitbull000   \n",
       "\n",
       "         intruder detectedIntruder  success  \n",
       "0       mammogram         kilogram        0  \n",
       "1       mammogram            lange        0  \n",
       "2    coat_factory     coat_factory        1  \n",
       "3         compute      NOTDETECTED        0  \n",
       "4       mammogram         kilogram        0  \n",
       "5       mammogram       horrendous        0  \n",
       "6       mammogram            lange        0  \n",
       "7       mammogram          ozzydog        0  \n",
       "8       mammogram          ozzydog        0  \n",
       "9       mammogram         kilogram        0  \n",
       "10      mammogram          ozzydog        0  \n",
       "11      mammogram            lange        0  \n",
       "12        hopeful          ozzydog        0  \n",
       "13        flutter   due_date_buddy        0  \n",
       "14  muscle_twitch         kilogram        0  \n",
       "15     torticolli         kilogram        0  \n",
       "16     torticolli       torticolli        1  \n",
       "17     torticolli            lange        0  \n",
       "18     torticolli          giqaacw        0  \n",
       "19     torticolli           shield        0  \n",
       "20     torticolli              aha        0  \n",
       "21     torticolli         kilogram        0  \n",
       "22     torticolli    endometriosis        0  \n",
       "23     torticolli         kilogram        0  \n",
       "24     torticolli       torticolli        1  \n",
       "25     torticolli          preggie        0  \n",
       "26     torticolli          ozzydog        0  \n",
       "27     torticolli         kilogram        0  \n",
       "28     torticolli           shield        0  \n",
       "29     torticolli           shield        0  \n",
       "30     torticolli            lange        0  \n",
       "31     torticolli         kilogram        0  \n",
       "32     torticolli         kilogram        0  \n",
       "33     torticolli            lange        0  \n",
       "34     torticolli            lange        0  \n",
       "35     torticolli            smile        0  \n",
       "36     torticolli           shield        0  \n",
       "37     torticolli       torticolli        1  \n",
       "38     torticolli          ozzydog        0  \n",
       "39     torticolli          ozzydog        0  \n",
       "40     torticolli          ozzydog        0  \n",
       "41     torticolli         kilogram        0  \n",
       "42     torticolli            lange        0  \n",
       "43     torticolli       torticolli        1  \n",
       "44     torticolli            lange        0  \n",
       "45     torticolli            lange        0  \n",
       "46     torticolli         kilogram        0  \n",
       "47     torticolli          statute        0  \n",
       "48     torticolli       torticolli        1  \n",
       "49     torticolli            lange        0  \n",
       "50     torticolli         kilogram        0  \n",
       "51     torticolli       torticolli        1  \n",
       "52     torticolli       horrendous        0  \n",
       "53     torticolli           saliva        0  \n",
       "54     torticolli            lange        0  \n",
       "55     torticolli         kilogram        0  \n",
       "56     torticolli       torticolli        1  \n",
       "57     torticolli         kilogram        0  \n",
       "58     torticolli       torticolli        1  \n",
       "59     torticolli            lange        0  \n",
       "60     torticolli            lange        0  \n",
       "61     torticolli          nerdery        0  \n",
       "62     torticolli            lange        0  \n",
       "63     torticolli       torticolli        1  \n",
       "64     torticolli       torticolli        1  \n",
       "65     torticolli       horrendous        0  \n",
       "66     torticolli         kilogram        0  \n",
       "67     torticolli       torticolli        1  \n",
       "68     torticolli            lange        0  \n",
       "69     torticolli            lange        0  \n",
       "70     torticolli            lange        0  \n",
       "71     torticolli           shield        0  \n",
       "72     torticolli    endometriosis        0  \n",
       "73     torticolli       torticolli        1  \n",
       "74     torticolli         kilogram        0  \n",
       "75     torticolli    endometriosis        0  \n",
       "76     torticolli            lange        0  \n",
       "77     torticolli       torticolli        1  \n",
       "78     torticolli            lange        0  \n",
       "79     torticolli       torticolli        1  \n",
       "80     torticolli            lange        0  \n",
       "81     torticolli            lange        0  \n",
       "82     torticolli            lange        0  \n",
       "83     torticolli       torticolli        1  \n",
       "84     torticolli         kilogram        0  \n",
       "85     torticolli    endometriosis        0  \n",
       "86     torticolli          ozzydog        0  \n",
       "87     torticolli            lange        0  \n",
       "88     torticolli         kilogram        0  \n",
       "89     torticolli            lange        0  \n",
       "90     torticolli         kilogram        0  \n",
       "91     torticolli         kilogram        0  \n",
       "92     torticolli         kilogram        0  \n",
       "93     torticolli            lange        0  \n",
       "94     torticolli           shield        0  \n",
       "95     torticolli         kilogram        0  \n",
       "96     torticolli         kilogram        0  \n",
       "97     torticolli      NOTDETECTED        0  \n",
       "98     torticolli       torticolli        1  \n",
       "99     torticolli          pitbull        0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(dict(data.tail(1)['data'])[19], orient= 'index')[['top 5 sample', 'wordliststr', 'rawLLMOP', 'intruder', 'detectedIntruder', 'success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Without dataset description\n",
    "# dataDesc = \"\"\"\"\"\"\n",
    "# dataDesc = \"\"\"\n",
    "# This is a dataset of words\n",
    "# \"\"\"\n",
    "# # dataDesc = \"\"\"\n",
    "# # The topic modelling is based on a corpus of reddit posts relating to maternal health. \n",
    "# # The data from which topics are extracted includes topics like abortion and sexuality.\n",
    "# # \"\"\"\n",
    "\n",
    "# for k, v in data.items():\n",
    "#     wordList = v['top 5 sample'] + [v['intruder']]\n",
    "#     random.shuffle(wordList)\n",
    "#     wordListStr = \", \".join(wordList)\n",
    "#     trueIntruder = v['intruder']\n",
    "#     detectedIntruder = 'NOTDETECTED'\n",
    "#     ans = llmChain({'datasetDescription': dataDesc, 'listOfWords': wordListStr})\n",
    "#     regSearch = re.search(r'000(.*?)000', ans['text'])\n",
    "#     data[k]['wordlist'] = wordList\n",
    "#     data[k]['wordliststr'] = wordListStr\n",
    "#     if regSearch:\n",
    "#         detectedIntruder = regSearch.group(1)\n",
    "#     data[k]['detectedIntruder'] = detectedIntruder\n",
    "#     data[k]['rawLLMOP'] = ans['text']\n",
    "#     if trueIntruder.lower() == detectedIntruder.lower():\n",
    "#         data[k]['success'] = 1\n",
    "#     else:\n",
    "#         data[k]['success'] = 0\n",
    "\n",
    "# df = pd.DataFrame.from_dict(data, orient='index')\n",
    "# rate = df['success'].sum() / len(df)\n",
    "# rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "##pd.DataFrame.from_dict(dict(data.head(1)['data'])[0], orient= 'index')\n",
    "#dict(data.head(1)[['data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict(data, orient= 'index')[['top 5 sample', 'wordliststr', 'rawLLMOP', 'intruder', 'detectedIntruder', 'success']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\n",
    "    'display.max_colwidth', 1000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
