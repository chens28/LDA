{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a57ecf0",
   "metadata": {},
   "source": [
    "# Part II: Mallet LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85a34257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run functions notbook\n",
    "%run ../functions/mallet_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a4cf91",
   "metadata": {},
   "source": [
    "### Load Processed Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "682f8e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buy guess flow heavy sort thing back tampon']\n",
      "24510\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../../data/train_clean.txt\"\n",
    "        \n",
    "training_data = load_processed_text(file_path)\n",
    "print(training_data[:1])\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380c336",
   "metadata": {},
   "source": [
    "### Mallet Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a17c7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mallet = 'C:/mallet/bin/mallet'  # CHANGE THIS TO YOUR MALLET PATH\n",
    "output_directory_path = 'C:/mallet/lda-data' # CHANGE THIS TO YOUR OUTPUT DIRECTORY\n",
    "\n",
    "path_to_training_data           = output_directory_path + '/training.txt'\n",
    "path_to_formatted_training_data = output_directory_path + '/mallet.training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d36c3528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "import_data(path_to_mallet,\n",
    "                path_to_training_data,\n",
    "                path_to_formatted_training_data,\n",
    "                training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2609ed0",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "204f7aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['buy', 'guess', 'flow', 'heavy', 'sort', 'thing', 'back', 'tampon']]\n"
     ]
    }
   ],
   "source": [
    "# Create Corpus\n",
    "texts = [doc.split() for doc in training_data]\n",
    "print(texts[:1])\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(texts)\n",
    "\n",
    "# mallet paths\n",
    "path_to_model                   = output_directory_path + '/mallet.model.' + str(num_topics)\n",
    "path_to_topic_keys              = output_directory_path + '/mallet.topic_keys.' + str(num_topics) + '.txt'\n",
    "path_to_topic_distributions     = output_directory_path + '/mallet.topic_distributions.' + str(num_topics) + '.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f3360e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training topic model...\n",
      "Complete\n",
      "\n",
      "Coherence Score (Top Words): 0.6493448917887764\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_topic_model(path_to_mallet,\n",
    "                  path_to_formatted_training_data,\n",
    "                  path_to_topic_keys,\n",
    "                  path_to_topic_distributions,\n",
    "                  num_topics= 20,\n",
    "                  param = 10,\n",
    "                  random_state = 42)\n",
    "\n",
    "# load topic words\n",
    "topic_words = load_topic_words(path_to_topic_keys)\n",
    "\n",
    "# Compute Coherence Score using top 50 words in each topics\n",
    "coherence_model_top_words = models.CoherenceModel(topics=topic_words, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_score_top_words = coherence_model_top_words.get_coherence()\n",
    "print('\\nCoherence Score (Top Words):', coherence_score_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af40e27",
   "metadata": {},
   "source": [
    "### Tune LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8e4bab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[836]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeds Generation\n",
    "seeds = generate_random_seeds(2)\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da0e3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params Grid\n",
    "num_topics = [10,20]\n",
    "\n",
    "grid = {'param': [5, 10, 20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lda_mallet(texts, id2word, num_topics, seeds, grid):\n",
    "    '''\n",
    "    tune lda for each num_topics and seeds using grid search\n",
    "    '''\n",
    "    results = []\n",
    "\n",
    "    total_iter = len(num_topics)*len(seeds)*len(grid['alpha']) * len(grid['eta'])\n",
    "    progress_bar = tqdm(total=total_iter, desc=\"Total progress\")\n",
    "    \n",
    "    for k in num_topics:\n",
    "        \n",
    "        for seed in seeds:\n",
    "            \n",
    "            # tune lda\n",
    "            best_model = None\n",
    "            best_score = float('-inf')\n",
    "            best_alpha = None\n",
    "            best_eta = None\n",
    "            \n",
    "            for alpha in grid['alpha']:\n",
    "                for eta in grid['eta']:\n",
    "                    model = models.ldamodel.LdaModel(\n",
    "                                corpus=corpus,\n",
    "                                id2word=id2word,\n",
    "                                num_topics=k,\n",
    "                                random_state=seed,\n",
    "                                chunksize=1000,\n",
    "                                passes=10,\n",
    "                                iterations=50,\n",
    "                                update_every = 1,\n",
    "                                alpha=alpha,\n",
    "                                eta=eta,  \n",
    "                                eval_every=None)\n",
    "                    \n",
    "                    top_words = [[word for word, _ in model.show_topic(i, topn=50)] for i in range(k)]\n",
    "                    coherence_model = models.CoherenceModel(topics=top_words, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "                    score = coherence_model.get_coherence()\n",
    "                        \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_model = model\n",
    "                        best_alpha = alpha\n",
    "                        best_eta = eta\n",
    "              \n",
    "                    progress_bar.update(1)\n",
    "            \n",
    "            \n",
    "            # make tests\n",
    "            tests = prepare_gensim_tests(seed, best_model)\n",
    "            \n",
    "            results.append({\n",
    "                    'num_topics': k,\n",
    "                    'seed': seed,\n",
    "                    'score': best_score,\n",
    "                    'alpha': best_alpha,\n",
    "                    'eta': best_eta,\n",
    "                    'tests': tests})\n",
    "    \n",
    "    progress_bar.close()\n",
    "   \n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e5a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d985a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
