{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1b44792",
   "metadata": {},
   "source": [
    "# Part II: Gensim LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20368ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run functions notbook\n",
    "%run ../functions/gensim_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75957dd1",
   "metadata": {},
   "source": [
    "### Seeds Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27544975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1139, 1585, 5442, 8411, 5060])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = generate_random_seeds(5)\n",
    "seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e505a3",
   "metadata": {},
   "source": [
    "### Load Processed Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "806ab36b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['buy', 'guess', 'flow', 'heavy', 'sort', 'thing', 'back', 'tampon']]\n",
      "24510\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../../data/train_clean.txt\"\n",
    "        \n",
    "processed_ngrams = load_processed_text(file_path)\n",
    "print(processed_ngrams[:1])\n",
    "print(len(processed_ngrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7755a35",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55a195b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(processed_ngrams)\n",
    "\n",
    "# Create Corpus\n",
    "texts = processed_ngrams\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "962d7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -9.329036690349717\n",
      "Wall time: 56.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=20,\n",
    "    random_state=42,\n",
    "    chunksize=1000,\n",
    "    passes=10,\n",
    "    iterations=100,\n",
    "    update_every = 1,\n",
    "    alpha='auto',\n",
    "    eta='auto',  \n",
    "    eval_every=None # helps to train faster\n",
    ")\n",
    "print('\\nPerplexity: ', model.log_perplexity(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c251a534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.5331070305996004\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = models.CoherenceModel(model=model, texts=processed_ngrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a148b6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score (Top Words):  0.5331070305996004\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract top 50 words for each topic and create texts representing top words for each topic\n",
    "top_words_texts = [[word for word, _ in model.show_topic(i, topn=50)] for i in range(20)]\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda_top_words = models.CoherenceModel(topics=top_words_texts, texts=processed_ngrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda_top_words = coherence_model_lda_top_words.get_coherence()\n",
    "print('\\nCoherence Score (Top Words): ', coherence_lda_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f787de3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33286106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a78486f",
   "metadata": {},
   "source": [
    "### Tune LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9418a36e",
   "metadata": {},
   "source": [
    "### K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "\n",
    "grid = {'alpha': ['auto', 0.01, 0.1, 1.0],  \n",
    "        'eta': ['auto', 0.01, 0.1, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962fad27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "total_iterations = seeds.shape[0]\n",
    "intrusion_tests = {}\n",
    "\n",
    "progress_bar = tqdm(total=total_iterations, desc=\"Running for seed\")\n",
    "for i, seed in enumerate(seeds):\n",
    "    # tune lda\n",
    "    best_lda_model, best_score, best_alpha, best_eta = tune_lda(seed, corpus, id2word, num_topics, grid)\n",
    "    print(\"Best Model Perplexity:\", best_score)\n",
    "    \n",
    "    # make tests\n",
    "    tests = prepare_gensim_tests(seed, best_lda_model)\n",
    "    intrusion_tests[i] = {'seed': seed, 'tests': tests,\n",
    "                          'alpha': best_alpha, 'eta': best_eta} \n",
    "    \n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01537cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intrusion_tests.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06dc744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gensim = pd.DataFrame(intrusion_tests).transpose()\n",
    "k_values = [10, 10, 10, 10, 10]\n",
    "df_gensim.insert(loc=0, column='k', value=k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21207bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a228755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a85f87b8",
   "metadata": {},
   "source": [
    "### K=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7aae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 20\n",
    "\n",
    "grid = {'alpha': ['auto', 0.01, 0.1, 1.0],  \n",
    "        'eta': ['auto', 0.01, 0.1, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = seeds.shape[0]\n",
    "intrusion_tests_20 = {}\n",
    "\n",
    "progress_bar = tqdm(total=total_iterations, desc=\"Running for seed\")\n",
    "for i, seed in enumerate(seeds):\n",
    "    # tune lda\n",
    "    best_lda_model, best_score, best_alpha, best_eta = tune_lda(seed, corpus, id2word, num_topics, grid)\n",
    "    print(\"Best Model Perplexity:\", best_score)\n",
    "    \n",
    "    # make tests\n",
    "    tests = prepare_gensim_tests(seed, best_lda_model)\n",
    "    intrusion_tests_20[i] = {'k': num_topics, 'seed': seed, 'tests': tests,\n",
    "                          'alpha': best_alpha, 'eta': best_eta} \n",
    "    \n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99899187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67caa45c",
   "metadata": {},
   "source": [
    "### K=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed8936",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 50\n",
    "\n",
    "grid = {'alpha': ['auto', 0.01, 0.1, 1.0],  \n",
    "        'eta': ['auto', 0.01, 0.1, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a44e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = seeds.shape[0]\n",
    "intrusion_tests_50 = {}\n",
    "\n",
    "progress_bar = tqdm(total=total_iterations, desc=\"Running for seed\")\n",
    "for i, seed in enumerate(seeds):\n",
    "    # tune lda\n",
    "    best_lda_model, best_score, best_alpha, best_eta = tune_lda(seed, corpus, id2word, num_topics, grid)\n",
    "    print(\"Best Model Perplexity:\", best_score)\n",
    "    \n",
    "    # make tests\n",
    "    tests = prepare_gensim_tests(seed, best_lda_model)\n",
    "    intrusion_tests_50[i] = {'seed': seed, 'tests': tests,\n",
    "                          'alpha': best_alpha, 'eta': best_eta} \n",
    "    \n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eecad09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3a0ad28",
   "metadata": {},
   "source": [
    "### K=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d603ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 100\n",
    "\n",
    "grid = {'alpha': ['auto', 0.01, 0.1, 1.0],  \n",
    "        'eta': ['auto', 0.01, 0.1, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = seeds.shape[0]\n",
    "intrusion_tests_100 = {}\n",
    "\n",
    "progress_bar = tqdm(total=total_iterations, desc=\"Running for seed\")\n",
    "for i, seed in enumerate(seeds):\n",
    "    # tune lda\n",
    "    best_lda_model, best_score, best_alpha, best_eta = tune_lda(seed, corpus, id2word, num_topics, grid)\n",
    "    print(\"Best Model Perplexity:\", best_score)\n",
    "    \n",
    "    # make tests\n",
    "    tests = prepare_gensim_tests(seed, best_lda_model)\n",
    "    intrusion_tests_100[i] = {'seed': seed, 'tests': tests,\n",
    "                          'alpha': best_alpha, 'eta': best_eta} \n",
    "    \n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04259ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
