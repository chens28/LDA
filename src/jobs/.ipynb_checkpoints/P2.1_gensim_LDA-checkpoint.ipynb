{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39847e2d",
   "metadata": {},
   "source": [
    "# Part II: Gensim LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78eb2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run functions notbook\n",
    "%run ../functions/gensim_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621f711",
   "metadata": {},
   "source": [
    "### Load Processed Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb73ea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['buy', 'guess', 'flow', 'heavy', 'sort', 'thing', 'back', 'tampon']]\n",
      "24510\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../../data/train_clean.txt\"\n",
    "        \n",
    "processed_ngrams = load_processed_text(file_path)\n",
    "print(processed_ngrams[:1])\n",
    "print(len(processed_ngrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a6d35",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ca775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(processed_ngrams)\n",
    "\n",
    "# Create Corpus\n",
    "texts = processed_ngrams\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea14b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score: 0.5294372097749029\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LDA Model\n",
    "model = models.ldamodel.LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=20,\n",
    "    random_state=42,\n",
    "    chunksize=1000,\n",
    "    passes=10,\n",
    "    iterations=50,\n",
    "    update_every = 1,\n",
    "    alpha='auto',\n",
    "    eta='auto',  \n",
    "    eval_every=None # helps to train faster\n",
    ")\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model = models.CoherenceModel(model=model, texts=processed_ngrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_score = coherence_model.get_coherence()\n",
    "print('\\nCoherence Score:', coherence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2d0cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score (Top Words): 0.5294372097749029\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Extract top 50 words for each topic and create texts representing top words for each topic\n",
    "top_words_texts = [[word for word, _ in model.show_topic(i, topn=50)] for i in range(20)]\n",
    "top_words_texts\n",
    "\n",
    "# Compute Coherence Score using top 50 words in each topics\n",
    "coherence_model_top_words = models.CoherenceModel(topics=top_words_texts, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_score_top_words = coherence_model_top_words.get_coherence()\n",
    "print('\\nCoherence Score (Top Words):', coherence_score_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe9039d",
   "metadata": {},
   "source": [
    "### Tune LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e27cf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1928, 3328, 1062, 3953, 1172]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeds Generation\n",
    "seeds = generate_random_seeds(5)\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1a3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params Grid\n",
    "num_topics = [10, 20, 50, 100]\n",
    "\n",
    "grid = {'alpha': ['symmetric','asymmetric','auto', 10, 0.1, 0.01],  \n",
    "        'eta': [None, 'symmetric', 'auto', 10, 0.1, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa05eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total progress: 100%|█████████████████████████████████████████████████████████████| 720/720 [14:19:26<00:00, 71.62s/it]\n"
     ]
    }
   ],
   "source": [
    "df = tune_lda_grid(texts, corpus, id2word, num_topics, seeds, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9563b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_topics</th>\n",
       "      <th>seed</th>\n",
       "      <th>score</th>\n",
       "      <th>alpha</th>\n",
       "      <th>eta</th>\n",
       "      <th>tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.615142</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{0: {'top 5 sample': ['start', 'time', 'feel',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.632058</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{0: {'top 5 sample': ['iud', 'month', 'bad', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.640627</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{0: {'top 5 sample': ['cup', 'flow', 'partner'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.633518</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{0: {'top 5 sample': ['pregnancy', 'early', 't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.648327</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{0: {'top 5 sample': ['control', 'pill', 'take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.557930</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{0: {'top 5 sample': ['good', 'time', 'feel', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.574971</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{0: {'top 5 sample': ['feel', 'time', 'ultraso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.561865</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{0: {'top 5 sample': ['pad', 'sex', 'clean', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.563291</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{0: {'top 5 sample': ['week', 'doctor', 'day',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.585560</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>{0: {'top 5 sample': ['period', 'pill', 'pack'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.612763</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['delay_clamp', 'due_date...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.631923</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['smp', 'lange', 'donate_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.629078</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['criminal', 'due_date_bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.657174</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['horrendous', 'smp', 'do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.622675</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['due_date_buddy', 'horre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.634541</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['hereditary', 'horrendou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>3328</td>\n",
       "      <td>0.666028</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['purposely', 'weapon', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>1062</td>\n",
       "      <td>0.662159</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['due_date_buddy', 'arthr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>3953</td>\n",
       "      <td>0.651841</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['kilogram', 'toxin', 'to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>1172</td>\n",
       "      <td>0.642149</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.00</td>\n",
       "      <td>{0: {'top 5 sample': ['horrendous', 'kilogram'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_topics  seed     score       alpha    eta  \\\n",
       "0           10  1928  0.615142  asymmetric   0.01   \n",
       "1           10  3328  0.632058          10   0.01   \n",
       "2           10  1062  0.640627          10    NaN   \n",
       "3           10  3953  0.633518          10   0.01   \n",
       "4           10  1172  0.648327          10    NaN   \n",
       "5           20  1928  0.557930  asymmetric   0.10   \n",
       "6           20  3328  0.574971        0.01    NaN   \n",
       "7           20  1062  0.561865          10    NaN   \n",
       "8           20  3953  0.563291  asymmetric   0.01   \n",
       "9           20  1172  0.585560          10   0.10   \n",
       "10          50  1928  0.612763         0.1  10.00   \n",
       "11          50  3328  0.631923         0.1  10.00   \n",
       "12          50  1062  0.629078         0.1  10.00   \n",
       "13          50  3953  0.657174         0.1  10.00   \n",
       "14          50  1172  0.622675         0.1  10.00   \n",
       "15         100  1928  0.634541         0.1  10.00   \n",
       "16         100  3328  0.666028         0.1  10.00   \n",
       "17         100  1062  0.662159         0.1  10.00   \n",
       "18         100  3953  0.651841         0.1  10.00   \n",
       "19         100  1172  0.642149         0.1  10.00   \n",
       "\n",
       "                                                tests  \n",
       "0   {0: {'top 5 sample': ['start', 'time', 'feel',...  \n",
       "1   {0: {'top 5 sample': ['iud', 'month', 'bad', '...  \n",
       "2   {0: {'top 5 sample': ['cup', 'flow', 'partner'...  \n",
       "3   {0: {'top 5 sample': ['pregnancy', 'early', 't...  \n",
       "4   {0: {'top 5 sample': ['control', 'pill', 'take...  \n",
       "5   {0: {'top 5 sample': ['good', 'time', 'feel', ...  \n",
       "6   {0: {'top 5 sample': ['feel', 'time', 'ultraso...  \n",
       "7   {0: {'top 5 sample': ['pad', 'sex', 'clean', '...  \n",
       "8   {0: {'top 5 sample': ['week', 'doctor', 'day',...  \n",
       "9   {0: {'top 5 sample': ['period', 'pill', 'pack'...  \n",
       "10  {0: {'top 5 sample': ['delay_clamp', 'due_date...  \n",
       "11  {0: {'top 5 sample': ['smp', 'lange', 'donate_...  \n",
       "12  {0: {'top 5 sample': ['criminal', 'due_date_bu...  \n",
       "13  {0: {'top 5 sample': ['horrendous', 'smp', 'do...  \n",
       "14  {0: {'top 5 sample': ['due_date_buddy', 'horre...  \n",
       "15  {0: {'top 5 sample': ['hereditary', 'horrendou...  \n",
       "16  {0: {'top 5 sample': ['purposely', 'weapon', '...  \n",
       "17  {0: {'top 5 sample': ['due_date_buddy', 'arthr...  \n",
       "18  {0: {'top 5 sample': ['kilogram', 'toxin', 'to...  \n",
       "19  {0: {'top 5 sample': ['horrendous', 'kilogram'...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1432e",
   "metadata": {},
   "source": [
    "### Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1e53fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../../res/gensim_test.csv'\n",
    "\n",
    "df_to_csv(df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3c08d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
